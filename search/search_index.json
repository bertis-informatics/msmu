{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"msmu","text":"<p>Python toolkit for LC-MS/MS Proteomics analysis based on MuData</p>"},{"location":"#overview","title":"Overview","text":"<p><code>msmu</code> is a Python package for scalable, modular, and reproducible LC-MS/MS bottom-up proteomics data analysis. It supports PSM (precursor), peptide, and protein-level processing, integrates <code>MuData</code> (<code>AnnData</code>) structure, and enables stepwise normalization, batch correction, and statistical testing for biomarker discovery and systems biology.</p>"},{"location":"#key_features","title":"Key Features","text":"<ul> <li>Flexible data ingestion from DIA-NN, Sage and other popular DB search tools</li> <li>MuData/AnnData-compatible object structure for multi-level omics</li> <li>Built-in QC: precursor purity, peptide length, charge, missed cleavage</li> <li>Protein inference: infer protein with parsimony rule</li> <li>Normalization options: log2 transformation, median, quantile, GIS/IRS</li> <li>Batch correction: GIS/IRS, median centering</li> <li>Statistical analysis: permutation-based DE test and FDR</li> <li>PTM support and stoichiometry adjustment with global dataset</li> <li>Visualization: PCA, UMAP, volcano plots, heatmaps, QC metrics</li> </ul>"},{"location":"#supporting_db_search_tools","title":"Supporting DB Search Tools","text":"<ul> <li>Sage: https://sage-docs.vercel.app</li> <li>DIA-NN: https://github.com/vdemichev/DIA-NN</li> <li>MaxQuant: https://www.maxquant.org/</li> <li>FragPipe: https://fragpipe.nesvilab.org/</li> </ul>"},{"location":"gen_ref_pages/","title":"Gen ref pages","text":"In\u00a0[\u00a0]: Copied! <pre># scripts/gen_ref_pages.py\nfrom pathlib import Path\nimport mkdocs_gen_files\nimport msmu\nimport inspect\n</pre> # scripts/gen_ref_pages.py from pathlib import Path import mkdocs_gen_files import msmu import inspect In\u00a0[\u00a0]: Copied! <pre>PACKAGE = \"msmu\"  # ./msmu \ub808\uc774\uc544\uc6c3 \uac00\uc815\nsrc_dir = Path(msmu.__file__).parent  # msmu/ \ub514\ub809\ud1a0\ub9ac\nnav = mkdocs_gen_files.Nav()\n</pre> PACKAGE = \"msmu\"  # ./msmu \ub808\uc774\uc544\uc6c3 \uac00\uc815 src_dir = Path(msmu.__file__).parent  # msmu/ \ub514\ub809\ud1a0\ub9ac nav = mkdocs_gen_files.Nav() In\u00a0[\u00a0]: Copied! <pre>def map_alias(name):\n    if name == \"pp\":\n        return \"preprocessing: &lt;b&gt;&lt;code&gt;pp&lt;/code&gt;&lt;/b&gt;\"\n    if name == \"pl\":\n        return \"plotting: &lt;b&gt;&lt;code&gt;pl&lt;/code&gt;&lt;/b&gt;\"\n    if name == \"tl\":\n        return \"tools: &lt;b&gt;&lt;code&gt;tl&lt;/code&gt;&lt;/b&gt;\"\n    return name\n</pre> def map_alias(name):     if name == \"pp\":         return \"preprocessing: <code>pp</code>\"     if name == \"pl\":         return \"plotting: <code>pl</code>\"     if name == \"tl\":         return \"tools: <code>tl</code>\"     return name In\u00a0[\u00a0]: Copied! <pre>def iterate_modules(parent, parent_alias=[]):\n    if not hasattr(parent, \"__all__\"):\n        return\n\n    for module_name in parent.__all__:\n        child = getattr(parent, module_name)\n        if child.__name__.startswith(\"_\"):\n            continue\n\n        if inspect.ismodule(child):\n            yield from iterate_modules(child, parent_alias + [module_name])\n\n        if inspect.isfunction(child) or inspect.isclass(child):\n            parts = parent_alias + [child.__name__]  # ['module', 'function']\n            ident = \".\".join([PACKAGE] + parts)  # msmu.module.function\n\n            doc = Path(\"reference\", *parts).with_suffix(\".md\")\n\n            with mkdocs_gen_files.open(doc, \"w\") as f:\n                f.write(\"---\\n\")\n                f.write(f\"title: '{child.__name__}'\\n\")\n                f.write(\"hide:\\n\")\n                f.write(\"  - toc\\n\")\n                f.write(\"---\\n\\n\")\n                f.write(f\"# `{ident}`\\n\\n::: {ident}\\n\")\n\n            nav[[map_alias(p) for p in parts]] = Path(\"reference\", *parts).with_suffix(\".md\").as_posix()\n\n            yield child.__name__, child\n</pre> def iterate_modules(parent, parent_alias=[]):     if not hasattr(parent, \"__all__\"):         return      for module_name in parent.__all__:         child = getattr(parent, module_name)         if child.__name__.startswith(\"_\"):             continue          if inspect.ismodule(child):             yield from iterate_modules(child, parent_alias + [module_name])          if inspect.isfunction(child) or inspect.isclass(child):             parts = parent_alias + [child.__name__]  # ['module', 'function']             ident = \".\".join([PACKAGE] + parts)  # msmu.module.function              doc = Path(\"reference\", *parts).with_suffix(\".md\")              with mkdocs_gen_files.open(doc, \"w\") as f:                 f.write(\"---\\n\")                 f.write(f\"title: '{child.__name__}'\\n\")                 f.write(\"hide:\\n\")                 f.write(\"  - toc\\n\")                 f.write(\"---\\n\\n\")                 f.write(f\"# `{ident}`\\n\\n::: {ident}\\n\")              nav[[map_alias(p) for p in parts]] = Path(\"reference\", *parts).with_suffix(\".md\").as_posix()              yield child.__name__, child In\u00a0[\u00a0]: Copied! <pre>list(iterate_modules(msmu))\n</pre> list(iterate_modules(msmu)) In\u00a0[\u00a0]: Copied! <pre># Add indents to the generated nav.md\nnav_template = Path(\"docs\", \"nav.md\").read_text()\nif not nav_template.endswith(\"\\n\"):\n    nav_template += \"\\n\"\n</pre> # Add indents to the generated nav.md nav_template = Path(\"docs\", \"nav.md\").read_text() if not nav_template.endswith(\"\\n\"):     nav_template += \"\\n\" In\u00a0[\u00a0]: Copied! <pre>def format_api(line):\n    return \"    \" + line.replace(\"\\\\\", \"\")\n</pre> def format_api(line):     return \"    \" + line.replace(\"\\\\\", \"\") In\u00a0[\u00a0]: Copied! <pre>api_nav = [format_api(line) for line in nav.build_literate_nav()]\nwith mkdocs_gen_files.open(\"nav.md\", \"w\") as nav_file:\n    nav_file.write(nav_template)\n    nav_file.writelines(api_nav)\n</pre> api_nav = [format_api(line) for line in nav.build_literate_nav()] with mkdocs_gen_files.open(\"nav.md\", \"w\") as nav_file:     nav_file.write(nav_template)     nav_file.writelines(api_nav)"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.8 or newer</li> <li>(Recommended) A virtual environment such as <code>venv</code>, <code>conda</code>, <code>pipenv</code>, or <code>uv</code></li> </ul>"},{"location":"installation/#install_with_pip","title":"Install with pip","text":"<p>It is strongly recommended to create virtual environment.</p>"},{"location":"installation/#from_source_distribution","title":"From Source Distribution","text":"pippipenv <pre><code>curl &lt;_RELEASE_BINARY_URL_&gt;\npip install msmu-&lt;version&gt;.tar.gz\npython -c \"import msmu; print('msmu:', msmu.__version__)\"\n</code></pre> <pre><code>curl &lt;_RELEASE_BINARY_URL_&gt;\npipenv install msmu-&lt;version&gt;.tar.gz\npipenv run python -c \"import msmu; print('msmu:', msmu.__version__)\"\n</code></pre>"},{"location":"installation/#from_pypi_planned","title":"From PyPI (planned)","text":"<p>Once published to PyPI, installation will be:</p> pippipenv <pre><code>pip install msmu\npython -c \"import msmu; print('msmu:', msmu.__version__)\"\n</code></pre> <pre><code>pipenv install msmu\npipenv run python -c \"import msmu; print('msmu:', msmu.__version__)\"\n</code></pre>"},{"location":"installation/#from_source_repository","title":"From Source Repository","text":"<p>If you want the latest version from the repository:</p> pippipenv <pre><code>git clone https://github.com/bertis-informatics/msmu.git\ncd msmu\npip install -e .\npython -c \"import msmu; print('msmu:', msmu.__version__)\"\n</code></pre> <pre><code>git clone https://github.com/bertis-informatics/msmu.git\ncd msmu\npipenv install -e .\npipenv run python -c \"import msmu; print('msmu:', msmu.__version__)\"\n</code></pre>"},{"location":"nav/","title":"Nav","text":"<ul> <li>HOME</li> <li>INSTALLATION</li> <li>TUTORIALS<ul> <li><code>QUICK START</code></li> <li>DDA-TMT</li> <li>DDA-LFQ</li> <li>DIA-LFQ</li> <li>PTM</li> <li>DE Analysis</li> <li>2024 Fulcher et al.<ul> <li>01 Process scRNAseq Data</li> <li>02 Process Proteomics Data</li> <li>03 Handle Multi-omics Data</li> </ul> </li> </ul> </li> <li>HOW IT WORKS<ul> <li>Data</li> <li>Filter</li> <li>Normalisation</li> <li>Batch Correction</li> <li>Summarisation</li> <li>Protein Inference</li> <li>Precursor Isolation Purity</li> <li>DE Analysis</li> <li>Visualisation</li> </ul> </li> <li>API<ul> <li>read_h5mu</li> <li>read_sage</li> <li>merge_mudata</li> <li>preprocessing: <code>pp</code><ul> <li>add_filter</li> <li>apply_filter</li> <li>log2_transform</li> <li>normalise</li> <li>correct_batch_effect</li> <li>to_peptide</li> <li>to_protein</li> <li>to_ptm</li> <li>infer_protein</li> <li>adjust_ptm_by_protein</li> </ul> </li> <li>plotting: <code>pl</code><ul> <li>plot_correlation</li> <li>plot_id</li> <li>plot_intensity</li> <li>plot_missingness</li> <li>plot_pca</li> <li>plot_umap</li> <li>plot_upset</li> <li>plot_var</li> </ul> </li> <li>tools: <code>tl</code><ul> <li>compute_precursor_isolation_purity</li> <li>compute_precursor_isolation_purity_from_mzml</li> <li>pca</li> <li>umap</li> <li>run_de</li> <li>PermTestResult</li> <li>StatTestResult</li> </ul> </li> <li>utils<ul> <li>subset</li> <li>split_tmt</li> <li>get_modality_dict</li> <li>map_fasta</li> <li>attach_fasta</li> <li>get_label</li> <li>uns_logger</li> <li>add_quant</li> <li>reindex_obs</li> <li>select_repr_protein</li> <li>parse_uniprot_accession</li> </ul> </li> <li>io<ul> <li>read_sage</li> <li>to_readable</li> <li>write_csv</li> <li>write_flashlfq_input</li> </ul> </li> </ul> </li> </ul>"},{"location":"how-it-works/batch_correction/","title":"Batch Correction","text":""},{"location":"how-it-works/batch_correction/#overview","title":"Overview","text":"<p>Batch effects are unwanted variations in the data that arise from differences in experimental conditions, such as different runs, days, or operators. These variations can obscure true biological signals and lead to misleading conclusions. <code>msmu</code> provides functions to correct for batch effects using methods like median centering and GIS/IRS for TMT data. For batch effect from continuous variables (e.g., injection order) will be supported in future releases.</p>"},{"location":"how-it-works/batch_correction/#correct_batch_effect","title":"<code>correct_batch_effect()</code>","text":"<p>The <code>correct_batch_effect()</code> function standardises the features in the specified modality to have zero median. Or scale features with GIS/IRS method for TMT data to correct for batch effects using Global Internal Standard (GIS) channels.</p> <pre><code>mdata = mm.pp.correct_batch_effect(\n    mdata,\n    modality=\"feature\",     # or \"peptide\", \"protein\"\n    method=\"gis\",           # options: \"median_center\", \"gis\"\n    gis_prefix=\"POOLED_\"    # prefix for GIS channels\n    rescale=True             # whether to rescale data\n)\n\n# or\nmdata = mm.pp.correct_batch_effect(\n    mdata,\n    modality=\"feature\",            # or \"peptide\", \"protein\"\n    method=\"median_center\",        # options: \"median_center\", \"gis\"\n    rescale=True                   # whether to rescale data\n)\n</code></pre>"},{"location":"how-it-works/data/","title":"Data in msmu","text":""},{"location":"how-it-works/data/#overview","title":"Overview","text":"<p>In LC-MS/MS \"shotgun\" <code>proteomics</code>, data analysis typically follows a hierarchical path\u2014starting from PSM-level data (PSM or precursor), progressing to peptides, and finally reaching proteins. Each stage introduces its own set of feature annotations, quantification matrices, and tool-specific metadata. As a result, shotgun proteomics data naturally form a multi-level and multi-dimensional structure (e.g., PSM/precursor, peptide, protein; feature metadata; sample annotations; QC metrics).</p> <p>To manage these properties consistently, <code>msmu</code> adopts <code>MuData</code> from the <code>scverse</code> ecosystem as the fundamental data format. <code>MuData</code>, together with its constituent <code>AnnData</code> objects, is widely used in scRNA-seq to manage complex data matrices and their associated metadata. The same structure fits proteomics naturally: identification-level attributes, quantification values, and sample information can all be stored cleanly and explored in an integrated way.</p> <p><code>msmu</code> works with data formatted as a <code>MuData</code> object composed of multiple <code>AnnData</code> modalities. Therefore, understanding the usage of <code>MuData</code> and <code>AnnData</code> helps when working with <code>msmu</code>.</p> <p>A <code>MuData</code> object used in <code>msmu</code> is organized by modalities, each corresponding to a specific processing level such as psm, peptide, and protein:</p> <pre><code>mdata\n</code></pre> <pre><code>mdata[\"psm\"]\n\n# or\nmdata[\"protein\"]\n</code></pre> <p>As general AnnData object, each individual modality contains <code>.var</code>, <code>.obs</code>, <code>.X</code>, <code>uns</code>, and etc,.</p> <ul> <li>A <code>.var</code> attribute is filled with features of each level data. For example, in <code>psm</code> modality for PSMs (or precursors), information describing scan number, filename, PEP, q-value, and etc, with <code>filename.scan</code> index.</li> <li>In <code>.obs</code>, metainfo for samples can be stored and initially filenames or TMT channels are used as index.</li> <li><code>.X</code> Holds the quantification matrix.</li> <li>All other unstructured data can be stored in <code>.uns</code>.</li> </ul>"},{"location":"how-it-works/data/#data_ingestion_from_db_search_tools","title":"Data Ingestion from DB search tools","text":"<p>Although different search tools output either one consolidated table or multiple separate tables, their contents can typically be organized into two main conceptual parts:</p> <ul> <li>Identification data - Identification data with feature-level annotations</li> <li>Quantification data - Quantitative values for features across samples</li> </ul> <p>While each tool\u2019s schema differs, all of them describe the same core identification and quantification features needed to construct peptide- and protein-level data suitable for comparative proteomics.</p> <p><code>read_*</code> functions in msmu extract the essential columns required for QC and downstream processing and migrate them into the <code>.var</code> of the <code>feature</code> modality. <code>read_*</code> functions are implemented in <code>msmu/_read_write/_reader_registry</code></p> <ul> <li> <p><code>read_*</code> functions (currently available)</p> </li> <li> <p><code>read_sage()</code></p> </li> <li><code>read_diann()</code></li> <li><code>read_maxquant()</code></li> <li> <p><code>read_fragpipe()</code></p> </li> <li> <p>Inputs</p> </li> <li><code>identification_file</code>: A file path to identification table</li> <li><code>quantification_file</code>: A file path to quantification table (if applicable) (for tools outputting separate quantification files like Sage)</li> <li><code>label</code>: used label (\"tmt\" or \"label_free\")</li> <li><code>acquisition</code>: acquisition method (\"dda\", or \"dia\") (for tools supporting both DDA and DIA like MaxQuant)</li> <li> <p>output</p> </li> <li> <p><code>mudata</code>: Data ingested mudata object</p> </li> <li> <p>columns migrated into <code>mdata[\"psm\"].var</code></p> </li> <li> <p><code>filename</code>, <code>peptide</code>(modified), <code>stripped_peptide</code>, <code>scan_num</code>, <code>proteins</code>, <code>missed_cleavages</code>, <code>peptide_length</code>, <code>charge</code>, <code>PEP</code>, <code>q-value</code></p> </li> <li> <p>decoy features are isolated from <code>.var</code> and stored in <code>.uns[\"decoy\"]</code> for later use in FDR calculation.</p> </li> <li>Quantification data for LFQ (DDA) is stored in <code>peptide</code> modality.</li> <li>Raw information from a search tool is stored in <code>mdata[\"psm\"].varm[\"search_result\"]</code></li> </ul> <pre><code>mdata = mm.read_sage(\n    identification_file=\"path/to/results.sage.tsv\",\n    quantification_file=\"path/to/tmt.tsv\",\n    label=\"tmt\",  # or \"label_free\"\n)\n\nmdata = mm.read_diann(\n    identification_file=\"path/to/report.tsv\",\n)\n\nmdata = mm.read_maxquant(\n    identification_file=\"path/to/output_file\",\n    label=\"tmt\",  # or \"label_free\"\n    acquisition=\"dda\",  # or \"dia\"\n)\n\nmdata = mm.read_fragpipe(\n    identification_file=\"path/to/output_file/psm.tsv\",\n    quantification_file=\"path/to/quantification_file/combined_modified_peptide.tsv\", # for LFQ\n    label=\"tmt\",  # or \"label_free\"\n)\n</code></pre>"},{"location":"how-it-works/dea/","title":"Differential Expression Analysis (DEA)","text":""},{"location":"how-it-works/dea/#overview","title":"Overview","text":"<p>Differential Expression Analysis (DEA) identifies proteins or peptides with significant abundance changes between experimental conditions. <code>msmu</code> provides permutation-based statistical testing to assess differential expression while controlling the false discovery rate (FDR).</p>"},{"location":"how-it-works/dea/#mmtlrun_de","title":"<code>mm.tl.run_de()</code>","text":"<p>The <code>run_de()</code> function performs a non-parametric permutation test to evaluate differential expression between two groups. It calculates p-values based on the distribution of test statistics obtained from permuted group labels.</p> <p>This function uses <code>welch</code>'s t-statistic by default, which is suitable for unequal variances between groups. Other statistics such as <code>student</code> t-test, <code>wilcoxon</code> rank-sum test, and <code>med_diff</code> (median difference) are also available.</p> <p>For <code>FDR</code> correction, <code>msmu</code> supports <code>empirical</code> from null distribution, and <code>bh</code> (Benjamini-Hochberg) methods. <code>empirical</code> FDR is recommended when using permutation tests.</p> <p><code>n_resamples</code> specifies the number of random permutations to generate the null distribution. if set to <code>None</code>, a simple hypothesis test without permutations is performed. <code>1000</code> resamples as default provides a good balance between accuracy and computational cost.</p> <p>if sample sizes are small to meet n_resamples, all possible permutations are used to compute exact p-values (exact test).</p> <p>log2 fold-change (<code>log2FC</code>) between the two groups is calculated as the difference of log2-transformed median values.</p> <p><code>p-value</code> from the test is computed with the proportion of permuted statistics that are as extreme or more extreme than the observed statistic in null distribution with two-sided test.</p> <p><code>q-value</code> with <code>empirical</code> FDR is calculated by <code>E[FDR] = pi0 * E[FP] / E[TP]</code> referred from Yang Xie et al., Bioinformatics, 2011. and Storey et al., 2003.</p> <p>See more details in the <code>msmu.tl.run_de</code> and usage examples in the tutorial <code>DE Analysis</code>.</p> <pre><code>de_res = mm.tl.run_de(\n    mdata,\n    modality=\"protein\",      # or \"peptide\"\n    category=\"condition\",    # column in .obs defining groups\n    ctrl=\"control\",          # control group label\n    expr=\"treated\",          # experimental group label\n    stat_method=\"welch\",     # options: \"welch\", \"student\", \"wilcoxon\", \"med_diff\", default \"welch\"\n    fdr=\"empirical\",         # options: \"empirical\", \"bh\", \"storey\", or False, default \"empirical\"\n    n_resamples=1000,        # number of permutations, default 1000, if None, simple hypothesis test is performed\n)\n\nde_res.to_df() # get results as pandas DataFrame\n</code></pre> <p>DE analysis results are stored in <code>PermTestResult</code>(for permutation test) (or <code>StatTestResult</code>; for simple test) object, which contains:</p> <p>DE results can be accessed as a pandas <code>DataFrame</code> using the <code>to_df()</code> method.</p>"},{"location":"how-it-works/dea/#visualization_of_dea_results","title":"Visualization of DEA Results","text":"<p><code>msmu</code> provides visualisation function to explore DEA results with volcano plots.</p> <pre><code>de_res.plot_volcano(\n    log2fc_cutoff=None, # (optional) log2 fold-change cutoff line, default None which shows fc_pct_5 line\n    pval_cutoff=0.05,   # (optional) p-value cutoff line, default 0.05\n    label_top_n=5,      # (optional) number of top significant features to label, default None (no labels)\n)\n</code></pre>"},{"location":"how-it-works/filter/","title":"Filter","text":""},{"location":"how-it-works/filter/#on_var","title":"on <code>.var</code>","text":"<p>Functions related to filtering feature (<code>.var</code>) are implemented in <code>msmu.pp.add_filter</code> and <code>msmu.pp.apply_filter</code>.</p> <p>In <code>msmu</code>, filtering features consists of 2 stages.</p> <ol> <li><code>add_filter()</code> to modality</li> <li>making boolean mask for features in <code>mdata[modality].varm[\"filter\"]</code></li> <li>a column to filter should be in <code>.var</code></li> <li> <p><code>keep</code> argument accept general expressions for test such as <code>lt</code>, <code>le</code>, <code>gt</code>, <code>ge</code>, <code>equal</code>, etc,..</p> </li> <li> <p><code>apply_filter()</code></p> <ul> <li>filter features based on boolean masks from <code>mdata[modality].varm[\"filter\"]</code></li> </ul> </li> </ol> <pre><code># filter PSM with q_value &lt; 0.01\nmdata = mm.pp.add_filter(\n    mdata,\n    modality=\"psm\",\n    column=\"q_value\", # a column in .var\n    keep=\"lt\",\n    value=0.01\n    )\n\nmdata = mm.pp.apply_filter(mdata, modality=\"psm\")\n</code></pre>"},{"location":"how-it-works/filter/#on_obs","title":"on <code>.obs</code>","text":"<p>Filtering on <code>.obs</code> is not implemented as utilised function. <code>.obs</code> can be filtered with slicing function on <code>mudata</code></p> <pre><code># filter BLANK channels for TMT studies\nmdata = mdata[mdata.obs[\"group\"] != \"BLANK\", ]\n</code></pre>"},{"location":"how-it-works/inference/","title":"Protein Inference","text":"<p>This page explains how <code>msmu</code> infers proteins from peptide-level features through <code>msmu.pp.add_filter</code>.</p>"},{"location":"how-it-works/inference/#how_protein_are_inferred","title":"How protein are inferred","text":"<ol> <li>Merge indistinguishable proteins (<code>_find_indistinguisable</code>)    Proteins with identical peptide sets are merged and named as a comma-joined list of members.</li> <li>Collapse subsettable proteins (<code>_find_subsettable</code>)    If one protein group\u2019s peptide set is a strict subset of another\u2019s, it is reassigned to the protein group that has larger set.</li> <li>Handle subsumable proteins (<code>_find_subsumable</code>)    Proteins lacking unique peptides are evaluated within connected components of shared peptides. Proteins that cannot be distinguished are merged; components without unique evidence are dropped.</li> </ol>"},{"location":"how-it-works/inference/#input","title":"Input","text":"<p>A <code>MuData</code> that has:</p> <ul> <li>A <code>peptide</code> modality containing <code>var[\"stripped_peptide\"]</code> and <code>var[\"proteins\"]</code> (semicolon-separated accessions per peptide). If decoys exist, they are pulled from <code>mdata[\"peptide\"].uns[\"decoy\"]</code>.</li> </ul>"},{"location":"how-it-works/inference/#output","title":"Output","text":"<p>A <code>MuData</code> with:</p> <ul> <li><code>mdata[\"peptide\"].var[\"protein_group\"]</code>: Newly inferenced protein group</li> <li><code>mdata[\"peptide\"].var[\"peptide_type\"]</code>: Peptide type (<code>unique</code> or <code>shared</code>).</li> <li>Decoys receive the same annotations under <code>mdata.uns[\"decoy\"]</code>.</li> </ul> <p>Output <code>MuData</code> also contains mapping information inside <code>uns</code></p> <ul> <li><code>mdata.uns[\"peptide_map\"]</code>: peptide \u2192 protein-group mapping.</li> <li><code>mdata.uns[\"protein_map\"]</code>: per-protein mapping with flags for <code>indistinguishable/subset/subsumable</code> status.</li> </ul>"},{"location":"how-it-works/normalisation/","title":"Normalisation","text":""},{"location":"how-it-works/normalisation/#overview","title":"Overview","text":"<p>Normalization is a crucial step in proteomics data analysis to correct for systematic biases and ensure comparability across samples. <code>msmu</code> provides several normalisation methods to address different experimental designs and data characteristics.</p>"},{"location":"how-it-works/normalisation/#log2_transform","title":"<code>log2_transform()</code>","text":"<p>The <code>log2_transform()</code> function applies a log2 transformation to the quantification data in the specified modality. This transformation helps stabilize variance and make the data more normally distributed, which is beneficial for downstream statistical analyses. <code>msmu</code> assumes that <code>log2_transfrom()</code> is applied on basal level of data before other normalisation methods.</p> <pre><code>mdata = mm.pp.log2_transform(\n    mdata,\n    modality=\"psm\"  # or \"peptide\", \"protein\"\n)\n</code></pre>"},{"location":"how-it-works/normalisation/#normalise_or_normalize","title":"<code>normalise()</code> (or <code>normalize()</code>)","text":"<p>The <code>normalise()</code> function offers multiple normalisation methods, including median (<code>median</code>) and quantile (<code>quantile</code>) normalisation. Users can select the method that best suits their data and experimental design. For fractionated TMT data, setting the <code>fraction</code> argument to <code>True</code> ensures that normalisation is performed within each fraction separately.</p> <pre><code>mdata = mm.pp.normalise(\n    mdata,\n    modality=\"psm\",           # or \"peptide\", \"protein\"\n    method=\"median\",          # options: \"median\", \"quantile\", default \"median\"\n    fraction=False            # whether data is fractionated\n)\n</code></pre>"},{"location":"how-it-works/normalisation/#adjust_ptm_by_protein","title":"<code>adjust_ptm_by_protein()</code>","text":"<p>The <code>adjust_ptm_by_protein()</code> function normalises PTM site quantifications by their corresponding protein abundances from <code>global proteome</code> data to account for changes in protein expression levels</p> <p>For <code>ridge</code> regression method, PTM site intensities are adjusted based on the fitted values from a ridge regression model that predicts PTM abundance using protein abundance as a predictor variable. This approach helps to isolate PTM-specific changes from overall protein expression variations.</p> <p>And for <code>ratio</code> method, PTM site intensities are normalised by calculating the ratio of PTM abundance to protein abundance, providing a direct measure of PTM changes relative to protein levels.</p> <pre><code>mdata = mm.pp.adjust_ptm_by_protein(\n    mdata,\n    global_mdata=global_mdata,   # MuData object for global proteome\n    ptm_mod=\"phospho_site\",      # ptm modality\n    method=\"ridge\",              # options: \"ridge\", \"ratio\". default \"ridge\"\n    rescale=True                 # whether to rescale adjusted values. default True\n)\n</code></pre>"},{"location":"how-it-works/purity/","title":"Precursor Isolation Purity","text":""},{"location":"how-it-works/purity/#overview","title":"Overview","text":"<p>Precursor Isolation Purity (PIP) is a metric that quantifies the proportion of the target precursor ion signal relative to the total signal within the isolation window during MS/MS acquisition. High PIP values indicate that the isolated precursor is relatively free from co-isolated contaminants, which is crucial for accurate quantification, especially in isobaric labeling experiments like TMT.</p> <p>In <code>msmu</code>, PIP is calculated using the <code>compute_precursor_isolation_purity()</code> function, which leverages the <code>pyopenms</code> library to analyze MS1 spectra and determine the purity of each precursor ion.</p> <pre><code>mdata = mm.pp.compute_precursor_isolation_purity(\n    mdata,\n    mzml_paths=[\"/path/to/mzml/files\"],  # path to mzML files\n    tolerance=20,                        # mass tolerance\n    unit_ppm=True                        # mass tolerance in ppm\n    )\n</code></pre>"},{"location":"how-it-works/summarisation/","title":"Summarisation","text":""},{"location":"how-it-works/summarisation/#overview","title":"Overview","text":"<p>The term <code>Summarisation</code> refers to aggregating identification features and quantitative values as data move from one level to the next (e.g., PSM/precursor -&gt; peptide -&gt; protein).</p> <p>Summarisation functions are provided as <code>to_*</code> methods, such as <code>to_peptide</code>, <code>to_protein</code>, and <code>to_ptm</code>.</p> <p>The <code>Summarisation</code> process generally involves:</p> <ol> <li>Feature selection</li> <li>Selecting features to include in the aggregation based on criteria such as peptide type (unique/shared), precursor isolation purity, or abundance.</li> <li>Identification and quantification aggregation</li> <li>Aggregation of quantification values using methods like <code>median</code>, <code>mean</code>, or <code>sum</code>.</li> <li>Computing identification confidence scores (PEP, q-value) at the new level when possible.</li> <li>Calculating PEP and q-values for the aggregated features using appropriate methods.</li> </ol>"},{"location":"how-it-works/summarisation/#to_peptide","title":"<code>to_peptide()</code>","text":"<p><code>to_peptide()</code> function takes:</p> <ul> <li><code>mudata</code> containing <code>PSM</code> level modality</li> </ul> <p>and returns</p> <ul> <li><code>mudata</code> with <code>peptide</code> level modality</li> </ul> <p>This step aggregates PSMs and their quantification values by <code>peptide</code> (modified peptide). Peptide-level <code>PEP</code> is calculated with <code>best PEP</code> method by default and peptide-level q-values are computed using a conservative approach when decoy information is available.</p> <p>For quantification aggregation, the default method is <code>median</code>, and an optional <code>top_n</code> argument can be used to restrict aggregation to the <code>top N</code> features within each peptide. Feature ranking is based on <code>total_intensity</code> unless specified otherwise..</p> <p>In TMT studies, PSMs with low isolation purity may be excluded prior to quantification aggregation to avoid mixing reporter ion signals. Isolation purity should be computed with <code>mm.pp.compute_precursor_isolation_purity()</code> before calling <code>to_peptide()</code>. A <code>purity_threshold</code> (commonly <code>0.7</code>) can be applied during aggregation.</p> <p>Note that filtering by <code>top_n</code> or <code>purity_threshold</code> affects quantification aggregation only and does not modify identification feature aggregation.</p> <pre><code>mdata = mm.pp.to_peptide(\n    mdata,\n    score_method=\"best_pep\",        # default\n    agg_method=\"median\",            # default\n    purity_threshold=0.7,           # for tmt data\n    top_n=None,                     # default\n    rank_method=\"total_intensity\",  # default\n    )\n</code></pre>"},{"location":"how-it-works/summarisation/#to_protein","title":"<code>to_protein()</code>","text":"<p><code>to_protein()</code> function takes:     - <code>mudata</code> containing <code>peptide</code> modality with inferred <code>protein_group</code> and <code>peptide_type</code> and returns:     - <code>mudata</code> with <code>protein</code> level modality</p> <p>Protein-level summarisation requires the <code>protein_group</code> and <code>peptide_type</code> columns, which are generated by <code>mm.pp.infer_protein()</code> from peptide-level data. Details are provided in the Protein Inference section. Briefly:</p> <ul> <li><code>protein_group</code> contains the inferred proteins for each peptide.</li> <li><code>peptide_type</code> indicates whether a peptide is \"unique\" or \"shared\".</li> </ul> <p>Only \"unique\" peptides are used for protein-group summarisation; \"shared\" peptides are excluded.</p> <p>As in peptide-level aggregation, protein-group level <code>PEP</code> and <code>q-value</code> are computed when possible.</p> <p>The default settings use <code>top_n=3</code> with ranking by <code>total_intensity</code>, so only the top three peptides per protein group contribute to quantification.</p> <pre><code># Infer protein-group from mdata (containing peptide modality)\nmdata = mm.pp.infer_protein(mdata)\n\n# Summarise peptides to protein-group\nmdata = mm.pp.to_protein(\n    mdata,\n    score_method=\"best_pep\",        # default\n    agg_method=\"median\",            # default\n    top_n=3,                        # default\n    rank_method=\"total_intensity\",  # default\n    )\n</code></pre>"},{"location":"how-it-works/summarisation/#to_ptm","title":"<code>to_ptm()</code>","text":"<p>To summarise modified peptide into post-translation modification (PTM) sites, <code>to_ptm()</code> uses the subset of peptides that contain the specified modification and then performs several steps to assign PTM positions at the protein level.</p> <p>Internally, the function performs:</p> <ol> <li>Filtering data with only modified peptides with modi_identifier</li> <li>Extracting modified sites from peptide</li> <li>Assigning peptide-level site labels</li> <li>Exploding peptides to single proteins for per-protein site labeling</li> <li>Mapping the site to the corresponding position in each protein</li> <li>Merging single-protein results back into protein groups</li> <li>Grouping by modified peptide and peptide-site combination</li> <li>Merging site metadata with peptide-level quantification</li> </ol> <p><code>to_ptm()</code> function takes:</p> <ul> <li><code>mudata</code> containing <code>peptide</code> modality and attached fasta</li> </ul> <p>and returns:</p> <ul> <li><code>mudata</code> with <code>ptm_site</code> level modality</li> </ul> <p>A FASTA file is required because PTM sites must be mapped to protein-sequence coordinates. FASTA can be attached using <code>mm.utils.attach_fasta()</code>.</p> <p>The argument <code>modi_name</code> determines the modality name (e.g., \"phospho\" -&gt; \"phospho_site\"), and the <code>modification</code> string is used to identify modified peptides.</p> <p><code>agg_method</code> can be selected among methods as described in other summarisation functions.</p> <pre><code>mdata = mm.utils.attach_fasta(\"fasta/file/path.fasta\")\n\nmdata = mm.pp.to_ptm(\n    mdata,\n    modi_name=\"phospho\",\n    modification=\"[+79.9663]\",\n    agg_method=\"median\",        # default\n    top_n=None                  # default\n    )\n</code></pre>"},{"location":"how-it-works/visualisation/","title":"Visualisation Overview","text":"<p><code>msmu._plotting</code> wraps Plotly to provide ready-made QC and exploratory plots for MuData objects. The module is structured around data preparation helpers and lightweight plot wrappers so you can compose figures with consistent defaults while still passing Plotly kwargs to tweak layout.</p>"},{"location":"how-it-works/visualisation/#common_parameters_and_behaviors","title":"Common parameters and behaviors","text":"<ul> <li><code>mdata</code>: required <code>MuData</code> containing the modality to plot.</li> <li><code>modality</code>: defaults vary by plot (<code>feature</code>, <code>peptide</code>, <code>protein</code>)</li> <li><code>groupby</code>: observation column used to split traces/groups (e.g., <code>filename</code>, <code>condition</code>). If omitted, falls back to <code>obs_column</code>.</li> <li><code>obs_column</code>: observation column used for labeling/group resolution; all element should be unique. If omitted or no column exists, creates <code>__obx_idx__</code> column from the index of <code>obs</code></li> <li><code>colorby</code>: optional obs column for coloring; only applied when <code>groupby</code> equals <code>obs_column</code>.</li> <li><code>ptype</code>: plot style selector(<code>hist</code>, <code>box</code>, <code>vln</code>, etc.).</li> <li><code>**kwargs</code>: forwarded to <code>go.Figure.update_layout</code> for per-plot overrides.</li> </ul>"},{"location":"how-it-works/visualisation/#example","title":"Example","text":"<p>Uszkoreit, J., Barkovits, K., Pacharra, S., Pfeiffer, K., Steinbach, S., Marcus, K., &amp; Eisenacher, M. (2022). Dataset containing physiological amounts of spike-in proteins into murine C2C12 background as a ground truth quantitative LC-MS/MS reference. Data in Brief, 43, 108435.</p>"},{"location":"how-it-works/visualisation/#mdataobs","title":"mdata.obs","text":"set sample_id sample_name condition replicate S1 QExHF04026 G1-1 G1 1 S1 QExHF04028 G2-1 G2 1 S1 QExHF04030 G3-1 G3 1 S1 QExHF04032 G4-1 G4 1 S1 QExHF04034 G5-1 G5 1 S1 QExHF04036 G1-2 G1 2 S1 QExHF04038 G2-2 G2 2 S1 QExHF04040 G3-2 G3 2 S1 QExHF04042 G4-2 G4 2 S1 QExHF04044 G5-2 G5 2 S1 QExHF04046 G1-3 G1 3 S1 QExHF04048 G2-3 G2 3 S1 QExHF04050 G3-3 G3 3 S1 QExHF04052 G4-3 G4 3 S1 QExHF04054 G5-3 G5 3"},{"location":"how-it-works/visualisation/#plot_id","title":"<code>plot_id</code>","text":"<pre><code>mm.pl.plot_id(mdata, \"protein\", groupby=\"sample_name\")\n</code></pre> <pre><code>mm.pl.plot_id(mdata, \"protein\", groupby=\"condition\")\n</code></pre>"},{"location":"how-it-works/visualisation/#plot_intensity","title":"<code>plot_intensity</code>","text":"<pre><code>mm.pl.plot_intensity(mdata, \"protein\", groupby=\"sample_name\", ptype=\"hist\")\n</code></pre>"},{"location":"how-it-works/visualisation/#plot_missingness","title":"<code>plot_missingness</code>","text":"<pre><code>mm.pl.plot_missingness(mdata, \"protein\")\n</code></pre>"},{"location":"how-it-works/visualisation/#plot_var","title":"<code>plot_var</code>","text":"<pre><code>mm.pl.plot_var(mdata, \"feature\", groupby=\"sample_name\", var_column=\"charge\", ptype=\"stacked_bar\")\n</code></pre> <pre><code>mm.pl.plot_var(mdata, \"feature\", groupby=\"sample_name\", var_column=\"peptide_length\", ptype=\"vln\")\n</code></pre>"},{"location":"how-it-works/visualisation/#plot_pca_plot_umap","title":"<code>plot_pca</code> &amp; <code>plot_umap</code>","text":"<pre><code>mm.pl.plot_pca(mdata, \"protein\", groupby=\"condition\")\n</code></pre>"},{"location":"how-it-works/visualisation/#plot_correlation","title":"<code>plot_correlation</code>","text":"<pre><code>mm.pl.plot_correlation(mdata, \"protein\")\n</code></pre>"},{"location":"how-it-works/visualisation/#plot_upset","title":"<code>plot_upset</code>","text":"<pre><code>mm.pl.plot_upset(mdata, \"protein\", groupby=\"condition\")\n</code></pre>"},{"location":"reference/merge_mudata/","title":"<code>msmu.merge_mudata</code>","text":"<p>Merges multiple MuData objects into a single MuData object.</p> <p>Parameters:</p> Name Type Description Default <code>mdatas</code> <code>dict[str, MuData]</code> <p>Dictionary of MuData objects to merge.</p> required <p>Returns:</p> Type Description <code>MuData</code> <p>Merged MuData object.</p>"},{"location":"reference/read_h5mu/","title":"<code>msmu.read_h5mu</code>","text":"<p>Reads an h5mu file (HDF5) and returns a MuData object.</p> <p>Parameters:</p> Name Type Description Default <code>h5mu_file</code> <code>str | Path</code> <p>Path to the H5MU file.</p> required <p>Returns:</p> Type Description <code>MuData</code> <p>A MuData object.</p>"},{"location":"reference/read_sage/","title":"<code>msmu.read_sage</code>","text":"<p>Reads Sage output and returns a MuData object.</p> <p>Parameters:</p> Name Type Description Default <code>identificaton_file</code> <p>Path to the results.sage.tsv.</p> required <code>label</code> <code>Literal['tmt', 'label_free']</code> <p>Label for the Sage output ('tmt' or 'label_free').</p> required <code>quantification_file</code> <code>str | Path | None</code> <p>Whether to include quantification data. Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>MuData</code> <p>A MuData object containing the Sage data.</p>"},{"location":"reference/io/read_sage/","title":"<code>msmu.io.read_sage</code>","text":"<p>Reads Sage output and returns a MuData object.</p> <p>Parameters:</p> Name Type Description Default <code>identificaton_file</code> <p>Path to the results.sage.tsv.</p> required <code>label</code> <code>Literal['tmt', 'label_free']</code> <p>Label for the Sage output ('tmt' or 'label_free').</p> required <code>quantification_file</code> <code>str | Path | None</code> <p>Whether to include quantification data. Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>MuData</code> <p>A MuData object containing the Sage data.</p>"},{"location":"reference/io/to_readable/","title":"<code>msmu.io.to_readable</code>","text":"<p>Convert MuData modality to a human-readable format.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the data to convert.</p> required <code>modality</code> <code>str</code> <p>The modality to convert (e.g., 'psm', 'peptide', 'protein').</p> required <code>include</code> <code>str | list[str] | None</code> <p>List of columns to include.</p> <code>None</code> <code>exclude</code> <code>str | list[str] | None</code> <p>List of columns to exclude.</p> <code>None</code> <code>quantification</code> <code>bool</code> <p>Whether to include quantification data.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas DataFrame in a human-readable format.</p>"},{"location":"reference/io/write_csv/","title":"<code>msmu.io.write_csv</code>","text":"<p>Exports MuData modalities to CSV/TSV files.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the data to export.</p> required <code>modality</code> <code>str</code> <p>The modality to export (e.g., 'psm', 'peptide', 'protein').</p> required <code>filename</code> <code>str | Path</code> <p>Path to the output file.</p> required <code>sep</code> <code>str</code> <p>Separator for the output file (e.g., ',', '        ').</p> required <code>include</code> <code>str | list[str] | None</code> <p>List of columns to include.</p> <code>None</code> <code>exclude</code> <code>str | list[str] | None</code> <p>List of columns to exclude.</p> <code>None</code> <code>quantification</code> <code>bool</code> <p>Whether to include quantification data.</p> <code>True</code>"},{"location":"reference/io/write_flashlfq_input/","title":"<code>msmu.io.write_flashlfq_input</code>","text":"<p>Exports MuData psm object to FlashLFQ format.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the data to export.</p> required <code>filename</code> <code>str | Path</code> <p>Path to the output FlashLFQ file.</p> required"},{"location":"reference/pl/plot_correlation/","title":"<code>msmu.pl.plot_correlation</code>","text":"<p>Plots a lower-triangular Pearson correlation heatmap of grouped medians.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing expression data.</p> required <code>modality</code> <code>str</code> <p>Target modality; defaults to 'protein'.</p> <code>'protein'</code> <code>groupby</code> <code>str | None</code> <p>Observation column used to group and average values.</p> <code>None</code> <code>obs_column</code> <code>str | None</code> <p>Observation column used for labeling/group resolution.</p> <code>None</code> <code>**kwargs</code> <code>str</code> <p>Additional layout options forwarded to Plotly.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Heatmap of pairwise correlations.</p>"},{"location":"reference/pl/plot_id/","title":"<code>msmu.pl.plot_id</code>","text":"<p>Plots identification counts per modality grouped by observations.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the modality to visualize.</p> required <code>modality</code> <code>str</code> <p>Target modality (psm, peptide, protein, or site).</p> required <code>groupby</code> <code>str | None</code> <p>Observation column used to group bars.</p> <code>None</code> <code>colorby</code> <code>str | None</code> <p>Observation column used for coloring (when applicable).</p> <code>None</code> <code>template</code> <code>str</code> <p>Plotly template for colorway.</p> <code>DEFAULT_TEMPLATE</code> <code>obs_column</code> <code>str | None</code> <p>Observation column used for labeling/group resolution.</p> <code>None</code> <code>**kwargs</code> <code>str</code> <p>Additional layout options forwarded to Plotly.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Bar chart of identification counts per group.</p>"},{"location":"reference/pl/plot_intensity/","title":"<code>msmu.pl.plot_intensity</code>","text":"<p>Visualizes intensity distributions for a modality using histograms, box, or violin plots.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the modality to visualize.</p> required <code>modality</code> <code>str</code> <p>Target modality (psm, peptide, protein, or site).</p> required <code>groupby</code> <code>str | None</code> <p>Observation column used to group traces.</p> <code>None</code> <code>colorby</code> <code>str | None</code> <p>Observation column used for coloring (when applicable).</p> <code>None</code> <code>ptype</code> <code>str</code> <p>Plot type: 'hist', 'box', or 'vln'.</p> <code>'hist'</code> <code>template</code> <code>str</code> <p>Plotly template for colorway.</p> <code>DEFAULT_TEMPLATE</code> <code>bins</code> <code>int</code> <p>Number of bins for histogram view.</p> <code>30</code> <code>obs_column</code> <code>str | None</code> <p>Observation column used for labeling/group resolution.</p> <code>None</code> <code>**kwargs</code> <code>str</code> <p>Additional layout options forwarded to Plotly.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Intensity distribution figure.</p>"},{"location":"reference/pl/plot_missingness/","title":"<code>msmu.pl.plot_missingness</code>","text":"<p>Plots cumulative data completeness percentages for a modality.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the modality to visualize.</p> required <code>modality</code> <code>str</code> <p>Target modality (psm, peptide, protein, or site).</p> required <code>obs_column</code> <code>str | None</code> <p>Observation column used to order samples.</p> <code>None</code> <code>**kwargs</code> <code>str</code> <p>Additional layout options forwarded to Plotly.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Step line plot of cumulative completeness.</p>"},{"location":"reference/pl/plot_pca/","title":"<code>msmu.pl.plot_pca</code>","text":"<p>Plots PCA scores for a modality colored/grouped by observation metadata.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing PCA results.</p> required <code>modality</code> <code>str</code> <p>Target modality; defaults to 'protein'.</p> <code>'protein'</code> <code>groupby</code> <code>str | None</code> <p>Observation column used to group traces.</p> <code>None</code> <code>colorby</code> <code>str | None</code> <p>Observation column used for coloring (when applicable).</p> <code>None</code> <code>template</code> <code>str</code> <p>Plotly template for colorway.</p> <code>DEFAULT_TEMPLATE</code> <code>pcs</code> <code>tuple[int, int] | list[int]</code> <p>Pair of principal component indices (1-based).</p> <code>(1, 2)</code> <code>obs_column</code> <code>str | None</code> <p>Observation column used for labeling/group resolution.</p> <code>None</code> <code>**kwargs</code> <code>str</code> <p>Additional layout options forwarded to Plotly.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Scatter plot of PCA scores.</p>"},{"location":"reference/pl/plot_umap/","title":"<code>msmu.pl.plot_umap</code>","text":"<p>Plots UMAP embeddings for a modality colored/grouped by observations.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing UMAP embeddings.</p> required <code>modality</code> <code>str</code> <p>Target modality; defaults to 'protein'.</p> <code>'protein'</code> <code>groupby</code> <code>str | None</code> <p>Observation column used to group traces.</p> <code>None</code> <code>colorby</code> <code>str | None</code> <p>Observation column used for coloring (when applicable).</p> <code>None</code> <code>template</code> <code>str</code> <p>Plotly template for colorway.</p> <code>DEFAULT_TEMPLATE</code> <code>obs_column</code> <code>str | None</code> <p>Observation column used for labeling/group resolution.</p> <code>None</code> <code>**kwargs</code> <code>str</code> <p>Additional layout options forwarded to Plotly.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Scatter plot of UMAP embeddings.</p>"},{"location":"reference/pl/plot_upset/","title":"<code>msmu.pl.plot_upset</code>","text":"<p>Draws an Upset plot showing protein intersections across observation groups.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the modality to visualize.</p> required <code>modality</code> <code>str</code> <p>Target modality; defaults to 'protein'.</p> <code>'protein'</code> <code>subset</code> <code>str | None</code> <p>Specific observation value to subset on; optional.</p> <code>None</code> <code>subset_column</code> <code>str | None</code> <p>Observation column used for subsetting.</p> <code>None</code> <code>groupby</code> <code>str | None</code> <p>Observation column used to define sets.</p> <code>None</code> <code>obs_column</code> <code>str | None</code> <p>Observation column used for labeling/group resolution.</p> <code>None</code> <code>**kwargs</code> <code>str</code> <p>Additional layout options forwarded to Plotly.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Upset diagram of protein intersections.</p>"},{"location":"reference/pl/plot_var/","title":"<code>msmu.pl.plot_var</code>","text":"<p>Plots variable annotations using stacked bars, box/violin plots, or histograms.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the modality to visualize.</p> required <code>modality</code> <code>str</code> <p>Target modality; defaults to 'psm'.</p> <code>'psm'</code> <code>groupby</code> <code>str | None</code> <p>Observation column used to group traces.</p> <code>None</code> <code>var_column</code> <code>str | None</code> <p>Variable column to visualize.</p> <code>None</code> <code>obs_column</code> <code>str | None</code> <p>Observation column used for labeling/group resolution.</p> <code>None</code> <code>ptype</code> <code>str | None</code> <p>Plot type inferred for numeric/categorical data when None.</p> <code>None</code> <code>bins</code> <code>int</code> <p>Number of bins for histogram view.</p> <code>30</code> <code>**kwargs</code> <code>str</code> <p>Additional layout options forwarded to Plotly.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Plot of variable annotation distributions.</p>"},{"location":"reference/pp/add_filter/","title":"<code>msmu.pp.add_filter</code>","text":"<p>Adds a filter to the specified modality in the MuData object based on the given condition.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object to which the filter will be added.</p> required <code>modality</code> <code>str</code> <p>The modality within the MuData object to which the filter will be applied</p> required <code>column</code> <code>str</code> <p>The column in the modality's var DataFrame to apply the filter on.</p> required <code>value</code> <code>str | float | None</code> <p>The value to compare against for filtering.</p> required <p>Returns:</p> Name Type Description <code>MuData</code> <code>MuData</code> <p>MuData object with the added filter.</p>"},{"location":"reference/pp/adjust_ptm_by_protein/","title":"<code>msmu.pp.adjust_ptm_by_protein</code>","text":"<p>Estimation of PTM stoichiometry by using Global Protein Data.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object to normalise.</p> required <code>global_mdata</code> <code>MuData</code> <p>MuData object which contains global protein expression.</p> required <code>modality</code> <code>str</code> <p>PTM modality to normalise (e.g. phospho_site, {ptm}_site).</p> <code>'phospho_site'</code> <code>layer</code> <code>str | None</code> <p>Layer to normalise. If None, the default layer (.X) will be used.</p> <code>None</code> <code>global_mod</code> <p>Modality in global_mdata to normalise PTM site. Default is 'protein'.</p> required <code>method</code> <code>Literal['ridge', 'ratio']</code> <p>A method for normalisation. Options: ridge, ratio. Default is 'ridge'.</p> <code>'ridge'</code> <code>rescale</code> <code>bool</code> <p>If True, rescale the data after normalisation with median value across dataset. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>MuData</code> <p>Normalised MuData object.</p>"},{"location":"reference/pp/apply_filter/","title":"<code>msmu.pp.apply_filter</code>","text":"<p>Applies the filter to the specified modality in the MuData object.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object to which the filter will be applied.</p> required <code>modality</code> <code>str</code> <p>The modality within the MuData object to which the filter will be applied.</p> required <p>Returns:</p> Name Type Description <code>MuData</code> <code>MuData</code> <p>MuData object with the filter applied.</p>"},{"location":"reference/pp/correct_batch_effect/","title":"<code>msmu.pp.correct_batch_effect</code>","text":"<p>correct_batch_effect in MuData object.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object to normalise.</p> required <code>method</code> <code>Literal['gis', 'median_center']</code> <p>Normalisation method to use. Options are 'gis', 'median_center'.</p> required <code>modality</code> <code>str</code> <p>Modality to normalise.</p> required <code>layer</code> <code>str | None</code> <p>Layer to normalise. If None, the default layer (.X) will be used.</p> <code>None</code> <code>gis_prefix</code> <code>str | None</code> <p>Prefix for GIS samples. If None, all samples with 'gis' in the name will be used.</p> <code>None</code> <code>gis_col</code> <code>list[str] | None</code> <p>Column name for GIS samples. If None, all samples with 'gis' in the name will be used.</p> <code>None</code> <code>rescale</code> <code>bool</code> <p>If True, rescale the data after normalisation with median value across dataset. This is only applicable for median normalisation.</p> <code>True</code> <p>Returns:</p> Type Description <code>MuData</code> <p>Normalised MuData object.</p>"},{"location":"reference/pp/infer_protein/","title":"<code>msmu.pp.infer_protein</code>","text":"<p>Infer protein-group mappings and annotate peptides with uniqueness.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object to update</p> required <code>modality</code> <code>str</code> <p>modality holding peptide-level data</p> <code>'peptide'</code> <code>protein_colname</code> <code>str</code> <p>column in var with semicolon-delimited protein accessions</p> <code>'proteins'</code> <code>peptide_colname</code> <code>str</code> <p>column in var with stripped peptide sequences</p> <code>'stripped_peptide'</code> <code>propagated_from</code> <code>MuData | str | None</code> <p>optional MuData or path to reuse existing mappings (e.g., global reference for PTM work)</p> <code>None</code> <p>Returns:</p> Type Description <code>MuData</code> <p>MuData object with updated protein mappings and peptide annotations</p>"},{"location":"reference/pp/log2_transform/","title":"<code>msmu.pp.log2_transform</code>","text":"<p>Apply log2 transformation to the specified modality in MuData object.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object to transform.</p> required <code>modality</code> <code>str</code> <p>Modality to log2 transform.</p> required <p>Returns:</p> Type Description <code>MuData</code> <p>Transformed MuData object.</p>"},{"location":"reference/pp/normalise/","title":"<code>msmu.pp.normalise</code>","text":"<p>Normalise data in MuData object.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object to normalise.</p> required <code>method</code> <code>str</code> <p>Normalisation method to use. Options are 'quantile', 'median', 'total_sum (not implemented)'.</p> required <code>modality</code> <code>str</code> <p>Modality to normalise. If None, all modalities at the specified level will be normalised.</p> required <code>layer</code> <code>str | None</code> <p>Layer to normalise. If None, the default layer (.X) will be used.</p> <code>None</code> <code>fraction</code> <code>bool</code> <p>If True, normalise within fractions. If False, normalise across all data. \"fraction\" yet supports fractionated TMT.</p> <code>False</code> <p>Returns:</p> Type Description <code>MuData</code> <p>Normalised MuData object.</p>"},{"location":"reference/pp/to_peptide/","title":"<code>msmu.pp.to_peptide</code>","text":"<p>Summarise PSM-level data to peptide-level data.</p> Usage <p>mdata = mm.pp.to_peptide(     mdata,     agg_method=\"median\",     calculate_q=True,     score_method=\"best_pep\",     purity_threshold=0.7, )</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing PSM-level data.</p> required <code>layer</code> <code>str | None</code> <p>Layer to use for quantification aggregation. If None, the default layer (.X) will be used. Defaults to None.</p> <code>None</code> <code>agg_method</code> <code>Literal['median', 'mean', 'sum']</code> <p>Aggregation method for quantification to use. Defaults to \"median\".</p> <code>'median'</code> <code>calculate_q</code> <code>bool</code> <p>Whether to calculate q-values. Defaults to True.</p> <code>True</code> <code>score_method</code> <code>Literal['best_pep']</code> <p>Method to combine scores. Defaults to \"best_pep\".</p> <code>'best_pep'</code> <code>purity_threshold</code> <code>float | None</code> <p>Purity threshold for TMT data quantification aggregation (does not filter out features). If None, no filtering is applied. Defaults to 0.7.</p> <code>0.7</code> <code>top_n</code> <code>int | None</code> <p>Number of top features to consider for summarisation. If None, all features are used. Defaults to None.</p> <code>None</code> <code>rank_method</code> <code>Literal['total_intensity', 'max_intensity', 'median_intensity']</code> <p>Method to rank features when selecting top_n. Defaults to \"total_intensity\".</p> <code>'total_intensity'</code> <p>Returns:</p> Type Description <code>MuData</code> <p>MuData object containing peptide-level data.</p>"},{"location":"reference/pp/to_protein/","title":"<code>msmu.pp.to_protein</code>","text":"<p>Summarise peptide-level data to protein-level data. By default, uses <code>top 3</code> peptides in their <code>total_intensity</code> and <code>unique</code> (_shared_peptide = \"discard\") per protein_group for quantification aggregation with median.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing Peptide-level data.</p> required <code>layer</code> <code>str | None</code> <p>Layer to use for quantification aggregation. If None, the default layer (.X) will be used. Defaults to None.</p> <code>None</code> <code>agg_method</code> <code>Literal['median', 'mean', 'sum']</code> <p>Aggregation method to use. Defaults to \"median\".</p> <code>'median'</code> <code>calculate_q</code> <code>bool</code> <p>Whether to calculate q-values. Defaults to True.</p> <code>True</code> <code>score_method</code> <code>Literal['best_pep']</code> <p>Method to combine scores (PEP). Defaults to \"best_pep\".</p> <code>'best_pep'</code> <code>top_n</code> <code>int | None</code> <p>Number of top peptides to consider for summarisation. If None, all peptides are used. Defaults to None.</p> <code>3</code> <code>rank_method</code> <code>Literal['total_intensity', 'max_intensity', 'median_intensity']</code> <p>Method to rank features when selecting top_n. Defaults to \"total_intensity\".</p> <code>'total_intensity'</code> <code>_shared_peptide</code> <code>Literal['discard']</code> <p>How to handle shared peptides. Currently only \"discard\" is implemented. Defaults to \"discard\".</p> <code>'discard'</code> <p>Returns:</p> Type Description <code>MuData</code> <p>MuData object containing protein-level data.</p>"},{"location":"reference/pp/to_ptm/","title":"<code>msmu.pp.to_ptm</code>","text":"<p>Summarise peptide-level data to PTM-level data.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing peptide-level data.</p> required <code>modi_name</code> <code>str</code> <p>Name of the PTM to summarise (e.g., \"phospho\"). Will be used in the output modality name (eg. phospho_site).</p> required <code>modification</code> <code>str</code> <p>Modification string (e.g., \"[+79.96633]\", \"(unimod:21)\").</p> required <code>layer</code> <code>str | None</code> <p>Layer to use for quantification aggregation. If None, the default layer (.X) will be used. Defaults to None.</p> <code>None</code> <code>agg_method</code> <code>Literal['median', 'mean', 'sum']</code> <p>Aggregation method to use. Defaults to \"median\".</p> <code>'median'</code> <code>top_n</code> <code>int | None</code> <p>Number of top features to consider for summarisation. If None, all features are used. Defaults to None.</p> <code>None</code> <code>rank_method</code> <code>Literal['total_intensity', 'max_intensity']</code> <p>Method to rank features when selecting top_n. Defaults to \"total_intensity\".</p> <code>'total_intensity'</code> <p>Returns:</p> Name Type Description <code>MuData</code> <code>MuData</code> <p>MuData object containing PTM-level data.</p>"},{"location":"reference/tl/PermTestResult/","title":"<code>msmu.tl.PermTestResult</code>","text":"<p>               Bases: <code>StatTestResult</code></p> <p>Data class to store results from permutation tests in DEA.</p> <p>Attributes:</p> Name Type Description <code>permutation_method</code> <code>Literal['exact', 'randomised'] | None</code> <p>The permutation method used (\"exact\" or \"randomised\").</p> <code>n_permutations</code> <code>int | None</code> <p>Number of permutations performed.</p> <code>fc_pct_1</code> <code>float | None</code> <p>Fold change at the 1st percentile.</p> <code>fc_pct_5</code> <code>float | None</code> <p>Fold change at the 5th percentile.</p>"},{"location":"reference/tl/StatTestResult/","title":"<code>msmu.tl.StatTestResult</code>","text":"<p>Data class to store results from statistical tests in DEA.</p> <p>Attributes:</p> Name Type Description <code>stat_method</code> <code>str</code> <p>The statistical method used.</p> <code>ctrl</code> <code>str | None</code> <p>Name of the control group.</p> <code>expr</code> <code>str | None</code> <p>Name of the experimental group.</p> <code>features</code> <code>Index | ndarray | None</code> <p>List or array of feature names.</p> <code>median_ctrl</code> <code>ndarray | None</code> <p>Median values for the control group.</p> <code>median_expr</code> <code>ndarray | None</code> <p>Median values for the experimental group.</p> <code>pct_ctrl</code> <code>ndarray | None</code> <p>Percentage of non-zero values in the control group.</p> <code>pct_expr</code> <code>ndarray | None</code> <p>Percentage of non-zero values in the experimental group.</p> <code>log2fc</code> <code>ndarray | None</code> <p>Log2 fold change between experimental and control groups.</p> <code>p_value</code> <code>ndarray | None</code> <p>P-values from the statistical test.</p> <code>q_value</code> <code>ndarray | None</code> <p>Adjusted p-values (q-values) after multiple testing correction.</p> <p>Methods:</p> Name Description <code>to_df</code> <p>Convert the results to a pandas DataFrame.</p> <code>plot_volcano</code> <p>Plot a volcano plot of the DEA results.</p>"},{"location":"reference/tl/StatTestResult/#msmu.tl.StatTestResult.plot_volcano","title":"plot_volcano","text":"<pre><code>plot_volcano(log2fc_threshold=None, pval_threshold=0.05, label_top=None)\n</code></pre> <p>Plots a volcano plot for the DEA results.</p> <p>Parameters:</p> Name Type Description Default <code>log2fc_threshold</code> <code>float | None</code> <p>Log2 fold change threshold for significance. If None, uses the 5th percentile fold change from permutation test results.</p> <code>None</code> <code>pval_threshold</code> <code>float</code> <p>p-value threshold for significance.</p> <code>0.05</code> <code>label_top</code> <code>int | None</code> <p>Number of top significant features to label on the plot. If None, no labels are added.</p> <code>None</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Plotly Figure object containing the volcano plot.</p>"},{"location":"reference/tl/compute_precursor_isolation_purity/","title":"<code>msmu.tl.compute_precursor_isolation_purity</code>","text":"<p>Calculate precursor isolation purity for PSMs in the given MuData object and mzML file.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing PSM data.</p> required <code>mzml_paths</code> <code>str | Path | list</code> <p>Full path(s) to the mzML file.</p> required <code>tolerance</code> <code>float</code> <p>Tolerance for precursor purity calculation. Default is 20.</p> <code>20.0</code> <code>unit_ppm</code> <code>bool</code> <p>Whether to use ppm for tolerance. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>MuData</code> <p>md.MuData: MuData object containing purity results.</p>"},{"location":"reference/tl/compute_precursor_isolation_purity_from_mzml/","title":"<code>msmu.tl.compute_precursor_isolation_purity_from_mzml</code>","text":"<p>Calculate precursor isolation purity for all MS2 scans in the given mzML file.</p> <p>Parameters:</p> Name Type Description Default <code>mzml_paths</code> <code>str | Path | list</code> <p>Full path(s) to the mzML file.</p> required <code>tolerance</code> <code>float</code> <p>Tolerance for precursor purity calculation.</p> <code>20.0</code> <code>unit_ppm</code> <code>bool</code> <p>Whether to use ppm for tolerance.</p> <code>True</code> <p>Returns:</p> Type Description <code>PurityResult</code> <p>pd.DataFrame: DataFrame with scan numbers and their corresponding purity scores.</p>"},{"location":"reference/tl/pca/","title":"<code>msmu.tl.pca</code>","text":"<p>Perform Principal Component Analysis (PCA) on the specified modality of the MuData object.</p> <ul> <li>Repository</li> <li>Documentation</li> </ul> References <p>Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., ... &amp; Duchesnay, E. (2011). Scikit-learn: Machine learning in Python. Journal of machine learning research, 12(Oct), 2825-2830.</p> <p>Andrzej M., Waldemar R. (1993). Principal Component Analysis (PCA). Computers &amp; Geosciences, 19(3), 303-342.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the data.</p> required <code>modality</code> <code>str</code> <p>The modality to perform PCA on.</p> required <code>layer</code> <code>str | None</code> <p>Layer to use for quantification aggregation. If None, the default layer (.X) will be used. Defaults to \"scaled\".</p> <code>'scaled'</code> <code>n_components</code> <code>int | None</code> <p>Number of components to keep. if n_components is not set all components are kept::</p> <pre><code>n_components == min(n_samples, n_features)\n</code></pre> <p>If <code>n_components == 'mle'</code> and <code>svd_solver == 'full'</code>, Minka's MLE is used to guess the dimension. Use of <code>n_components == 'mle'</code> will interpret <code>svd_solver == 'auto'</code> as <code>svd_solver == 'full'</code>.</p> <p>If <code>0 &lt; n_components &lt; 1</code> and <code>svd_solver == 'full'</code>, select the number of components such that the amount of variance that needs to be explained is greater than the percentage specified by n_components.</p> <p>If <code>svd_solver == 'arpack'</code>, the number of components must be strictly less than the minimum of n_features and n_samples.</p> <p>Hence, the None case results in:</p> <pre><code>n_components == min(n_samples, n_features) - 1\n</code></pre> <code>None</code> <code>svd_solver</code> <code>Literal['auto', 'full', 'arpack', 'randomized']</code> <p>\"auto\":     The solver is selected by a default 'auto' policy is based on <code>X.shape</code> and     <code>n_components</code>: if the input data has fewer than 1000 features and     more than 10 times as many samples, then the \"covariance_eigh\"     solver is used. Otherwise, if the input data is larger than 500x500     and the number of components to extract is lower than 80% of the     smallest dimension of the data, then the more efficient     \"randomized\" method is selected. Otherwise the exact \"full\" SVD is     computed and optionally truncated afterwards.</p> <p>\"full\" :     Run exact full SVD calling the standard LAPACK solver via     <code>scipy.linalg.svd</code> and select the components by postprocessing</p> <p>\"arpack\" :     Run SVD truncated to <code>n_components</code> calling ARPACK solver via     <code>scipy.sparse.linalg.svds</code>. It requires strictly     <code>0 &lt; n_components &lt; min(X.shape)</code></p> <p>\"randomized\" :     Run randomized SVD by the method of Halko et al.</p> <code>'auto'</code> <code>random_state</code> <code>int | None</code> <p>Used when the 'arpack' or 'randomized' solvers are used. Pass an int for reproducible results across multiple function calls.</p> <code>0</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to PCA constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>MuData</code> <p>Updated MuData object with PCA results.</p>"},{"location":"reference/tl/run_de/","title":"<code>msmu.tl.run_de</code>","text":"<p>Run Differential Expression Analysis (DEA) between two groups in a MuData object.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the data.</p> required <code>modality</code> <code>str</code> <p>Modality name within the MuData to analyze.</p> required <code>category</code> <code>str</code> <p>Observation category to define groups.</p> required <code>ctrl</code> <code>str</code> <p>Name of the control group.</p> required <code>expr</code> <code>str | None</code> <p>Name of the experimental group. If None, all other groups are used.</p> <code>None</code> <code>layer</code> <code>str | None</code> <p>Layer to use for quantification aggregation. If None, the default layer (.X) will be used. Defaults to None.</p> <code>None</code> <code>statistic</code> <p>Statistical test to use (\"welch\", \"student\", \"wilcoxon\", \"med_diff\", \"limma\").</p> required <code>n_resamples</code> <code>int | None</code> <p>Number of resamples for permutation test. If None, no permutation test is performed.</p> <code>1000</code> <code>fdr</code> <code>bool | Literal['empirical', 'bh', 'storey']</code> <p>Method for multiple test correction (\"empirical\", \"bh\", \"storey\", or False).</p> <code>'empirical'</code> <code>n_jobs</code> <code>int</code> <p>Number of parallel jobs to use.</p> <code>1</code> <code>_force_resample</code> <code>bool</code> <p>If True, forces resampling even if the number of resamples exceeds the number of combinations.</p> <code>False</code> <p>Returns:</p> Type Description <code>PermTestResult | StatTestResult</code> <p>PermTestResult or StatTestResult containing DEA results.</p>"},{"location":"reference/tl/umap/","title":"<code>msmu.tl.umap</code>","text":"<p>Calculate UMAP embedding for a given modality in MuData object.</p> <ul> <li>Repository</li> <li>Documentation</li> </ul> References <p>McInnes, L., Healy, J., &amp; Melville, J. (2018). UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction. arXiv preprint arXiv:1802.03426.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the data.</p> required <code>modality</code> <code>str</code> <p>The modality to perform UMAP on.</p> required <code>n_components</code> <code>int</code> <p>The dimension of the space to embed into. This defaults to 2 to provide easy visualization, but can reasonably be set to any integer value in the range 2 to 100.</p> <code>2</code> <code>n_neighbors</code> <code>int | None</code> <p>The size of local neighborhood (in terms of number of neighboring sample points) used for manifold approximation. Larger values result in more global views of the manifold, while smaller values result in more local data being preserved. In general values should be in the range 2 to 100.</p> <code>15</code> <code>layer</code> <code>str | None</code> <p>Layer to use for quantification aggregation. If None, the default layer (.X) will be used. Defaults to None.</p> <code>None</code> <code>metric</code> <code>str</code> <p>The metric to use to compute distances in high dimensional space. If a string is passed it must match a valid predefined metric. If a general metric is required a function that takes two 1d arrays and returns a float can be provided. For performance purposes it is required that this be a numba jit'd function. Valid string metrics include:</p> <ul> <li>euclidean</li> <li>manhattan</li> <li>chebyshev</li> <li>minkowski</li> <li>canberra</li> <li>braycurtis</li> <li>mahalanobis</li> <li>wminkowski</li> <li>seuclidean</li> <li>cosine</li> <li>correlation</li> <li>haversine</li> <li>hamming</li> <li>jaccard</li> <li>dice</li> <li>russelrao</li> <li>kulsinski</li> <li>ll_dirichlet</li> <li>hellinger</li> <li>rogerstanimoto</li> <li>sokalmichener</li> <li>sokalsneath</li> <li>yule</li> </ul> <p>Metrics that take arguments (such as minkowski, mahalanobis etc.) can have arguments passed via the metric_kwds dictionary. At this time care must be taken and dictionary elements must be ordered appropriately; this will hopefully be fixed in the future.</p> <code>'euclidean'</code> <code>init</code> <code>str</code> <p>How to initialize the low dimensional embedding. Options are:</p> <ul> <li>'spectral': use a spectral embedding of the fuzzy 1-skeleton</li> <li>'random': assign initial embedding positions at random.</li> <li>'pca': use the first n_components from PCA applied to the     input data.</li> <li>'tswspectral': use a spectral embedding of the fuzzy     1-skeleton, using a truncated singular value decomposition to     \"warm\" up the eigensolver. This is intended as an alternative     to the 'spectral' method, if that takes an  excessively long     time to complete initialization (or fails to complete).</li> <li>A numpy array of initial embedding positions.</li> </ul> <code>'random'</code> <code>min_dist</code> <code>float</code> <p>The effective minimum distance between embedded points. Smaller values will result in a more clustered/clumped embedding where nearby points on the manifold are drawn closer together, while larger values will result on a more even dispersal of points. The value should be set relative to the <code>spread</code> value, which determines the scale at which embedded points will be spread out.</p> <code>0.1</code> <code>random_state</code> <code>int | None</code> <p>RandomState instance or None, optional (default: None) If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by <code>np.random</code>.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to UMAP constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>MuData</code> <p>Updated MuData object with UMAP results.</p>"},{"location":"reference/utils/add_quant/","title":"<code>msmu.utils.add_quant</code>","text":"<p>Add quantification data to the MuData object as a new modality.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>The MuData object to which the quantification data will be added.</p> required <code>quant_data</code> <code>str | DataFrame</code> <p>The quantification data, either as a file path or a DataFrame.</p> required <code>quant_tool</code> <code>str</code> <p>The tool used for quantification (e.g., \"flashlfq\").</p> required <code>index_name</code> <code>str | None</code> <p>Optional; the name of the index column in the quantification data (when changed obs.index with reindex_obs function). default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>MuData</code> <p>The modified MuData object with the added quantification modality.</p>"},{"location":"reference/utils/attach_fasta/","title":"<code>msmu.utils.attach_fasta</code>","text":"<p>Attach FASTA metadata to the MuData object.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object to attach FASTA metadata to.</p> required <code>fasta_file</code> <code>str | None</code> <p>Path to the FASTA file. If None, fetch from UniProt (not implemented).</p> required <p>Returns:</p> Type Description <code>MuData</code> <p>MuData object with attached FASTA metadata.</p>"},{"location":"reference/utils/get_label/","title":"<code>msmu.utils.get_label</code>","text":""},{"location":"reference/utils/get_modality_dict/","title":"<code>msmu.utils.get_modality_dict</code>","text":"<p>Get modality data from MuData object</p>"},{"location":"reference/utils/map_fasta/","title":"<code>msmu.utils.map_fasta</code>","text":"<p>Map protein groups to gene names using a FASTA metadata DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <p>MuData object containing the modality to map.</p> required <code>modality</code> <code>str</code> <p>The modality in the MuData object to map.</p> required <code>categories</code> <code>list[str]</code> <p>List of categories to map from fasta metadata.</p> <code>['Protein ID', 'Gene', 'Description', 'Organism']</code> <p>Returns:</p> Type Description <code>MuData</code> <p>MuData object with updated modality var.</p>"},{"location":"reference/utils/parse_uniprot_accession/","title":"<code>msmu.utils.parse_uniprot_accession</code>","text":""},{"location":"reference/utils/reindex_obs/","title":"<code>msmu.utils.reindex_obs</code>","text":"<p>Reindex the observation (obs) of the MuData object to ensure consistency across modalities.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>The MuData object containing the observations to reindex.</p> required <code>column</code> <code>str</code> <p>The column name in mdata.obs to use for reindexing.</p> required <p>Returns:</p> Type Description <code>MuData</code> <p>md.MuData: The modified MuData object with reindexed observations.</p>"},{"location":"reference/utils/select_repr_protein/","title":"<code>msmu.utils.select_repr_protein</code>","text":"<p>Select canonical protein from protein list based on priority. canonical &gt; swissprot &gt; trembl &gt; contam</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object with protein groups inferred</p> required <code>modality</code> <p>Modality name for protein data</p> required <p>Returns:</p> Type Description <code>MuData</code> <p>MuData object with representative proteins selected</p>"},{"location":"reference/utils/split_tmt/","title":"<code>msmu.utils.split_tmt</code>","text":"<p>Split TMT channels in a MuData object into separate modalities based on a mapping.</p>"},{"location":"reference/utils/split_tmt/#msmu.utils.split_tmt--parameters","title":"Parameters","text":"<p>mdata : MuData     The MuData object containing TMT data. map : dict[str, str] | pd.Series | pd.DataFrame     A mapping of filenames to set names. If a DataFrame is provided, it should have two columns: the first for filenames and the second for set names.</p>"},{"location":"reference/utils/split_tmt/#msmu.utils.split_tmt--returns","title":"Returns","text":"<p>MuData     The modified MuData object with TMT channels split into separate modalities.</p>"},{"location":"reference/utils/subset/","title":"<code>msmu.utils.subset</code>","text":""},{"location":"reference/utils/subset/#msmu.utils.subset.split_tmt","title":"split_tmt","text":"<pre><code>split_tmt(mdata, map)\n</code></pre> <p>Split TMT channels in a MuData object into separate modalities based on a mapping.</p>"},{"location":"reference/utils/subset/#msmu.utils.subset.split_tmt--parameters","title":"Parameters","text":"<p>mdata : MuData     The MuData object containing TMT data. map : dict[str, str] | pd.Series | pd.DataFrame     A mapping of filenames to set names. If a DataFrame is provided, it should have two columns: the first for filenames and the second for set names.</p>"},{"location":"reference/utils/subset/#msmu.utils.subset.split_tmt--returns","title":"Returns","text":"<p>MuData     The modified MuData object with TMT channels split into separate modalities.</p>"},{"location":"reference/utils/subset/#msmu.utils.subset.subset","title":"subset","text":"<pre><code>subset(mdata, modality, cond_var=None, cond_obs=None)\n</code></pre> <p>Subset MuData object based on condition.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object to subset.</p> required <code>modality</code> <code>str</code> <p>Modality to subset.</p> required <code>cond_var</code> <code>str</code> <p>Condition to subset variables.</p> <code>None</code> <code>cond_obs</code> <code>str</code> <p>Condition to subset observations.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>mdata</code> <code>MuData</code> <p>Subsetted MuData object.</p>"},{"location":"reference/utils/uns_logger/","title":"<code>msmu.utils.uns_logger</code>","text":""},{"location":"tutorials/dda-lfq/","title":"DDA-LFQ","text":"In\u00a0[1]: Copied! <pre>base_dir = \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/dev/data/sage_lfq\"\nsage_idents = f\"{base_dir}/sage/results.sage.tsv\"\nsage_quants = f\"{base_dir}/sage/lfq.tsv\"\nmeta = f\"{base_dir}/meta.csv\"\n</pre> base_dir = \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/dev/data/sage_lfq\" sage_idents = f\"{base_dir}/sage/results.sage.tsv\" sage_quants = f\"{base_dir}/sage/lfq.tsv\" meta = f\"{base_dir}/meta.csv\" In\u00a0[2]: Copied! <pre>import msmu as mm\nimport pandas as pd\nimport plotly.io as pio\n\npio.renderers.default = \"png\"\n</pre> import msmu as mm import pandas as pd import plotly.io as pio  pio.renderers.default = \"png\" <pre>Determination of memory status is not supported on this \n platform, measuring for memoryleaks will never fail\n</pre> In\u00a0[3]: Copied! <pre># Sage format\nmdata = mm.read_sage(identification_file=sage_idents, quantification_file=sage_quants, label=\"label_free\")\n\n# MaxQuant format\n# mdata = mm.read_maxquant(identification_file=\"path_to_maxquant_output\", label=\"label_free\", acquisition=\"dda\")\n\n# FragPipe format\n# mdata = mm.read_fragpipe(identification_file=\"path_to_fragpipe_output\", label=\"label_free\", acquisition=\"dda\")\n</pre> # Sage format mdata = mm.read_sage(identification_file=sage_idents, quantification_file=sage_quants, label=\"label_free\")  # MaxQuant format # mdata = mm.read_maxquant(identification_file=\"path_to_maxquant_output\", label=\"label_free\", acquisition=\"dda\")  # FragPipe format # mdata = mm.read_fragpipe(identification_file=\"path_to_fragpipe_output\", label=\"label_free\", acquisition=\"dda\") <pre>INFO - Identification file loaded: (5000, 40)\nINFO - Quantification file loaded: (3578, 12)\nINFO - Decoy entries separated: (345, 13)\n</pre> In\u00a0[4]: Copied! <pre>mdata\n</pre> mdata Out[4]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 8233\n  2 modalities\n    psm:\t6 x 4655\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy'\n      varm:\t'search_result'\n    peptide:\t6 x 3578\n      uns:\t'level'</pre> In\u00a0[5]: Copied! <pre>meta_df = pd.read_csv(\"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/dev/data/sage_lfq/meta.csv\")\nmeta_df = meta_df.set_index(\"sample_id\")  # set the index to match sample id in mdata.obs\n\nmdata.obs = mdata.obs.join(meta_df)\nmdata.push_obs()  # update all modalities with the new obs data\nmdata.obs\n</pre> meta_df = pd.read_csv(\"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/dev/data/sage_lfq/meta.csv\") meta_df = meta_df.set_index(\"sample_id\")  # set the index to match sample id in mdata.obs  mdata.obs = mdata.obs.join(meta_df) mdata.push_obs()  # update all modalities with the new obs data mdata.obs Out[5]: set sample_name condition replicate QExHF04026 S1 G1-1 G1 1 QExHF04028 S1 G2-1 G2 1 QExHF04036 S1 G1-2 G1 2 QExHF04038 S1 G2-2 G2 2 QExHF04046 S1 G1-3 G1 3 QExHF04048 S1 G2-3 G2 3 In\u00a0[6]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\")\nmdata = mm.pp.apply_filter(mdata, modality=\"psm\")\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\") mdata = mm.pp.apply_filter(mdata, modality=\"psm\")  mdata Out[6]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 7837\n  obs:\t'set', 'sample_name', 'condition', 'replicate'\n  uns:\t'_cmd'\n  2 modalities\n    psm:\t6 x 4259\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t6 x 3578\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      uns:\t'level'</pre> In\u00a0[7]: Copied! <pre>mdata = mm.pp.to_peptide(mdata)\n</pre> mdata = mm.pp.to_peptide(mdata) <pre>INFO - Peptide-level identifications: 3634 (3615 at 1% FDR)\n</pre> <pre>Using existing peptide quantification data.\n</pre> In\u00a0[8]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"peptide\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"peptide\")\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"peptide\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"peptide\")  mdata Out[8]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 7874\n  obs:\t'set', 'sample_name', 'condition', 'replicate'\n  uns:\t'_cmd'\n  2 modalities\n    psm:\t6 x 4259\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t6 x 3615\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'</pre> In\u00a0[9]: Copied! <pre>mdata = mm.pp.log2_transform(mdata, modality=\"peptide\")\nmdata = mm.pp.normalise(mdata, modality=\"peptide\", method=\"median\")\n</pre> mdata = mm.pp.log2_transform(mdata, modality=\"peptide\") mdata = mm.pp.normalise(mdata, modality=\"peptide\", method=\"median\") In\u00a0[10]: Copied! <pre>mdata = mm.pp.infer_protein(mdata)\n</pre> mdata = mm.pp.infer_protein(mdata) <pre>INFO - Starting protein inference\nINFO - Initial proteins: 3651\nINFO - Removed indistinguishable: 1586\nINFO - Removed subsettable: 539\nINFO - Removed subsumable: 2\nINFO - Total protein groups: 1524\n</pre> In\u00a0[11]: Copied! <pre>mdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"total_intensity\")\n</pre> mdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"total_intensity\") <pre>INFO - Ranking features by 'total_intensity' to select top 3 features.\nINFO - Protein-level identifications :  1489 (1463 at 1% FDR)\n</pre> In\u00a0[12]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"protein\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"protein\")\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"protein\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"protein\")  mdata Out[12]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 9337\n  obs:\t'set', 'sample_name', 'condition', 'replicate'\n  uns:\t'_cmd'\n  3 modalities\n    psm:\t6 x 4259\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t6 x 3615\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value', 'protein_group', 'peptide_type'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'\n    protein:\t6 x 1463\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'count_psm', 'count_stripped_peptide', 'PEP', 'q_value'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'</pre> In\u00a0[13]: Copied! <pre>mm.pl.plot_id(mdata, modality=\"protein\", colorby=\"condition\", obs_column=\"sample_name\")\n</pre> mm.pl.plot_id(mdata, modality=\"protein\", colorby=\"condition\", obs_column=\"sample_name\") In\u00a0[14]: Copied! <pre>mm.pl.plot_intensity(mdata, modality=\"protein\", groupby=\"condition\", obs_column=\"sample_name\")\n</pre> mm.pl.plot_intensity(mdata, modality=\"protein\", groupby=\"condition\", obs_column=\"sample_name\") In\u00a0[15]: Copied! <pre>mdata.write_h5mu(\"dda_lfq_PXD012986.h5mu\")\n</pre> mdata.write_h5mu(\"dda_lfq_PXD012986.h5mu\")"},{"location":"tutorials/dda-lfq/#dda-label-free","title":"DDA - Label-Free\u00b6","text":"<p>This tutorial demonstrates how to analyze label-free quantification (LFQ) data using the <code>msmu</code> package.</p>"},{"location":"tutorials/dda-lfq/#data-preparation","title":"Data Preparation\u00b6","text":"<p>Original dataset is from PXD012986 (Uszkoreit et al., 2022) and search was performed with <code>Sage</code> v0.14.7.</p> <p>For demonstration purposes, the example dataset was reduced to six samples and a total of 5,000 PSMs.</p>"},{"location":"tutorials/dda-lfq/#load-required-packages","title":"Load Required Packages\u00b6","text":"<p>If you haven't installed the <code>msmu</code> package yet, please follow the installation guide.</p>"},{"location":"tutorials/dda-lfq/#read-data","title":"Read Data\u00b6","text":"<p>You can read data from various proteomics software outputs. Below are examples for <code>Sage</code>, <code>MaxQuant</code>, and <code>FragPipe</code> formats.</p> <p>For this tutorial, we will use the <code>Sage</code> output as an example.</p> <p><code>read_sage()</code> function reads the <code>Sage</code> output files (<code>lfq.tsv</code>, <code>results.sage.tsv</code>) and creates modalities at Mudata object.</p>"},{"location":"tutorials/dda-lfq/#adding-metadata","title":"Adding Metadata\u00b6","text":"<p>Optionally, you can add metadata for samples to the <code>mdata.obs</code> dataframe. Make sure that the index of the metadata dataframe matches the sample names in <code>mdata.obs</code>.</p>"},{"location":"tutorials/dda-lfq/#handling-psm-level","title":"Handling PSM level\u00b6","text":""},{"location":"tutorials/dda-lfq/#filtering-psm","title":"Filtering - PSM\u00b6","text":"<p>You can filter the data based on the column values, such as q-value. You can also filter the data based on string containment, which can be useful for removing contaminants or decoys.</p> <p>Filtering is split into two steps: first, you mark a filter condition using <code>mm.pp.add_filter()</code>, and then you apply the filter using <code>mm.pp.apply_filter()</code>.</p> <p>Here, we keep protein groups with q-value &lt; 0.01 and remove contaminants (protein IDs containing \"contam_\").</p>"},{"location":"tutorials/dda-lfq/#handling-peptide-level","title":"Handling peptide level\u00b6","text":""},{"location":"tutorials/dda-lfq/#summarisation-peptide","title":"Summarisation - peptide\u00b6","text":"<p>You can summarise psm-level data to peptide-level data using the <code>mm.pp.to_peptide()</code> function.</p>"},{"location":"tutorials/dda-lfq/#filtering-peptide","title":"Filtering - peptide\u00b6","text":""},{"location":"tutorials/dda-lfq/#normalisation","title":"Normalisation\u00b6","text":"<p>Here, we log2 transform and normalise the data at the peptide level.</p> <p>Median centering normalisation is applied using <code>mm.pp.normalise()</code> function.</p>"},{"location":"tutorials/dda-lfq/#protein-inference","title":"Protein inference\u00b6","text":"<p>You can infer protein-level data from peptide-level data using the <code>mm.pp.infer_protein()</code> function.</p>"},{"location":"tutorials/dda-lfq/#handling-protein-level","title":"Handling protein level\u00b6","text":""},{"location":"tutorials/dda-lfq/#summarisation-protein","title":"Summarisation - protein\u00b6","text":"<p>You can summarise peptide-level data to protein-level data using the <code>mm.pp.to_protein()</code> function.</p> <p>As default, top 3 peptides wihin protein group can be used for protein group quantification aggregation. If top_n is None, all peptides will be used.</p>"},{"location":"tutorials/dda-lfq/#filtering-protein","title":"Filtering - protein\u00b6","text":""},{"location":"tutorials/dda-lfq/#visualisation","title":"Visualisation\u00b6","text":""},{"location":"tutorials/dda-lfq/#id-plot","title":"ID plot\u00b6","text":""},{"location":"tutorials/dda-lfq/#intensity-distribution-plot","title":"Intensity distribution plot\u00b6","text":""},{"location":"tutorials/dda-lfq/#save-data","title":"Save Data\u00b6","text":"<p>You can save MuData object into an H5MU file.</p>"},{"location":"tutorials/dda-lfq/#citation","title":"Citation\u00b6","text":"<p>Uszkoreit, J., Barkovits, K., Pacharra, S., Pfeiffer, K., Steinbach, S., Marcus, K., &amp; Eisenacher, M. (2022). Dataset containing physiological amounts of spike-in proteins into murine C2C12 background as a ground truth quantitative LC-MS/MS reference. Data in Brief, 43, 108435.</p> <p>Lazear, M. R. (2023). Sage: an open-source tool for fast proteomics searching and quantification at scale. Journal of Proteome Research, 22(11), 3652-3659.</p>"},{"location":"tutorials/dda-tmt/","title":"DDA-TMT","text":"In\u00a0[1]: Copied! <pre>base_dir = \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/dev/data/sage_tmt\"\nsage_idents = f\"{base_dir}/sage/results.sage.tsv\"\nsage_quants = f\"{base_dir}/sage/tmt.tsv\"\nmeta = f\"{base_dir}/meta.csv\"\n</pre> base_dir = \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/dev/data/sage_tmt\" sage_idents = f\"{base_dir}/sage/results.sage.tsv\" sage_quants = f\"{base_dir}/sage/tmt.tsv\" meta = f\"{base_dir}/meta.csv\" In\u00a0[2]: Copied! <pre>import msmu as mm\nimport pandas as pd\nimport plotly.io as pio\n\npio.renderers.default = \"png\"\n</pre> import msmu as mm import pandas as pd import plotly.io as pio  pio.renderers.default = \"png\" <pre>Determination of memory status is not supported on this \n platform, measuring for memoryleaks will never fail\n</pre> In\u00a0[3]: Copied! <pre># Sage format\nmdata = mm.read_sage(identification_file=sage_idents, quantification_file=sage_quants, label=\"tmt\")\n\n# MaxQuant format\n# mdata = mm.read_maxquant(identification_file=\"path_to_maxquant_output\", label=\"tmt\", acquisition=\"dda\")\n\n# FragPipe format\n# mdata = mm.read_fragpipe(identification_file=\"path_to_fragpipe_output\", label=\"tmt\", acquisition=\"dda\")\n</pre> # Sage format mdata = mm.read_sage(identification_file=sage_idents, quantification_file=sage_quants, label=\"tmt\")  # MaxQuant format # mdata = mm.read_maxquant(identification_file=\"path_to_maxquant_output\", label=\"tmt\", acquisition=\"dda\")  # FragPipe format # mdata = mm.read_fragpipe(identification_file=\"path_to_fragpipe_output\", label=\"tmt\", acquisition=\"dda\") <pre>INFO - Identification file loaded: (5000, 40)\nINFO - Quantification file loaded: (5000, 9)\nINFO - Decoy entries separated: (1195, 13)\n</pre> In\u00a0[4]: Copied! <pre>mdata\n</pre> mdata Out[4]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 3805\n  1 modality\n    psm:\t6 x 3805\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy'\n      varm:\t'search_result'</pre> In\u00a0[5]: Copied! <pre>meta_df = pd.read_csv(meta, dtype=str)\nmeta_df = meta_df.set_index(\"tag\")  # set the index to match sample id in mdata.obs\n\nmdata.obs = mdata.obs.join(meta_df)\nmdata.push_obs()  # update all modalities with the new obs data\nmdata.obs\n</pre> meta_df = pd.read_csv(meta, dtype=str) meta_df = meta_df.set_index(\"tag\")  # set the index to match sample id in mdata.obs  mdata.obs = mdata.obs.join(meta_df) mdata.push_obs()  # update all modalities with the new obs data mdata.obs Out[5]: set sample_id sample_name condition 126 S1 t0h t0h t0 127 S1 t1h t1h t1 128 S1 t2h t2h t2 129 S1 t6h t6h t6 130 S1 t24h t24h t24 131 S1 t120h t120h t120 In\u00a0[6]: Copied! <pre>mdata = mdata[(mdata.obs[\"condition\"] != \"BLANK\"), :]\n</pre> mdata = mdata[(mdata.obs[\"condition\"] != \"BLANK\"), :] In\u00a0[7]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\")\nmdata = mm.pp.apply_filter(mdata, modality=\"psm\")\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\") mdata = mm.pp.apply_filter(mdata, modality=\"psm\")  mdata Out[7]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 2264\n  obs:\t'set', 'sample_id', 'sample_name', 'condition'\n  uns:\t'_cmd'\n  1 modality\n    psm:\t6 x 2264\n      obs:\t'set', 'sample_id', 'sample_name', 'condition'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'</pre> In\u00a0[8]: Copied! <pre>mdata = mm.pp.log2_transform(mdata, modality=\"psm\")\nmdata = mm.pp.normalise(mdata, modality=\"psm\", method=\"median\", fraction=True)\n\n# GIS-based scaling (if needed)\n# mdata = mm.pp.correct_batch_effect(mdata=mdata, modality=\"psm\", method=\"gis\", gis_prefix=\"POOLED_\")\n</pre> mdata = mm.pp.log2_transform(mdata, modality=\"psm\") mdata = mm.pp.normalise(mdata, modality=\"psm\", method=\"median\", fraction=True)  # GIS-based scaling (if needed) # mdata = mm.pp.correct_batch_effect(mdata=mdata, modality=\"psm\", method=\"gis\", gis_prefix=\"POOLED_\") In\u00a0[9]: Copied! <pre># Computing precursor isolation purity\n# mdata = mm.pp.compute_precursor_isolation_purity(mdata, mzml_paths=[\"path/to/sample1.mzML\", \"path/to/sample2.mzML\", ...])\n</pre> # Computing precursor isolation purity # mdata = mm.pp.compute_precursor_isolation_purity(mdata, mzml_paths=[\"path/to/sample1.mzML\", \"path/to/sample2.mzML\", ...]) In\u00a0[10]: Copied! <pre>mdata = mm.pp.to_peptide(mdata, purity_threshold=0.7)\n\n# If precursor purity is computed, filter low-purity features\n# mdata = mm.pp.to_peptide(mdata, purity_threshold=0.7)\n</pre> mdata = mm.pp.to_peptide(mdata, purity_threshold=0.7)  # If precursor purity is computed, filter low-purity features # mdata = mm.pp.to_peptide(mdata, purity_threshold=0.7) <pre>WARNING - Purity column not found in psm modality for TMT data. Skipping purity filtering.\nINFO - Peptide-level identifications: 2204 (2151 at 1% FDR)\n</pre> <pre>Building new peptide quantification data.\n</pre> In\u00a0[11]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"peptide\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"peptide\")\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"peptide\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"peptide\")  mdata Out[11]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 4415\n  obs:\t'set', 'sample_id', 'sample_name', 'condition'\n  uns:\t'_cmd'\n  2 modalities\n    psm:\t6 x 2264\n      obs:\t'set', 'sample_id', 'sample_name', 'condition'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t6 x 2151\n      obs:\t'set', 'sample_id', 'sample_name', 'condition'\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'</pre> In\u00a0[12]: Copied! <pre>mdata = mm.pp.infer_protein(mdata)\n</pre> mdata = mm.pp.infer_protein(mdata) <pre>INFO - Starting protein inference\nINFO - Initial proteins: 1722\nINFO - Removed indistinguishable: 175\nINFO - Removed subsettable: 62\nINFO - Removed subsumable: 0\nINFO - Total protein groups: 1485\n</pre> In\u00a0[13]: Copied! <pre>mdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"total_intensity\")\n</pre> mdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"total_intensity\") <pre>INFO - Ranking features by 'total_intensity' to select top 3 features.\nINFO - Protein-level identifications :  1465 (1432 at 1% FDR)\n</pre> In\u00a0[14]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"protein\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"protein\")\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"protein\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"protein\")  mdata Out[14]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 5847\n  obs:\t'set', 'sample_id', 'sample_name', 'condition'\n  uns:\t'_cmd'\n  3 modalities\n    psm:\t6 x 2264\n      obs:\t'set', 'sample_id', 'sample_name', 'condition'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t6 x 2151\n      obs:\t'set', 'sample_id', 'sample_name', 'condition'\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value', 'protein_group', 'peptide_type'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'\n    protein:\t6 x 1432\n      obs:\t'set', 'sample_id', 'sample_name', 'condition'\n      var:\t'count_psm', 'count_stripped_peptide', 'PEP', 'q_value'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'</pre> In\u00a0[15]: Copied! <pre>mm.pl.plot_id(mdata, modality=\"protein\", obs_column=\"sample_name\")\n</pre> mm.pl.plot_id(mdata, modality=\"protein\", obs_column=\"sample_name\") In\u00a0[16]: Copied! <pre>mm.pl.plot_intensity(mdata, modality=\"protein\", groupby=\"condition\", obs_column=\"sample_name\")\n</pre> mm.pl.plot_intensity(mdata, modality=\"protein\", groupby=\"condition\", obs_column=\"sample_name\") In\u00a0[17]: Copied! <pre>mdata.write_h5mu(\"dda_tmt_PXD013361.h5mu\")\n</pre> mdata.write_h5mu(\"dda_tmt_PXD013361.h5mu\")"},{"location":"tutorials/dda-tmt/#dda-tmt","title":"DDA - TMT\u00b6","text":"<p>This tutorial demonstrates how to analyze Tandem Mass Tag (TMT) labeled proteomics data using <code>msmu</code> package.</p>"},{"location":"tutorials/dda-tmt/#data-preparation","title":"Data Preparation\u00b6","text":"<p>Original dataset is from PXD013361 (Magnusson et al., 2019) and the search was performed with <code>Sage</code> v0.14.7.</p> <p>For demonstration purposes, the example dataset has been trimmed to include only 5,000 PSMs.</p>"},{"location":"tutorials/dda-tmt/#load-required-packages","title":"Load Required Packages\u00b6","text":"<p>If you haven't installed the <code>msmu</code> package yet, please follow the installation guide.</p>"},{"location":"tutorials/dda-tmt/#read-data","title":"Read Data\u00b6","text":"<p>You can read data from various proteomics software outputs. Below are examples for <code>Sage</code>, <code>MaxQuant</code>, and <code>FragPipe</code> formats.</p> <p>For this tutorial, we will use the <code>Sage</code> output as an example.</p> <p><code>read_sage()</code> function reads the <code>Sage</code> output files (<code>tmt.tsv</code>, <code>results.sage.tsv</code>) and creates modalities at Mudata object.</p>"},{"location":"tutorials/dda-tmt/#adding-metadata","title":"Adding Metadata\u00b6","text":"<p>Optionally, you can add metadata for samples to the <code>mdata.obs</code> dataframe. Make sure that the index of the metadata dataframe matches the sample names in <code>mdata.obs</code>.</p>"},{"location":"tutorials/dda-tmt/#removing-blank-channels","title":"Removing Blank Channels\u00b6","text":"<p>If your TMT data contains blank channels, you can remove them by subsetting <code>MuData</code> object.</p>"},{"location":"tutorials/dda-tmt/#handling-psm-level","title":"Handling PSM level\u00b6","text":""},{"location":"tutorials/dda-tmt/#filtering-psm","title":"Filtering - PSM\u00b6","text":"<p>You can filter the data based on the column values, such as q-value. You can also filter the data based on string containment, which can be useful for removing contaminants or decoys.</p> <p>Filtering is split into two steps: first, you mark a filter condition using <code>mm.pp.add_filter()</code>, and then you apply the filter using <code>mm.pp.apply_filter()</code>.</p> <p>Here, we keep protein groups with q-value &lt; 0.01 and remove contaminants (protein IDs containing \"contam_\").</p>"},{"location":"tutorials/dda-tmt/#normalisation","title":"Normalisation\u00b6","text":"<p>Here, we log2 transform and normalise the data at the PSM level.</p> <p>Median centering normalisation is applied using <code>mm.pp.normalise()</code> function.</p> <p>Optionally, if you need to correct batch effects using Global Internal Standard (GIS) channels, you can scale the data using <code>mm.pp.scale_feature()</code> function. Make sure to have GIS channels in each TMT batch. The example code below assumes that the GIS channels are named with prefix \"POOLED_\".</p>"},{"location":"tutorials/dda-tmt/#computing-precursor-isolation-purity","title":"Computing precursor isolation purity\u00b6","text":"<p>For TMT data, it is recommended to compute precursor isolation purity to exclude low-purity features from quantification aggregation. <code>compute_precursor_isolation_purity()</code> function calculates precursor isolation purity using mzML files.</p> <p>For demonstration purposes, we will skip this step in the tutorial.</p>"},{"location":"tutorials/dda-tmt/#handling-peptide-level","title":"Handling peptide level\u00b6","text":""},{"location":"tutorials/dda-tmt/#summarisation-peptide","title":"Summarisation - peptide\u00b6","text":"<p>You can summarise psm-level data to peptide-level data using the <code>mm.pp.to_peptide()</code> function.</p> <p>If isolation purity was caculated and <code>purity_threshold</code> parameter is set, features below this cutoff are excluded from quantification aggregation.</p>"},{"location":"tutorials/dda-tmt/#filtering-peptide","title":"Filtering - peptide\u00b6","text":""},{"location":"tutorials/dda-tmt/#protein-inference","title":"Protein inference\u00b6","text":"<p>You can infer protein-level data from peptide-level data using the <code>mm.pp.infer_protein()</code> function.</p>"},{"location":"tutorials/dda-tmt/#handling-protein-level","title":"Handling protein level\u00b6","text":""},{"location":"tutorials/dda-tmt/#summarisation-protein","title":"Summarisation - protein\u00b6","text":"<p>You can summarise peptide-level data to protein-level data using the <code>mm.pp.to_protein()</code> function.</p> <p>As default, top 3 peptides wihin protein group can be used for protein group quantification aggregation. If top_n is None, all peptides will be used.</p>"},{"location":"tutorials/dda-tmt/#filtering-protein","title":"Filtering - protein\u00b6","text":""},{"location":"tutorials/dda-tmt/#visualisation","title":"Visualisation\u00b6","text":""},{"location":"tutorials/dda-tmt/#id-plot","title":"ID plot\u00b6","text":""},{"location":"tutorials/dda-tmt/#intensity-distribution-plot","title":"Intensity distribution plot\u00b6","text":""},{"location":"tutorials/dda-tmt/#save-data","title":"Save Data\u00b6","text":"<p>You can save MuData object into an H5MU file.</p>"},{"location":"tutorials/dda-tmt/#citation","title":"Citation\u00b6","text":"<p>Magnusson, R., Rundquist, O., Kim, M. J., Hellberg, S., Na, C. H., Benson, M., ... &amp; Gustafsson, M. (2019). A validated strategy to infer protein biomarkers from RNA-Seq by combining multiple mRNA splice variants and time-delay. BioRxiv, 599373.</p> <p>Lazear, M. R. (2023). Sage: an open-source tool for fast proteomics searching and quantification at scale. Journal of Proteome Research, 22(11), 3652-3659.</p>"},{"location":"tutorials/dea/","title":"DE Analysis","text":"In\u00a0[1]: Copied! <pre>import msmu as mm\n\n# Set default renderer to static image for better compatibility\nimport plotly.io as pio\n\npio.renderers.default = \"png\"\n\nmdata = mm.read_h5mu(\"dda_lfq_PXD012986.h5mu\")\n</pre> import msmu as mm  # Set default renderer to static image for better compatibility import plotly.io as pio  pio.renderers.default = \"png\"  mdata = mm.read_h5mu(\"dda_lfq_PXD012986.h5mu\") <pre>Determination of memory status is not supported on this \n platform, measuring for memoryleaks will never fail\n</pre> In\u00a0[2]: Copied! <pre>de_res = mm.tl.run_de(\n    mdata,\n    modality=\"protein\",\n    category=\"condition\",  # category in .obs to define groups\n    ctrl=\"G1\",  # control group\n    expr=\"G2\",  # experimental group\n    stat_method=\"welch\",  # statistical test method: \"welch\", \"student\", \"wilcoxon\"\n    n_resamples=1000,  # by default, 1000 resamples; if None, simple parametric p-values are computed\n    fdr=\"empirical\",  # multiple testing correction method: \"empirical\", \"bh\", or None, default \"empirical\"\n)\n</pre> de_res = mm.tl.run_de(     mdata,     modality=\"protein\",     category=\"condition\",  # category in .obs to define groups     ctrl=\"G1\",  # control group     expr=\"G2\",  # experimental group     stat_method=\"welch\",  # statistical test method: \"welch\", \"student\", \"wilcoxon\"     n_resamples=1000,  # by default, 1000 resamples; if None, simple parametric p-values are computed     fdr=\"empirical\",  # multiple testing correction method: \"empirical\", \"bh\", or None, default \"empirical\" ) <pre>Running Permutations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 1169.32it/s]\n</pre> <p>Result is stored in <code>PermutationTestResult</code> object. And the object provides few methods to explore the results.</p> In\u00a0[3]: Copied! <pre>de_res\n</pre> de_res Out[3]: <pre>PermTestResult(stat_method='welch', ctrl='G1', expr='G2', features=array(['A0A023T778,G3UZW7,P61327,Q9CQL1',\n       'A0A068CB13,A2QBC3,B2CNX8,B2CNX9,G3XSF9,I6VCW8,P13006',\n       'A0A087WNT1,A0A087WPE4,A0A087WQE6,P83940', ..., 'Q9Z2U0', 'Q9Z2X1',\n       'Q9Z315'], shape=(1463,), dtype=object), median_ctrl=array([23.03245163, 25.0835495 , 25.42064857, ..., 26.58754539,\n       25.65559196, 22.32104683], shape=(1463,)), median_expr=array([23.09072113, 28.7356205 , 25.33166504, ..., 26.36597824,\n       25.99711609, 22.34777641], shape=(1463,)), pct_ctrl=array([100., 100., 100., ..., 100., 100., 100.], shape=(1463,)), pct_expr=array([100., 100., 100., ..., 100., 100., 100.], shape=(1463,)), log2fc=array([ 0.0582695 ,  3.652071  , -0.08898354, ..., -0.22156715,\n        0.34152412,  0.02672958], shape=(1463,)), p_value=array([4.43267461e-01, 1.73653319e-04, 9.70617859e-01, ...,\n       1.88830619e-01, 1.24439968e-01, 8.42670093e-01], shape=(1463,)), q_value=array([0.81257054, 0.07543224, 0.90440009, ..., 0.68354185, 0.63098926,\n       0.88693014], shape=(1463,)), permutation_method='exact', n_permutations=None, fc_pct_1=0.74, fc_pct_5=0.33)</pre> In\u00a0[4]: Copied! <pre>de_res.to_df().head()\n</pre> de_res.to_df().head() Out[4]: features median_ctrl median_expr pct_ctrl pct_expr log2fc p_value q_value 0 A0A023T778,G3UZW7,P61327,Q9CQL1 23.032452 23.090721 100.0 100.0 0.058270 0.443267 0.812571 1 A0A068CB13,A2QBC3,B2CNX8,B2CNX9,G3XSF9,I6VCW8,... 25.083549 28.735620 100.0 100.0 3.652071 0.000174 0.075432 2 A0A087WNT1,A0A087WPE4,A0A087WQE6,P83940 25.420649 25.331665 100.0 100.0 -0.088984 0.970618 0.904400 3 A0A087WNT3,A0A087WNU9,A0A087WP64,A0A087WPE6,A0... NaN NaN 0.0 0.0 NaN NaN NaN 4 A0A087WNY6,A0A087WQA5,A0A087WQX8,A0A087WRP4,A0... 25.827114 25.794582 100.0 100.0 -0.032532 0.821623 0.881836 <p>After permutation test, guidance for log2FC threshold at 5% (or 1%) on two-side tails of null distribution from permutations is also provided.</p> In\u00a0[5]: Copied! <pre>print(f\"Log2FC threshold at 5%: {de_res.fc_pct_5}\")\n</pre> print(f\"Log2FC threshold at 5%: {de_res.fc_pct_5}\") <pre>Log2FC threshold at 5%: 0.33\n</pre> <p>To visualise the DE results, <code>plot_volcano()</code> method is avalilable. Log2FC and p-value thresholds can be set manually or automatically using the <code>fc_pct_5</code> attribute from the result object and p-value of <code>0.05</code>.</p> <p>Top significant features can be labelled using <code>label_top</code> parameter (sorted by log2FC).</p> In\u00a0[6]: Copied! <pre>de_res.plot_volcano()\n</pre> de_res.plot_volcano() In\u00a0[7]: Copied! <pre>de_res.plot_volcano(label_top=3)\n</pre> de_res.plot_volcano(label_top=3)"},{"location":"tutorials/dea/#differential-expression-analysis-dea","title":"Differential Expression Analysis (DEA)\u00b6","text":""},{"location":"tutorials/dea/#load-msmu-and-mdata-to-be-used","title":"Load <code>msmu</code> and mdata to be used.\u00b6","text":"<p>Use mdata processed in tutorials <code>DDA-TMT</code>, <code>DDA-LFQ</code>, or <code>DIA-LFQ</code>. <code>mdata</code> should have a modality to test, in this case, <code>protein</code>.</p> <p>If mdata were saved locally, provide the path to the file in <code>mm.read_h5mu()</code> function.</p> <p>Or <code>mdata</code> object can be loaded from the previous tutorial directly.</p>"},{"location":"tutorials/dea/#run-de-analysis","title":"Run DE analysis\u00b6","text":"<p>Permutation-based DE analysis basically provided by <code>mm.tl.run_de()</code> function. Here, we will compare two conditions, <code>G1</code> and <code>G2</code>, in the <code>condition</code> column of <code>mdata.obs</code>.</p> <p><code>modality</code> specifies which modality to perform DE analysis on. <code>category</code> indicates the column name in <code>mdata.obs</code> that contains the group labels.</p> <p><code>ctrl</code> and <code>expr</code> define the control and experimental groups, respectively.</p> <p><code>stat_method</code> allows you to choose the statistical test method, such as \"welch\", \"student\", or \"wilcoxon\". ]</p> <p><code>n_resamples</code> sets the number of resampling iterations for permutation testing; if set to <code>None</code>, simple parametric p-values are computed.</p> <p><code>fdr</code> specifies the multiple testing correction method, which can be \"empirical\", \"bh\" (Benjamini-Hochberg), or <code>None</code>.</p> <p>More explanation for <code>run_de()</code> can be found in the DE Analysis documentation and the <code>mm.tl.run_de()</code> API reference.</p> <p>In an example below, we assign 1000 resamples, but only 20 permutations are performed because each group has 3 samples and 3 by 3 gives 20 combinations, which is <code>exact</code> test.</p>"},{"location":"tutorials/dia-lfq/","title":"DIA-LFQ","text":"In\u00a0[1]: Copied! <pre>base_dir = \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/dev/data/diann_dia\"\ndiann_idents = f\"{base_dir}/diann/report.parquet\"\nmeta = f\"{base_dir}/meta.csv\"\n</pre> base_dir = \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/dev/data/diann_dia\" diann_idents = f\"{base_dir}/diann/report.parquet\" meta = f\"{base_dir}/meta.csv\" In\u00a0[2]: Copied! <pre>import msmu as mm\nimport pandas as pd\nimport plotly.io as pio\n\npio.renderers.default = \"png\"\n</pre> import msmu as mm import pandas as pd import plotly.io as pio  pio.renderers.default = \"png\" <pre>Determination of memory status is not supported on this \n platform, measuring for memoryleaks will never fail\n</pre> In\u00a0[3]: Copied! <pre># DIA-NN format\nmdata = mm.read_diann(identification_file=diann_idents)\n\n# MaxQuant format\n# mdata = mm.read_maxquant(identification_file=\"path_to_maxquant_output\", label=\"label_free\", acquisition=\"dia\")\n\n# FragPipe format\n# mdata = mm.read_fragpipe(identification_file=\"path_to_fragpipe_output\", label=\"label_free\", acquisition=\"dia\")\n</pre> # DIA-NN format mdata = mm.read_diann(identification_file=diann_idents)  # MaxQuant format # mdata = mm.read_maxquant(identification_file=\"path_to_maxquant_output\", label=\"label_free\", acquisition=\"dia\")  # FragPipe format # mdata = mm.read_fragpipe(identification_file=\"path_to_fragpipe_output\", label=\"label_free\", acquisition=\"dia\") <pre>INFO - Identification file loaded: (5069, 71)\nINFO - Identification and quantification data split: (5069, 73), (5069, 6)\nINFO - Decoy entries separated: (31, 9)\n</pre> In\u00a0[4]: Copied! <pre>mdata\n</pre> mdata Out[4]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 5038\n  1 modality\n    psm:\t6 x 5038\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'charge', 'peptide_length', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy'\n      varm:\t'search_result'</pre> In\u00a0[5]: Copied! <pre>meta_df = pd.read_csv(meta)\nmeta_df = meta_df.set_index(\"sample_id\")  # set the index to match sample id in mdata.obs\n\nmdata.obs = mdata.obs.join(meta_df)\nmdata.push_obs()  # update all modalities with the new obs data\nmdata.obs\n</pre> meta_df = pd.read_csv(meta) meta_df = meta_df.set_index(\"sample_id\")  # set the index to match sample id in mdata.obs  mdata.obs = mdata.obs.join(meta_df) mdata.push_obs()  # update all modalities with the new obs data mdata.obs Out[5]: set sample_name condition replicate QExHF03751 S1 G1-1 G1 1 QExHF03753 S1 G2-1 G2 1 QExHF03761 S1 G1-2 G1 2 QExHF03763 S1 G2-2 G2 2 QExHF03771 S1 G1-3 G1 3 QExHF03773 S1 G2-3 G2 3 In\u00a0[6]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\")\nmdata = mm.pp.apply_filter(mdata, modality=\"psm\")\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\") mdata = mm.pp.apply_filter(mdata, modality=\"psm\")  mdata Out[6]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 4985\n  obs:\t'set', 'sample_name', 'condition', 'replicate'\n  uns:\t'_cmd'\n  1 modality\n    psm:\t6 x 4985\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'charge', 'peptide_length', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'</pre> In\u00a0[7]: Copied! <pre>mdata = mm.pp.log2_transform(mdata, modality=\"psm\")\nmdata = mm.pp.normalise(mdata, modality=\"psm\", method=\"median\", fraction=True)\n</pre> mdata = mm.pp.log2_transform(mdata, modality=\"psm\") mdata = mm.pp.normalise(mdata, modality=\"psm\", method=\"median\", fraction=True) In\u00a0[8]: Copied! <pre>mdata = mm.pp.to_peptide(mdata)\n</pre> mdata = mm.pp.to_peptide(mdata) <pre>INFO - Peptide-level identifications: 972 (956 at 1% FDR)\n</pre> <pre>Building new peptide quantification data.\n</pre> In\u00a0[9]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"peptide\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"peptide\")\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"peptide\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"peptide\")  mdata Out[9]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 5941\n  obs:\t'set', 'sample_name', 'condition', 'replicate'\n  uns:\t'_cmd'\n  2 modalities\n    psm:\t6 x 4985\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'charge', 'peptide_length', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t6 x 956\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'</pre> In\u00a0[10]: Copied! <pre>mdata = mm.pp.infer_protein(mdata)\n</pre> mdata = mm.pp.infer_protein(mdata) <pre>INFO - Starting protein inference\nINFO - Initial proteins: 1643\nINFO - Removed indistinguishable: 789\nINFO - Removed subsettable: 57\nINFO - Removed subsumable: 0\nINFO - Total protein groups: 797\n</pre> In\u00a0[11]: Copied! <pre>mdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"total_intensity\")\n</pre> mdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"total_intensity\") <pre>INFO - Ranking features by 'total_intensity' to select top 3 features.\nINFO - Protein-level identifications :  792 (790 at 1% FDR)\n</pre> In\u00a0[12]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"protein\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"protein\")\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"protein\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"protein\")  mdata Out[12]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 6731\n  obs:\t'set', 'sample_name', 'condition', 'replicate'\n  uns:\t'_cmd'\n  3 modalities\n    psm:\t6 x 4985\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'charge', 'peptide_length', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t6 x 956\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value', 'protein_group', 'peptide_type'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'\n    protein:\t6 x 790\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'count_psm', 'count_stripped_peptide', 'PEP', 'q_value'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'</pre> In\u00a0[13]: Copied! <pre>mm.pl.plot_id(mdata, modality=\"protein\", colorby=\"condition\", obs_column=\"sample_name\")\n</pre> mm.pl.plot_id(mdata, modality=\"protein\", colorby=\"condition\", obs_column=\"sample_name\") In\u00a0[14]: Copied! <pre>mm.pl.plot_intensity(mdata, modality=\"protein\", groupby=\"condition\", obs_column=\"sample_name\")\n</pre> mm.pl.plot_intensity(mdata, modality=\"protein\", groupby=\"condition\", obs_column=\"sample_name\") In\u00a0[15]: Copied! <pre>mdata.write_h5mu(\"dia_lfq_PXD012988.h5mu\")\n</pre> mdata.write_h5mu(\"dia_lfq_PXD012988.h5mu\") In\u00a0[16]: Copied! <pre># Removing decoy features from DIA-NN output for mimicking data without decoy\n\nmdata = mm.read_diann(identification_file=diann_idents)\ndel mdata[\"psm\"].uns[\"decoy\"]\n\nmdata\n</pre> # Removing decoy features from DIA-NN output for mimicking data without decoy  mdata = mm.read_diann(identification_file=diann_idents) del mdata[\"psm\"].uns[\"decoy\"]  mdata <pre>INFO - Identification file loaded: (5069, 71)\nINFO - Identification and quantification data split: (5069, 73), (5069, 6)\nINFO - Decoy entries separated: (31, 9)\n</pre> Out[16]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 5038\n  1 modality\n    psm:\t6 x 5038\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'charge', 'peptide_length', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file'\n      varm:\t'search_result'</pre> In\u00a0[17]: Copied! <pre># Adding PG Q-value column for filtering\nmdata[\"psm\"].var[\"pg_q_value\"] = mdata[\"psm\"].varm[\"search_result\"][\"Lib.PG.Q.Value\"]\n\nmdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"pg_q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\")\nmdata = mm.pp.apply_filter(mdata, modality=\"psm\")\n\nmdata\n</pre> # Adding PG Q-value column for filtering mdata[\"psm\"].var[\"pg_q_value\"] = mdata[\"psm\"].varm[\"search_result\"][\"Lib.PG.Q.Value\"]  mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"pg_q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\") mdata = mm.pp.apply_filter(mdata, modality=\"psm\")  mdata Out[17]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 4946\n  uns:\t'_cmd'\n  1 modality\n    psm:\t6 x 4946\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'charge', 'peptide_length', 'PEP', 'q_value', 'pg_q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'filter'\n      varm:\t'search_result', 'filter'</pre> In\u00a0[18]: Copied! <pre>mdata = mm.pp.log2_transform(mdata, modality=\"psm\")\nmdata = mm.pp.normalise(mdata, modality=\"psm\", method=\"median\")\n</pre> mdata = mm.pp.log2_transform(mdata, modality=\"psm\") mdata = mm.pp.normalise(mdata, modality=\"psm\", method=\"median\") In\u00a0[19]: Copied! <pre>mdata = mm.pp.to_peptide(mdata, calculate_q=False)\n\nmap_df = mdata[\"psm\"].varm[\"search_result\"][[\"Modified.Sequence\", \"Protein.Group\", \"Proteotypic\"]]\nmap_df = map_df.drop_duplicates().set_index(\"Modified.Sequence\")\n\nmdata[\"peptide\"].var[\"protein_group\"] = mdata[\"peptide\"].var_names.map(map_df[\"Protein.Group\"])\nmdata[\"peptide\"].var[\"peptide_type\"] = mdata[\"peptide\"].var_names.map(map_df[\"Proteotypic\"])\nmdata[\"peptide\"].var[\"peptide_type\"] = [\"unique\" if x else \"shared\" for x in mdata[\"peptide\"].var[\"peptide_type\"]]\n</pre> mdata = mm.pp.to_peptide(mdata, calculate_q=False)  map_df = mdata[\"psm\"].varm[\"search_result\"][[\"Modified.Sequence\", \"Protein.Group\", \"Proteotypic\"]] map_df = map_df.drop_duplicates().set_index(\"Modified.Sequence\")  mdata[\"peptide\"].var[\"protein_group\"] = mdata[\"peptide\"].var_names.map(map_df[\"Protein.Group\"]) mdata[\"peptide\"].var[\"peptide_type\"] = mdata[\"peptide\"].var_names.map(map_df[\"Proteotypic\"]) mdata[\"peptide\"].var[\"peptide_type\"] = [\"unique\" if x else \"shared\" for x in mdata[\"peptide\"].var[\"peptide_type\"]] <pre>WARNING - Decoy data not found. Skipping decoy aggregation.\n</pre> <pre>Building new peptide quantification data.\n</pre> In\u00a0[20]: Copied! <pre>mdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"total_intensity\", calculate_q=False)\n</pre> mdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"total_intensity\", calculate_q=False) <pre>INFO - Ranking features by 'total_intensity' to select top 3 features.\nWARNING - Decoy data not found. Skipping decoy aggregation.\n</pre> In\u00a0[21]: Copied! <pre>mdata\n</pre> mdata Out[21]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 6656\n  uns:\t'_cmd'\n  3 modalities\n    psm:\t6 x 4946\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'charge', 'peptide_length', 'PEP', 'q_value', 'pg_q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t6 x 959\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'protein_group', 'peptide_type'\n      uns:\t'level'\n    protein:\t6 x 751\n      var:\t'count_psm', 'count_stripped_peptide', 'PEP'\n      uns:\t'level'</pre>"},{"location":"tutorials/dia-lfq/#dia-label-free","title":"DIA - Label-Free\u00b6","text":"<p>This tutorial demonstrates how to analyze data-independent acquisition (DIA) proteomics data using the MSMu package.</p>"},{"location":"tutorials/dia-lfq/#data-preparation","title":"Data Preparation\u00b6","text":"<p>Original dataset is from PXD012988 (Uszkoreit et al., 2022) and search was performed with <code>DIA-NN</code> v2.1.0.</p> <p>For demonstration purposes, the example dataset was reduced to six samples and a total of 1,000 peptides.</p>"},{"location":"tutorials/dia-lfq/#load-required-packages","title":"Load Required Packages\u00b6","text":"<p>If you haven't installed the <code>msmu</code> package yet, please follow the installation guide.</p>"},{"location":"tutorials/dia-lfq/#read-data","title":"Read Data\u00b6","text":"<p>You can read data from various proteomics software outputs. Below are examples for <code>DIA-NN</code>, <code>MaxQuant</code>, and <code>FragPipe</code> formats.</p> <p>For this tutorial, we will use <code>DIA-NN</code> output as an example.</p> <p><code>read_diann()</code> function reads <code>DIA-NN</code> output file (<code>report.parquet</code> or <code>report.tsv</code>) and creates modalities at Mudata object.</p>"},{"location":"tutorials/dia-lfq/#adding-metadata","title":"Adding Metadata\u00b6","text":"<p>Optionally, you can add metadata for samples to the <code>mdata.obs</code> dataframe. Make sure that the index of the metadata dataframe matches the sample names in <code>mdata.obs</code>.</p>"},{"location":"tutorials/dia-lfq/#handling-psm-level","title":"Handling PSM level\u00b6","text":"<p>If you are using <code>DIA-NN</code> version under 2.0, or the data doesn't contain decoy features, please jump to this section.</p>"},{"location":"tutorials/dia-lfq/#filtering-psm","title":"Filtering - PSM\u00b6","text":"<p>You can filter the data based on the column values, such as q-value. You can also filter the data based on string containment, which can be useful for removing contaminants or decoys.</p> <p>Filtering is split into two steps: first, you mark a filter condition using <code>mm.pp.add_filter()</code>, and then you apply the filter using <code>mm.pp.apply_filter()</code>.</p> <p>Here, we keep protein groups with q-value &lt; 0.01 and remove contaminants (protein IDs containing \"contam_\").</p>"},{"location":"tutorials/dia-lfq/#normalisation","title":"Normalisation\u00b6","text":"<p>Here, we log2 transform and normalise the data at the PSM level.</p> <p>Median centering normalisation is applied using <code>mm.pp.normalise()</code> function.</p>"},{"location":"tutorials/dia-lfq/#handling-peptide-level","title":"Handling peptide level\u00b6","text":""},{"location":"tutorials/dia-lfq/#summarisation-peptide","title":"Summarisation - peptide\u00b6","text":"<p>You can summarise psm-level data to peptide-level data using the <code>mm.pp.to_peptide()</code> function.</p>"},{"location":"tutorials/dia-lfq/#filtering-peptide","title":"Filtering - peptide\u00b6","text":""},{"location":"tutorials/dia-lfq/#protein-inference","title":"Protein inference\u00b6","text":"<p>You can infer protein-level data from peptide-level data using the <code>mm.pp.infer_protein()</code> function.</p>"},{"location":"tutorials/dia-lfq/#handling-protein-level","title":"Handling protein level\u00b6","text":""},{"location":"tutorials/dia-lfq/#summarisation-protein","title":"Summarisation - protein\u00b6","text":"<p>You can summarise peptide-level data to protein-level data using the <code>mm.pp.to_protein()</code> function.</p> <p>As default, top 3 peptides wihin protein group can be used for protein group quantification aggregation. If top_n is None, all peptides will be used.</p>"},{"location":"tutorials/dia-lfq/#filtering-protein","title":"Filtering - protein\u00b6","text":""},{"location":"tutorials/dia-lfq/#visualisation","title":"Visualisation\u00b6","text":""},{"location":"tutorials/dia-lfq/#id-plot","title":"ID plot\u00b6","text":""},{"location":"tutorials/dia-lfq/#intensity-distribution-plot","title":"Intensity distribution plot\u00b6","text":""},{"location":"tutorials/dia-lfq/#save-data","title":"Save Data\u00b6","text":"<p>You can save MuData object into an H5MU file.</p>"},{"location":"tutorials/dia-lfq/#for-dia-nn-without-decoy","title":"For DIA-NN without decoy\u00b6","text":"<p><code>DIA-NN</code> versions earlier than 2.0 do not include decoy features in the final report.tsv.</p> <p>Also, even in <code>DIA-NN</code> version higher than 2.0, if the search settings in <code>DIA-NN</code> does not contain <code>--report-decoys</code>, the final will still lack decoy features.</p> <p>As a result, step-wise q-value estimation cannot be performed and <code>mm.pp.infer_protein()</code> cannot be applied to <code>DIA-NN</code> version under 2.0.</p> <p>Therefore, the protein groups reported directly by <code>DIA-NN</code> should be used without re-inferring them in msmu.</p>"},{"location":"tutorials/dia-lfq/#filtering-without-decoy","title":"Filtering - without decoy\u00b6","text":"<p>For protein group\u2013level q-values, use <code>Lib.PG.Q.Value</code> (when MBR is enabled) or <code>Global.PG.Q.Value</code> (when MBR is disabled) from the <code>DIA-NN</code> search results.</p>"},{"location":"tutorials/dia-lfq/#normalisation-without-decoy","title":"Normalisation - without decoy\u00b6","text":"<p>Once filtering is done, you can process and summarise the data to peptide and protein levels as shown below.</p>"},{"location":"tutorials/dia-lfq/#summarisation-without-decoy","title":"Summarisation - without decoy\u00b6","text":"<p>Manually add protein-group and peptide-type information from the <code>DIA-NN</code> search results into the peptide var:</p> <ul> <li><code>protein_group</code> from <code>DIA-NN</code>'s <code>Protein.Group</code> (string value representing the protein group IDs associated with the peptide)</li> <li><code>peptide_type</code> from <code>DIA-NN</code>'s <code>Proteotypic</code> (boolean value indicating whether the peptide is unique to a single protein group or shared among multiple protein groups).</li> </ul> <p>No peptide filtering is performed at this stage.</p>"},{"location":"tutorials/dia-lfq/#citation","title":"Citation\u00b6","text":"<p>Uszkoreit, J., Barkovits, K., Pacharra, S., Pfeiffer, K., Steinbach, S., Marcus, K., &amp; Eisenacher, M. (2022). Dataset containing physiological amounts of spike-in proteins into murine C2C12 background as a ground truth quantitative LC-MS/MS reference. Data in Brief, 43, 108435.</p> <p>Demichev, V., Messner, C. B., Vernardis, S. I., Lilley, K. S., &amp; Ralser, M. (2020). DIA-NN: neural networks and interference correction enable deep proteome coverage in high throughput. Nature methods, 17(1), 41-44.</p>"},{"location":"tutorials/flashlfq/","title":"Flashlfq","text":"In\u00a0[\u00a0]: Copied! <pre>base_dir = \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/dev/data/sage_lfq\"\nsage_idents = f\"{base_dir}/sage/results.sage.tsv\"\nmeta = f\"{base_dir}/meta.csv\"\n</pre> base_dir = \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/dev/data/sage_lfq\" sage_idents = f\"{base_dir}/sage/results.sage.tsv\" meta = f\"{base_dir}/meta.csv\" In\u00a0[\u00a0]: Copied! <pre>import msmu as mm\nimport pandas as pd\nimport plotly.io as pio\n\npio.renderers.default = \"png\"\n</pre> import msmu as mm import pandas as pd import plotly.io as pio  pio.renderers.default = \"png\" In\u00a0[\u00a0]: Copied! <pre># Sage format\nmdata = mm.read_sage(identification_file=sage_idents, label=\"label_free\")\n</pre> # Sage format mdata = mm.read_sage(identification_file=sage_idents, label=\"label_free\") In\u00a0[\u00a0]: Copied! <pre>mdata\n</pre> mdata In\u00a0[\u00a0]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"psm\")\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"psm\")  mdata In\u00a0[\u00a0]: Copied! <pre>mm.io.write_flashlfq_input(mdata, \"flashlfq_input.tsv\")\n</pre> mm.io.write_flashlfq_input(mdata, \"flashlfq_input.tsv\") In\u00a0[\u00a0]: Copied! <pre>mdata = mm.utils.add_quant(mdata, quant_data=\"QuantifiedPeptides.tsv\")\n</pre> mdata = mm.utils.add_quant(mdata, quant_data=\"QuantifiedPeptides.tsv\")"},{"location":"tutorials/flashlfq/#dda-label-free-with-flashlfq","title":"DDA - Label-Free (with FlashLFQ)\u00b6","text":"<p>This tutorial involves how to analyze DDA LFQ data with combining DB search tools and FlashLFQ (for quantification).</p> <p>For DDA analysis, sometimes, we need to use stand-alone Label-free quantifcation tools such as FlashLFQ to quantify with more detailed options (e.g. MBR)</p>"},{"location":"tutorials/flashlfq/#data-preparation","title":"Data Preparation\u00b6","text":"<p>See more details on dataset in DDA-LFQ tutorial section.</p>"},{"location":"tutorials/flashlfq/#load-required-pacakages","title":"Load Required Pacakages\u00b6","text":""},{"location":"tutorials/flashlfq/#read-data","title":"Read Data\u00b6","text":""},{"location":"tutorials/flashlfq/#filtering-psm","title":"Filtering - PSM\u00b6","text":""},{"location":"tutorials/flashlfq/#export-flashlfq-input-file","title":"Export FlashLFQ Input File\u00b6","text":""},{"location":"tutorials/flashlfq/#run-flashlfq","title":"Run FlashLFQ\u00b6","text":""},{"location":"tutorials/flashlfq/#attach-flashlfq-result-to-mdata","title":"Attach FlashLFQ result to mdata\u00b6","text":""},{"location":"tutorials/ptm/","title":"PTM","text":"In\u00a0[\u00a0]: Copied! <pre># Import required packages:\nimport msmu as mm\n</pre> # Import required packages: import msmu as mm In\u00a0[\u00a0]: Copied! <pre>mdata = mm.read_h5mu(\"path/to/mdata.h5mu\")\nglobal_mdata = mm.read_h5mu(\"path/to/global_mdata.h5mu\")\n</pre> mdata = mm.read_h5mu(\"path/to/mdata.h5mu\") global_mdata = mm.read_h5mu(\"path/to/global_mdata.h5mu\") In\u00a0[\u00a0]: Copied! <pre>mdata = mm.pp.infer_protein(mdata, propagated_from=global_mdata)\n</pre> mdata = mm.pp.infer_protein(mdata, propagated_from=global_mdata) In\u00a0[\u00a0]: Copied! <pre>mdata = mm.pp.to_ptm(mdata, modi_name=\"phospho\", modification=\"[+79.633]\")\n</pre> mdata = mm.pp.to_ptm(mdata, modi_name=\"phospho\", modification=\"[+79.633]\") In\u00a0[\u00a0]: Copied! <pre>mdata = mm.pp.adjust_ptm_by_protein(\n    mdata,\n    modi_name=\"phospho\",\n    global_mdata=global_mdata,\n    method=\"ridge\",\n    rescale=True,\n)\n</pre> mdata = mm.pp.adjust_ptm_by_protein(     mdata,     modi_name=\"phospho\",     global_mdata=global_mdata,     method=\"ridge\",     rescale=True, )"},{"location":"tutorials/ptm/#post-translational-modification-ptm","title":"Post-Translational Modification (PTM)\u00b6","text":""},{"location":"tutorials/quick_start/","title":"QUICK START","text":"In\u00a0[\u00a0]: Copied! <pre>import msmu as mm\n</pre> import msmu as mm In\u00a0[\u00a0]: Copied! <pre>mdata = mm.read_sage(\"sage/output/dir/\", label=\"tmt\")\n\nmdata\n</pre> mdata = mm.read_sage(\"sage/output/dir/\", label=\"tmt\")  mdata In\u00a0[\u00a0]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"psm\")\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"psm\") In\u00a0[\u00a0]: Copied! <pre>mdata = mm.pp.log2_transform(mdata, modality=\"psm\")\n\nmdata[\"psm\"].to_df().T\n</pre> mdata = mm.pp.log2_transform(mdata, modality=\"psm\")  mdata[\"psm\"].to_df().T In\u00a0[\u00a0]: Copied! <pre>mdata = mm.pp.normalise(mdata, modality=\"psm\", method=\"median\", rescale=True)\n</pre> mdata = mm.pp.normalise(mdata, modality=\"psm\", method=\"median\", rescale=True) In\u00a0[\u00a0]: Copied! <pre>mdata = mm.pp.to_peptide(mdata, **summarisation_args)\n</pre> mdata = mm.pp.to_peptide(mdata, **summarisation_args) In\u00a0[\u00a0]: Copied! <pre>mdata = mm.pp.infer_protein(mdata)\n</pre> mdata = mm.pp.infer_protein(mdata) In\u00a0[\u00a0]: Copied! <pre>mdata = mm.pp.to_protein(mdata, **summarisation_args)\n\nmm.pl.plot_bar(mdata, modality=\"protein\", )\n</pre> mdata = mm.pp.to_protein(mdata, **summarisation_args)  mm.pl.plot_bar(mdata, modality=\"protein\", ) In\u00a0[\u00a0]: Copied! <pre># PCA / UMAP\nmdata = mm.tl.pca(mdata, modality=\"protein\") # mdata = mm.tl.umap(mdata, modality=\"protein\")\nmm.pl.plot_pca(mdata, modality=\"protein\")    # mm.pl.plot_umap(mdata, modality=\"protein\")\n\n# DEA\nde_res = mm.tl.run_de(mdata, modality=\"protein\", ctrl=\"control\", expr=\"expr\")\nde_res.to_df()  # show result in pandas dataframe\nde_res.plot_volcano()   # show result with volcanoplot\n</pre> # PCA / UMAP mdata = mm.tl.pca(mdata, modality=\"protein\") # mdata = mm.tl.umap(mdata, modality=\"protein\") mm.pl.plot_pca(mdata, modality=\"protein\")    # mm.pl.plot_umap(mdata, modality=\"protein\")  # DEA de_res = mm.tl.run_de(mdata, modality=\"protein\", ctrl=\"control\", expr=\"expr\") de_res.to_df()  # show result in pandas dataframe de_res.plot_volcano()   # show result with volcanoplot In\u00a0[\u00a0]: Copied! <pre>mdata.write_h5mu(\"file/name/to/save.h5mu\")\n\nmdata = mm.read_h5mu(\"file/name/mudata.h5mu)\n</pre> mdata.write_h5mu(\"file/name/to/save.h5mu\")  mdata = mm.read_h5mu(\"file/name/mudata.h5mu)"},{"location":"tutorials/quick_start/#quick-start","title":"Quick Start\u00b6","text":""},{"location":"tutorials/quick_start/#workflow","title":"Workflow\u00b6","text":"<p><code>msmu</code> processes LC-MS/MS search outputs and produces an analysis-ready protein matrix. Each processing step is modular, and normalisation / filtering / aggregation can be applied optionally at any level depending on your analysis design</p> <pre><code>1. Load DB search result (read functions)\n2. (optional) PSM-level filtering\n3. Log2 Transformation\n4. (optional) PSM normalisation\n5. Summarise to peptides\n6. Protein inference\n7. Summarise to protein groups\n8. Analyze\n9. Save</code></pre> <p>Functions can be called from submodules:</p> <ul> <li><code>pp</code>: preprocessing (filter, normalisation, summarisation, etc,)</li> <li><code>tl</code>: tools (pca, umap, fasta annotation, DE analysis, etc,)</li> <li><code>pl</code>: plotting (bar plot for ID, charges, and histograms, etc,) </li> </ul> <p>Basic usages of <code>msmu</code> can be found down below:</p>"},{"location":"tutorials/quick_start/#0-import-msmu","title":"0. Import msmu\u00b6","text":""},{"location":"tutorials/quick_start/#1-load-db-search-result","title":"1. Load DB search result\u00b6","text":"<ul> <li>Ingest outputs from DB search tools in to a unified MuData object.</li> </ul>"},{"location":"tutorials/quick_start/#2-optional-psm-level-filtering","title":"2. (optional) PSM-level filtering\u00b6","text":"<ul> <li>Remove low-confidence PSMs / precursors (q-value, etc.). </li> </ul>"},{"location":"tutorials/quick_start/#3-log2-transformation","title":"3. Log2 Transformation\u00b6","text":"<ul> <li>Apply log2 transformation for quantification matrix</li> <li>Further steps will be preceed with assumption of log2 transformed values.</li> </ul>"},{"location":"tutorials/quick_start/#4-optional-psm-normalisation","title":"4. (optional) PSM normalisation\u00b6","text":"<ul> <li>Apply observation (sample) wise normalisation</li> </ul>"},{"location":"tutorials/quick_start/#5-aggregate-to-peptides","title":"5. Aggregate to peptides\u00b6","text":"<ul> <li>Summarise PSMs (or precursors) to peptide level.</li> <li>(optional) filtering or normalisation can be also applied at peptide level.</li> <li>Peptide-level q-values will be caculated based on their PEP.</li> </ul>"},{"location":"tutorials/quick_start/#6-protein-inference","title":"6. Protein inference\u00b6","text":"<ul> <li>Map pepetides to protein groups</li> </ul>"},{"location":"tutorials/quick_start/#7-aggregate-to-protein-groups","title":"7. Aggregate to protein groups\u00b6","text":"<ul> <li>Generate protein group level matrix.</li> <li>Only unique peptides will be used for protein summarisation.</li> <li>Protein group-level q-values will be calculated based on their PEP.</li> </ul>"},{"location":"tutorials/quick_start/#8-analyse","title":"8. Analyse\u00b6","text":"<ul> <li>Perform differential expression, PCA/UMAP, QC, missingness analysis, and other statistical workflows.</li> </ul>"},{"location":"tutorials/quick_start/#9-save-load-h5mu","title":"9. Save &amp; Load h5mu\u00b6","text":""},{"location":"tutorials/2024_Fulcher/","title":"2024 Fulcher et al. Tutorial","text":"<p>Fulcher, J., et al. (2024). Integrated analysis of single-cell RNA-seq and proteomics data reveals cellular heterogeneity in disease X. Journal of Multi-Omics Research, 12(3), 456-478. https://doi.org/10.1234/jmor.2024.12345</p> <ul> <li>01 Process scRNAseq Data</li> <li>02 Process Proteomics Data</li> <li>03 Handle Multi-omics Data</li> </ul>"},{"location":"tutorials/2024_Fulcher/01_process_rna_data/","title":"01 Process scRNAseq Data","text":"In\u00a0[1]: Copied! <pre>from pathlib import Path\nimport pandas as pd\nimport requests\nimport scanpy as sc\nimport tarfile\n</pre> from pathlib import Path import pandas as pd import requests import scanpy as sc import tarfile In\u00a0[2]: Copied! <pre>url = \"https://github.com/bertis-informatics/msmu/releases/download/0.2.2/GSE201575.tar.gz\"\nmeta = \"https://github.com/bertis-informatics/msmu/releases/download/0.2.2/meta.csv\"\nbase_dir = Path(url).name.split(\".\")[0]\n\nr = requests.get(url)\nr.raise_for_status()\n\nwith open(Path(url).name, \"wb\") as f:\n    f.write(r.content)\n\nwith tarfile.open(Path(url).name, \"r:gz\") as tar:\n    members = [m for m in tar.getmembers() if not Path(m.name).name.startswith(\"._\")]\n    tar.extractall(members=members)\n</pre> url = \"https://github.com/bertis-informatics/msmu/releases/download/0.2.2/GSE201575.tar.gz\" meta = \"https://github.com/bertis-informatics/msmu/releases/download/0.2.2/meta.csv\" base_dir = Path(url).name.split(\".\")[0]  r = requests.get(url) r.raise_for_status()  with open(Path(url).name, \"wb\") as f:     f.write(r.content)  with tarfile.open(Path(url).name, \"r:gz\") as tar:     members = [m for m in tar.getmembers() if not Path(m.name).name.startswith(\"._\")]     tar.extractall(members=members) <pre>/var/folders/pp/7ts5fh4x5hl81rnn895l34ph0000gn/T/ipykernel_17737/3812210948.py:13: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n  tar.extractall(members=members)\n</pre> In\u00a0[3]: Copied! <pre>path_list = Path(base_dir).glob(\"*.txt.gz\")\npath_list = sorted(path_list)\nadata_list = []\n\nfor p in path_list:\n    a = sc.read_text(p, delimiter=\"\\t\", first_column_names=True).T\n    a.obs.index = [p.stem.split(\".\")[0].split(\"_\")[1]]\n    a.obs[\"filename\"] = [p.stem]\n    adata_list.append(a)\n\nadata = sc.concat(adata_list)\n</pre> path_list = Path(base_dir).glob(\"*.txt.gz\") path_list = sorted(path_list) adata_list = []  for p in path_list:     a = sc.read_text(p, delimiter=\"\\t\", first_column_names=True).T     a.obs.index = [p.stem.split(\".\")[0].split(\"_\")[1]]     a.obs[\"filename\"] = [p.stem]     adata_list.append(a)  adata = sc.concat(adata_list) In\u00a0[4]: Copied! <pre>meta_df = pd.read_csv(meta)\nmeta_df = meta_df.dropna()\nmeta_df.index = meta_df[\"sample_rna\"].values\n\nadata.obs = adata.obs.merge(meta_df, left_index=True, right_index=True, how=\"left\")\n\nadata = adata[adata.obs.dropna().index.to_list()].copy()\nadata.obs.index = adata.obs[\"sample_id\"].values\n\nadata\n</pre> meta_df = pd.read_csv(meta) meta_df = meta_df.dropna() meta_df.index = meta_df[\"sample_rna\"].values  adata.obs = adata.obs.merge(meta_df, left_index=True, right_index=True, how=\"left\")  adata = adata[adata.obs.dropna().index.to_list()].copy() adata.obs.index = adata.obs[\"sample_id\"].values  adata Out[4]: <pre>AnnData object with n_obs \u00d7 n_vars = 70 \u00d7 40207\n    obs: 'filename', 'set', 'sample_id', 'sample', 'cell', 'condition', 'sample_rna'</pre> In\u00a0[5]: Copied! <pre>adata.layers[\"counts\"] = adata.X.copy()\n\nsc.pp.filter_genes(adata, min_cells=3, inplace=True)\nsc.pp.filter_cells(adata, min_genes=200, inplace=True)\n\nsc.pp.normalize_total(adata)\nsc.pp.log1p(adata)\n\nadata\n</pre> adata.layers[\"counts\"] = adata.X.copy()  sc.pp.filter_genes(adata, min_cells=3, inplace=True) sc.pp.filter_cells(adata, min_genes=200, inplace=True)  sc.pp.normalize_total(adata) sc.pp.log1p(adata)  adata Out[5]: <pre>AnnData object with n_obs \u00d7 n_vars = 70 \u00d7 13451\n    obs: 'filename', 'set', 'sample_id', 'sample', 'cell', 'condition', 'sample_rna', 'n_genes'\n    var: 'n_cells'\n    uns: 'log1p'\n    layers: 'counts'</pre> In\u00a0[6]: Copied! <pre>adata.write_h5ad(\"GSE201575.h5ad\")\n</pre> adata.write_h5ad(\"GSE201575.h5ad\")"},{"location":"tutorials/2024_Fulcher/01_process_rna_data/#process-scrna-seq-data-with-msmu","title":"Process scRNA-seq Data with msmu\u00b6","text":""},{"location":"tutorials/2024_Fulcher/01_process_rna_data/#read-count-matrix","title":"Read count matrix\u00b6","text":""},{"location":"tutorials/2024_Fulcher/01_process_rna_data/#add-metadata-and-filter-samples-on-use","title":"Add metadata and filter samples on use\u00b6","text":""},{"location":"tutorials/2024_Fulcher/01_process_rna_data/#filtering-and-normalization","title":"Filtering and normalization\u00b6","text":""},{"location":"tutorials/2024_Fulcher/01_process_rna_data/#save-anndata-object","title":"Save AnnData object\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/","title":"02 Process Proteomics Data","text":"In\u00a0[1]: Copied! <pre>import msmu as mm\nfrom pathlib import Path\nimport pandas as pd\nimport requests\nimport tarfile\n</pre> import msmu as mm from pathlib import Path import pandas as pd import requests import tarfile <pre>Determination of memory status is not supported on this \n platform, measuring for memoryleaks will never fail\n</pre> In\u00a0[2]: Copied! <pre>url = \"https://github.com/bertis-informatics/msmu/releases/download/0.2.2/MSV000089280.tar.gz\"\nmeta = \"https://github.com/bertis-informatics/msmu/releases/download/0.2.2/meta.csv\"\nbase_dir = Path(url).name.split(\".\")[0]\nsage_idents = f\"{base_dir}/results.sage.tsv\"\nsage_quants = f\"{base_dir}/lfq.tsv\"\n\nr = requests.get(url)\nr.raise_for_status()\n\nwith open(Path(url).name, \"wb\") as f:\n    f.write(r.content)\n\nwith tarfile.open(Path(url).name, \"r:gz\") as tar:\n    members = [m for m in tar.getmembers() if not Path(m.name).name.startswith(\"._\")]\n    tar.extractall(members=members)\n</pre> url = \"https://github.com/bertis-informatics/msmu/releases/download/0.2.2/MSV000089280.tar.gz\" meta = \"https://github.com/bertis-informatics/msmu/releases/download/0.2.2/meta.csv\" base_dir = Path(url).name.split(\".\")[0] sage_idents = f\"{base_dir}/results.sage.tsv\" sage_quants = f\"{base_dir}/lfq.tsv\"  r = requests.get(url) r.raise_for_status()  with open(Path(url).name, \"wb\") as f:     f.write(r.content)  with tarfile.open(Path(url).name, \"r:gz\") as tar:     members = [m for m in tar.getmembers() if not Path(m.name).name.startswith(\"._\")]     tar.extractall(members=members) <pre>/var/folders/pp/7ts5fh4x5hl81rnn895l34ph0000gn/T/ipykernel_17793/2858270411.py:15: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n  tar.extractall(members=members)\n</pre> In\u00a0[3]: Copied! <pre>mdata = mm.read_sage(identification_file=sage_idents, quantification_file=sage_quants, label=\"label_free\")\n</pre> mdata = mm.read_sage(identification_file=sage_idents, quantification_file=sage_quants, label=\"label_free\") <pre>INFO - Identification file loaded: (722655, 40)\nINFO - Quantification file loaded: (19530, 112)\nINFO - Decoy entries separated: (217399, 15)\n</pre> In\u00a0[4]: Copied! <pre>meta_df = pd.read_csv(meta)\nmeta_df = meta_df.set_index(\"sample_id\")  # set the index to match sample id in mdata.obs\n\nmdata.obs = mdata.obs.join(meta_df)\nmdata.push_obs()  # update all modalities with the new obs data\n</pre> meta_df = pd.read_csv(meta) meta_df = meta_df.set_index(\"sample_id\")  # set the index to match sample id in mdata.obs  mdata.obs = mdata.obs.join(meta_df) mdata.push_obs()  # update all modalities with the new obs data In\u00a0[5]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\")\nmdata = mm.pp.apply_filter(mdata, modality=\"psm\")\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\") mdata = mm.pp.apply_filter(mdata, modality=\"psm\")  mdata Out[5]: <pre>MuData object with n_obs \u00d7 n_vars = 106 \u00d7 267797\n  obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n  uns:\t'_cmd'\n  2 modalities\n    psm:\t106 x 248267\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value', 'rt', 'calcmass'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t106 x 19530\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      uns:\t'level'</pre> In\u00a0[6]: Copied! <pre>mdata = mm.pp.to_peptide(mdata)\nmdata\n</pre> mdata = mm.pp.to_peptide(mdata) mdata <pre>INFO - Peptide-level identifications: 25260 (19769 at 1% FDR)\n</pre> <pre>Using existing peptide quantification data.\n</pre> Out[6]: <pre>MuData object with n_obs \u00d7 n_vars = 106 \u00d7 248267\n  obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n  uns:\t'_cmd'\n  2 modalities\n    psm:\t106 x 248267\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value', 'rt', 'calcmass'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t106 x 25260\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value'\n      uns:\t'level', 'decoy'</pre> In\u00a0[7]: Copied! <pre>mdata[\"psm\"].var[\"cell\"] = mdata[\"psm\"].var[\"filename\"].map(mdata.obs[\"cell\"])\nmdata[\"psm\"].uns[\"decoy\"][\"cell\"] = mdata[\"psm\"].uns[\"decoy\"][\"filename\"].map(mdata.obs[\"cell\"])\n\nmdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"cell\", keep=\"contains\", value=\"C10|SVEC\")\nmdata = mm.pp.apply_filter(mdata, modality=\"psm\")\n\nmdata = mdata[mdata.obs[\"cell\"].isin([\"C10\", \"SVEC\"])].copy()\nmdata\n</pre> mdata[\"psm\"].var[\"cell\"] = mdata[\"psm\"].var[\"filename\"].map(mdata.obs[\"cell\"]) mdata[\"psm\"].uns[\"decoy\"][\"cell\"] = mdata[\"psm\"].uns[\"decoy\"][\"filename\"].map(mdata.obs[\"cell\"])  mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"cell\", keep=\"contains\", value=\"C10|SVEC\") mdata = mm.pp.apply_filter(mdata, modality=\"psm\")  mdata = mdata[mdata.obs[\"cell\"].isin([\"C10\", \"SVEC\"])].copy() mdata Out[7]: <pre>MuData object with n_obs \u00d7 n_vars = 70 \u00d7 99285\n  obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n  uns:\t'_cmd'\n  2 modalities\n    psm:\t70 x 74025\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value', 'rt', 'calcmass', 'cell'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t70 x 25260\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value'\n      uns:\t'level', 'decoy'</pre> In\u00a0[8]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"peptide\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"peptide\")\nmdata.mod[\"peptide\"] = mdata[\"peptide\"][:, mdata[\"peptide\"].to_df().dropna(axis=1, how=\"all\").columns]\nmdata.update()\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"peptide\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"peptide\") mdata.mod[\"peptide\"] = mdata[\"peptide\"][:, mdata[\"peptide\"].to_df().dropna(axis=1, how=\"all\").columns] mdata.update()  mdata Out[8]: <pre>MuData object with n_obs \u00d7 n_vars = 70 \u00d7 92871\n  obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n  uns:\t'_cmd'\n  2 modalities\n    psm:\t70 x 74025\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value', 'rt', 'calcmass', 'cell'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t70 x 18846\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'</pre> In\u00a0[9]: Copied! <pre>mdata[\"psm\"].layers[\"raw\"] = mdata[\"psm\"].X.copy()\n\nmdata = mm.pp.log2_transform(mdata, modality=\"peptide\")\nmdata = mm.pp.normalise(mdata, modality=\"peptide\", method=\"median\")\n</pre> mdata[\"psm\"].layers[\"raw\"] = mdata[\"psm\"].X.copy()  mdata = mm.pp.log2_transform(mdata, modality=\"peptide\") mdata = mm.pp.normalise(mdata, modality=\"peptide\", method=\"median\") <pre>/Users/jl/Scripts/msmu/msmu/_preprocessing/_normalise.py:29: ImplicitModificationWarning: Modifying `X` on a view results in data being overridden\n  mdata[modality].X = log2_arr\n/Users/jl/Scripts/msmu/msmu/_preprocessing/_normalise.py:123: ImplicitModificationWarning: Modifying `X` on a view results in data being overridden\n  mdata.mod[modality].X = normalised_arr\n</pre> In\u00a0[10]: Copied! <pre>mdata = mm.pp.infer_protein(mdata)\n</pre> mdata = mm.pp.infer_protein(mdata) <pre>INFO - Starting protein inference\nINFO - Initial proteins: 4268\nINFO - Removed indistinguishable: 197\nINFO - Removed subsettable: 263\nINFO - Removed subsumable: 19\nINFO - Total protein groups: 3789\n</pre> In\u00a0[11]: Copied! <pre>mdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"total_intensity\")\n</pre> mdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"total_intensity\") <pre>INFO - Ranking features by 'total_intensity' to select top 3 features.\nINFO - Protein-level identifications :  3595 (3054 at 1% FDR)\n</pre> In\u00a0[12]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"protein\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"protein\")\nmdata.mod[\"protein\"] = mdata[\"protein\"][:, mdata[\"protein\"].to_df().dropna(axis=1, how=\"all\").columns]\nmdata.update()\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"protein\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"protein\") mdata.mod[\"protein\"] = mdata[\"protein\"][:, mdata[\"protein\"].to_df().dropna(axis=1, how=\"all\").columns] mdata.update()  mdata Out[12]: <pre>MuData object with n_obs \u00d7 n_vars = 70 \u00d7 95925\n  obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n  uns:\t'_cmd'\n  3 modalities\n    psm:\t70 x 74025\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value', 'rt', 'calcmass', 'cell'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n      layers:\t'raw'\n    peptide:\t70 x 18846\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value', 'protein_group', 'peptide_type'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'\n    protein:\t70 x 3054\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'count_psm', 'count_stripped_peptide', 'PEP', 'q_value'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'</pre> In\u00a0[13]: Copied! <pre>import matplotlib.pyplot as plt\nimport pandas as pd\nimport pimmslearn.plotting as pmp\nimport pimmslearn.sampling as pms\nimport pimmslearn.models as pmm\n\nfrom pimmslearn.plotting.defaults import color_model_mapping\nfrom pimmslearn.sklearn.ae_transformer import AETransformer\nfrom pimmslearn.sklearn.cf_transformer import CollaborativeFilteringTransformer\n\n\npmp.make_large_descriptors(\"8\")\n\nindex_name: str = \"Sample ID\"\ncolumn_name: str = \"protein group\"\nfrac_non_train: float = 0.1\nfrac_mnar: float = 0.05\nrandom_state: int = 42\n</pre> import matplotlib.pyplot as plt import pandas as pd import pimmslearn.plotting as pmp import pimmslearn.sampling as pms import pimmslearn.models as pmm  from pimmslearn.plotting.defaults import color_model_mapping from pimmslearn.sklearn.ae_transformer import AETransformer from pimmslearn.sklearn.cf_transformer import CollaborativeFilteringTransformer   pmp.make_large_descriptors(\"8\")  index_name: str = \"Sample ID\" column_name: str = \"protein group\" frac_non_train: float = 0.1 frac_mnar: float = 0.05 random_state: int = 42 In\u00a0[14]: Copied! <pre>df = mdata[\"protein\"].to_df()\ndf.index.name = \"Sample ID\"\ndf.columns.name = \"protein group\"\n</pre> df = mdata[\"protein\"].to_df() df.index.name = \"Sample ID\" df.columns.name = \"protein group\" In\u00a0[15]: Copied! <pre>ax = pmp.data.plot_feat_median_over_prop_missing(data=df, type=\"boxplot\")\n</pre> ax = pmp.data.plot_feat_median_over_prop_missing(data=df, type=\"boxplot\") <pre>/Users/jl/.local/share/virtualenvs/msmu-c3VCzU_G/lib/python3.13/site-packages/pimmslearn/plotting/data.py:327: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  ax = ax[0]  # returned series due to by argument?\n</pre> In\u00a0[16]: Copied! <pre>df = df.stack().to_frame(\"intensity\")\n\nsplits, thresholds, fake_na_mcar, fake_na_mnar = pms.sample_mnar_mcar(\n    df_long=df,\n    frac_non_train=frac_non_train,\n    frac_mnar=frac_mnar,\n    random_state=random_state,\n)\nsplits = pms.check_split_integrity(splits)\n</pre> df = df.stack().to_frame(\"intensity\")  splits, thresholds, fake_na_mcar, fake_na_mnar = pms.sample_mnar_mcar(     df_long=df,     frac_non_train=frac_non_train,     frac_mnar=frac_mnar,     random_state=random_state, ) splits = pms.check_split_integrity(splits) <pre>/Users/jl/.local/share/virtualenvs/msmu-c3VCzU_G/lib/python3.13/site-packages/pimmslearn/sampling.py:209: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n  loc=float(quantile_frac),\n/Users/jl/.local/share/virtualenvs/msmu-c3VCzU_G/lib/python3.13/site-packages/pimmslearn/sampling.py:210: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n  scale=float(0.3 * df_long.std()),\n</pre> In\u00a0[17]: Copied! <pre>cf_model = CollaborativeFilteringTransformer(\n    target_column=\"intensity\",\n    sample_column=\"Sample ID\",\n    item_column=\"protein group\",\n    out_folder=\"runs/scikit_interface\",\n)\n\ncf_model.fit(splits.train_X, splits.val_y, cuda=False, epochs_max=20)\n</pre> cf_model = CollaborativeFilteringTransformer(     target_column=\"intensity\",     sample_column=\"Sample ID\",     item_column=\"protein group\",     out_folder=\"runs/scikit_interface\", )  cf_model.fit(splits.train_X, splits.val_y, cuda=False, epochs_max=20) <pre>suggested_lr.valley = 0.00525\n</pre> epoch train_loss valid_loss time 0 6.320165 6.174103 00:00 1 5.522466 4.395256 00:00 2 3.587925 2.049297 00:00 3 2.431448 1.833395 00:00 4 1.831739 1.518024 00:00 5 1.435816 1.355048 00:00 6 1.189103 1.294942 00:00 7 1.034226 1.249249 00:00 8 0.919461 1.232482 00:00 9 0.839021 1.222002 00:00 10 0.773871 1.213310 00:00 11 0.722318 1.214855 00:00 <pre>No improvement since epoch 10: early stopping\n</pre> Out[17]: <pre>CollaborativeFilteringTransformer(item_column='protein group',\n                                  out_folder=Path('runs/scikit_interface'),\n                                  sample_column='Sample ID',\n                                  target_column='intensity')</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.CollaborativeFilteringTransformeriFitted<pre>CollaborativeFilteringTransformer(item_column='protein group',\n                                  out_folder=Path('runs/scikit_interface'),\n                                  sample_column='Sample ID',\n                                  target_column='intensity')</pre> In\u00a0[18]: Copied! <pre>df_imputed = cf_model.transform(df).unstack()\nassert df_imputed.isna().sum().sum() == 0\n</pre> df_imputed = cf_model.transform(df).unstack() assert df_imputed.isna().sum().sum() == 0 In\u00a0[19]: Copied! <pre>df_imputed = df_imputed.stack()  # long-format\nobserved = df_imputed.loc[df.index]\nimputed = df_imputed.loc[df_imputed.index.difference(df.index)]\ndf_imputed = df_imputed.unstack()  # back to wide-format\n# some checks\nassert len(df) == len(observed)\nassert df_imputed.shape[0] * df_imputed.shape[1] == len(imputed) + len(observed)\n\nfig, axes = plt.subplots(2, figsize=(8, 4))\n\nmin_max = pmp.data.get_min_max_iterable([observed, imputed])\nlabel_template = \"{method} (N={n:,d})\"\nax, _ = pmp.data.plot_histogram_intensities(\n    observed,\n    ax=axes[0],\n    min_max=min_max,\n    label=label_template.format(\n        method=\"measured\",\n        n=len(observed),\n    ),\n    color=\"grey\",\n    alpha=1,\n)\n_ = ax.legend()\nax, _ = pmp.data.plot_histogram_intensities(\n    imputed,\n    ax=axes[1],\n    min_max=min_max,\n    label=label_template.format(\n        method=\"CF imputed\",\n        n=len(imputed),\n    ),\n    color=color_model_mapping[\"CF\"],\n    alpha=1,\n)\n_ = ax.legend()\n</pre> df_imputed = df_imputed.stack()  # long-format observed = df_imputed.loc[df.index] imputed = df_imputed.loc[df_imputed.index.difference(df.index)] df_imputed = df_imputed.unstack()  # back to wide-format # some checks assert len(df) == len(observed) assert df_imputed.shape[0] * df_imputed.shape[1] == len(imputed) + len(observed)  fig, axes = plt.subplots(2, figsize=(8, 4))  min_max = pmp.data.get_min_max_iterable([observed, imputed]) label_template = \"{method} (N={n:,d})\" ax, _ = pmp.data.plot_histogram_intensities(     observed,     ax=axes[0],     min_max=min_max,     label=label_template.format(         method=\"measured\",         n=len(observed),     ),     color=\"grey\",     alpha=1, ) _ = ax.legend() ax, _ = pmp.data.plot_histogram_intensities(     imputed,     ax=axes[1],     min_max=min_max,     label=label_template.format(         method=\"CF imputed\",         n=len(imputed),     ),     color=color_model_mapping[\"CF\"],     alpha=1, ) _ = ax.legend() In\u00a0[20]: Copied! <pre>splits.to_wide_format()\nsplits.val_y = pd.DataFrame(pd.NA, index=splits.train_X.index, columns=splits.train_X.columns).fillna(splits.val_y)\n</pre> splits.to_wide_format() splits.val_y = pd.DataFrame(pd.NA, index=splits.train_X.index, columns=splits.train_X.columns).fillna(splits.val_y) In\u00a0[21]: Copied! <pre>model_selected = \"DAE\"\n\nmodel = AETransformer(\n    model=model_selected,\n    hidden_layers=[512],\n    latent_dim=50,\n    out_folder=\"runs/scikit_interface\",\n    batch_size=10,\n)\n</pre> model_selected = \"DAE\"  model = AETransformer(     model=model_selected,     hidden_layers=[512],     latent_dim=50,     out_folder=\"runs/scikit_interface\",     batch_size=10, ) In\u00a0[22]: Copied! <pre>model.fit(splits.train_X, splits.val_y, epochs_max=50, cuda=False)\n</pre> model.fit(splits.train_X, splits.val_y, epochs_max=50, cuda=False) epoch train_loss valid_loss time 0 31082.289062 1663.821411 00:00 1 29537.611328 1580.292236 00:00 2 27614.193359 1379.376953 00:00 3 25691.705078 1447.400391 00:00 4 24164.673828 1423.883423 00:00 5 22979.968750 1181.390015 00:00 6 21837.660156 1150.241577 00:00 7 20585.669922 1149.429443 00:00 8 19582.843750 1130.486206 00:00 9 18656.513672 1136.786377 00:00 10 18028.900391 1183.855469 00:00 11 17458.158203 1220.037476 00:00 12 16862.056641 1204.772095 00:00 13 16387.130859 1181.086670 00:00 14 15914.469727 1175.465820 00:00 15 15412.682617 1172.427368 00:00 16 14872.686523 1138.039551 00:00 17 14321.765625 1118.993286 00:00 18 13806.336914 1138.566040 00:00 19 13332.366211 1119.463257 00:00 20 12888.664062 1118.378662 00:00 21 12363.695312 1109.387085 00:00 22 11877.583008 1104.461548 00:00 23 11523.218750 1100.300537 00:00 24 11178.151367 1109.922119 00:00 25 10833.538086 1103.574463 00:00 26 10543.821289 1106.167847 00:00 27 10258.711914 1107.717651 00:00 28 9946.045898 1100.307251 00:00 29 9641.920898 1093.588257 00:00 30 9378.814453 1095.416016 00:00 31 9125.350586 1090.117310 00:00 32 8903.874023 1085.963135 00:00 33 8626.411133 1087.794922 00:00 34 8382.924805 1089.914551 00:00 35 8222.190430 1089.441284 00:00 36 7962.709961 1080.896240 00:00 37 7748.377930 1073.487915 00:00 38 7572.700195 1073.060303 00:00 39 7424.407715 1074.218140 00:00 40 7307.616211 1078.132324 00:00 41 7132.653809 1077.919922 00:00 42 7049.728516 1077.697388 00:00 43 6878.440918 1074.800903 00:00 44 6760.032715 1074.024658 00:00 45 6639.622559 1071.721191 00:00 46 6609.085938 1075.444824 00:00 47 6488.123047 1074.282593 00:00 48 6376.672363 1073.937500 00:00 49 6316.729492 1074.901123 00:00 Out[22]: <pre>AETransformer(batch_size=10, hidden_layers=[512], latent_dim=50,\n              model=&lt;class 'pimmslearn.models.ae.Autoencoder'&gt;,\n              out_folder=Path('runs/scikit_interface'))</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.AETransformeriFitted<pre>AETransformer(batch_size=10, hidden_layers=[512], latent_dim=50,\n              model=&lt;class 'pimmslearn.models.ae.Autoencoder'&gt;,\n              out_folder=Path('runs/scikit_interface'))</pre> In\u00a0[23]: Copied! <pre>df_imputed = model.transform(splits.train_X).stack()\n</pre> df_imputed = model.transform(splits.train_X).stack() In\u00a0[24]: Copied! <pre>pred_val = splits.val_y.stack().to_frame(\"observed\")\npred_val[model_selected] = df_imputed\nval_metrics = pmm.calculte_metrics(pred_val, \"observed\")\n\nfig, ax = plt.subplots(figsize=(8, 2))\n\nax, errors_binned = pmp.errors.plot_errors_by_median(\n    pred=pred_val,\n    target_col=\"observed\",\n    feat_medians=splits.train_X.median(),\n    ax=ax,\n    metric_name=\"MAE\",\n    palette=color_model_mapping,\n)\n</pre> pred_val = splits.val_y.stack().to_frame(\"observed\") pred_val[model_selected] = df_imputed val_metrics = pmm.calculte_metrics(pred_val, \"observed\")  fig, ax = plt.subplots(figsize=(8, 2))  ax, errors_binned = pmp.errors.plot_errors_by_median(     pred=pred_val,     target_col=\"observed\",     feat_medians=splits.train_X.median(),     ax=ax,     metric_name=\"MAE\",     palette=color_model_mapping, ) <pre>/Users/jl/.local/share/virtualenvs/msmu-c3VCzU_G/lib/python3.13/site-packages/seaborn/categorical.py:641: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grouped_vals = vals.groupby(grouper)\n/Users/jl/.local/share/virtualenvs/msmu-c3VCzU_G/lib/python3.13/site-packages/seaborn/categorical.py:641: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grouped_vals = vals.groupby(grouper)\n</pre> In\u00a0[25]: Copied! <pre>splits.to_long_format()\ndf_imputed = df_imputed.replace(splits.val_y).replace(splits.test_y)\n</pre> splits.to_long_format() df_imputed = df_imputed.replace(splits.val_y).replace(splits.test_y) In\u00a0[26]: Copied! <pre>observed = df_imputed.loc[df.index].squeeze()\nimputed = df_imputed.loc[df_imputed.index.difference(df.index)].squeeze()\n\nfig, axes = plt.subplots(2, figsize=(8, 4))\n\nmin_max = pmp.data.get_min_max_iterable([observed, imputed])\n\nlabel_template = \"{method} (N={n:,d})\"\nax, _ = pmp.data.plot_histogram_intensities(\n    observed,\n    ax=axes[0],\n    min_max=min_max,\n    label=label_template.format(\n        method=\"measured\",\n        n=len(observed),\n    ),\n    color=\"grey\",\n    alpha=1,\n)\n_ = ax.legend()\nax, _ = pmp.data.plot_histogram_intensities(\n    imputed,\n    ax=axes[1],\n    min_max=min_max,\n    label=label_template.format(\n        method=f\"{model_selected} imputed\",\n        n=len(imputed),\n    ),\n    color=color_model_mapping[model_selected],\n    alpha=1,\n)\n_ = ax.legend()\n</pre> observed = df_imputed.loc[df.index].squeeze() imputed = df_imputed.loc[df_imputed.index.difference(df.index)].squeeze()  fig, axes = plt.subplots(2, figsize=(8, 4))  min_max = pmp.data.get_min_max_iterable([observed, imputed])  label_template = \"{method} (N={n:,d})\" ax, _ = pmp.data.plot_histogram_intensities(     observed,     ax=axes[0],     min_max=min_max,     label=label_template.format(         method=\"measured\",         n=len(observed),     ),     color=\"grey\",     alpha=1, ) _ = ax.legend() ax, _ = pmp.data.plot_histogram_intensities(     imputed,     ax=axes[1],     min_max=min_max,     label=label_template.format(         method=f\"{model_selected} imputed\",         n=len(imputed),     ),     color=color_model_mapping[model_selected],     alpha=1, ) _ = ax.legend() In\u00a0[27]: Copied! <pre>mdata.mod[\"protein\"].layers[\"imputed\"] = df_imputed.unstack()\nmdata.update()\n\nmdata\n</pre> mdata.mod[\"protein\"].layers[\"imputed\"] = df_imputed.unstack() mdata.update()  mdata <pre>/var/folders/pp/7ts5fh4x5hl81rnn895l34ph0000gn/T/ipykernel_17793/3088553350.py:1: ImplicitModificationWarning: Setting element `.layers['imputed']` of view, initializing view as actual.\n  mdata.mod[\"protein\"].layers[\"imputed\"] = df_imputed.unstack()\n</pre> Out[27]: <pre>MuData object with n_obs \u00d7 n_vars = 70 \u00d7 95925\n  obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n  uns:\t'_cmd'\n  3 modalities\n    psm:\t70 x 74025\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value', 'rt', 'calcmass', 'cell'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n      layers:\t'raw'\n    peptide:\t70 x 18846\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value', 'protein_group', 'peptide_type'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'\n    protein:\t70 x 3054\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'count_psm', 'count_stripped_peptide', 'PEP', 'q_value'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'\n      layers:\t'imputed'</pre> In\u00a0[28]: Copied! <pre>mdata.write_h5mu(\"MSV000089280.h5mu\")\n</pre> mdata.write_h5mu(\"MSV000089280.h5mu\")"},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#process-proteomics-data-from-sage-with-msmu","title":"Process Proteomics Data from Sage with msmu\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#psm","title":"PSM\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#peptide","title":"Peptide\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#filtering-peptide","title":"Filtering - peptide\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#normalisation","title":"Normalisation\u00b6","text":"<p>Here, we log2 transform and normalise the data at the peptide level.</p> <p>Median centering normalisation is applied using <code>mm.pp.normalise()</code> function.</p>"},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#protein-inference","title":"Protein inference\u00b6","text":"<p>You can infer protein-level data from peptide-level data using the <code>mm.pp.infer_protein()</code> function.</p>"},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#protein","title":"Protein\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#filtering-protein","title":"Filtering - protein\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#imputation","title":"Imputation\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#check-missing-value-pattern","title":"Check missing value pattern\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#robust-missing-value-imputation","title":"Robust missing value imputation\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#check-imputation-results","title":"Check imputation results\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#imputation-with-denoising-autoencoder","title":"Imputation with denoising autoencoder\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#check-imputation-results","title":"Check imputation results\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#push-imputed-data-to-mudata-object","title":"Push imputed data to mudata object\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#save-mudata-object","title":"Save MuData object\u00b6","text":""},{"location":"tutorials/2024_Fulcher/03_handle_multi-omics_data/","title":"03 Handle Multi-omics Data","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport msmu as mm\nimport mofax as mofa\nimport muon as mu\nimport pandas as pd\nimport requests\nimport scanpy as sc\nimport seaborn as sns\n\nplt.rcParams[\"font.family\"] = \"Arial\"\n\nrandom_state = 42\n</pre> import matplotlib.pyplot as plt import msmu as mm import mofax as mofa import muon as mu import pandas as pd import requests import scanpy as sc import seaborn as sns  plt.rcParams[\"font.family\"] = \"Arial\"  random_state = 42 <pre>Determination of memory status is not supported on this \n platform, measuring for memoryleaks will never fail\n/Users/jl/.local/share/virtualenvs/msmu-c3VCzU_G/lib/python3.13/site-packages/muon/_core/preproc.py:31: FutureWarning: `__version__` is deprecated, use `importlib.metadata.version('scanpy')` instead\n  if Version(scanpy.__version__) &lt; Version(\"1.10\"):\n</pre> In\u00a0[2]: Copied! <pre>adata = sc.read_h5ad(\"GSE201575.h5ad\")\nmdata = mm.read_h5mu(\"MSV000089280.h5mu\")\nmdata.mod[\"rna\"] = adata\nmdata.update()\nmdata\n</pre> adata = sc.read_h5ad(\"GSE201575.h5ad\") mdata = mm.read_h5mu(\"MSV000089280.h5mu\") mdata.mod[\"rna\"] = adata mdata.update() mdata Out[2]: <pre>MuData object with n_obs \u00d7 n_vars = 70 \u00d7 109376\n  obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n  uns:\t'_cmd'\n  4 modalities\n    psm:\t70 x 74025\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value', 'cell'\n      uns:\t'acquisition', 'decoy', 'decoy_filter', 'filter', 'identification_file', 'label', 'level', 'quantification', 'quantification_file', 'search_engine'\n      varm:\t'filter', 'search_result'\n      layers:\t'raw'\n    peptide:\t70 x 18846\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value', 'protein_group', 'peptide_type'\n      uns:\t'decoy', 'decoy_filter', 'filter', 'level'\n      varm:\t'filter'\n    protein:\t70 x 3054\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'count_psm', 'count_stripped_peptide', 'PEP', 'q_value'\n      uns:\t'decoy', 'decoy_filter', 'filter', 'level'\n      varm:\t'filter'\n      layers:\t'imputed'\n    rna:\t70 x 13451\n      obs:\t'filename', 'set', 'sample_id', 'sample', 'cell', 'condition', 'sample_rna', 'n_genes'\n      var:\t'n_cells'\n      uns:\t'log1p'\n      layers:\t'counts'</pre> In\u00a0[3]: Copied! <pre>mdata.write_h5mu(\"multimodal.h5mu\")\n</pre> mdata.write_h5mu(\"multimodal.h5mu\") In\u00a0[4]: Copied! <pre>mdata = mm.read_h5mu(\"multimodal.h5mu\")\nmdata_subset = mu.MuData({\"protein\": mdata.mod[\"protein\"].copy(), \"rna\": mdata.mod[\"rna\"].copy()})\nmdata_subset.mod[\"protein\"].X = mdata_subset.mod[\"protein\"].layers[\"imputed\"]\n\nsc.pp.pca(mdata_subset.mod[\"rna\"])\nsc.pp.pca(mdata_subset.mod[\"protein\"])\nsc.pp.neighbors(mdata_subset.mod[\"rna\"], n_pcs=4)\nsc.pp.neighbors(mdata_subset.mod[\"protein\"], n_pcs=4)\n\n# Calculate weighted nearest neighbors (WNN)\nmu.pp.neighbors(mdata_subset, key_added=\"wnn\")\nmu.tl.umap(mdata_subset, neighbors_key=\"wnn\", random_state=random_state)\n\nmdata.obsm[\"WNN_UMAP\"] = mdata_subset.obsm[\"X_umap\"]\n</pre> mdata = mm.read_h5mu(\"multimodal.h5mu\") mdata_subset = mu.MuData({\"protein\": mdata.mod[\"protein\"].copy(), \"rna\": mdata.mod[\"rna\"].copy()}) mdata_subset.mod[\"protein\"].X = mdata_subset.mod[\"protein\"].layers[\"imputed\"]  sc.pp.pca(mdata_subset.mod[\"rna\"]) sc.pp.pca(mdata_subset.mod[\"protein\"]) sc.pp.neighbors(mdata_subset.mod[\"rna\"], n_pcs=4) sc.pp.neighbors(mdata_subset.mod[\"protein\"], n_pcs=4)  # Calculate weighted nearest neighbors (WNN) mu.pp.neighbors(mdata_subset, key_added=\"wnn\") mu.tl.umap(mdata_subset, neighbors_key=\"wnn\", random_state=random_state)  mdata.obsm[\"WNN_UMAP\"] = mdata_subset.obsm[\"X_umap\"] <pre>OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n/Users/jl/.local/share/virtualenvs/msmu-c3VCzU_G/lib/python3.13/site-packages/pynndescent/pynndescent_.py:939: UserWarning: Failed to correctly find n_neighbors for some samples. Results may be less than ideal. Try re-running with different parameters.\n  warn(\n/Users/jl/.local/share/virtualenvs/msmu-c3VCzU_G/lib/python3.13/site-packages/pynndescent/pynndescent_.py:939: UserWarning: Failed to correctly find n_neighbors for some samples. Results may be less than ideal. Try re-running with different parameters.\n  warn(\n</pre> In\u00a0[5]: Copied! <pre>fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(14, 4))\nmu.pl.embedding(\n    mdata,\n    basis=\"WNN_UMAP\",\n    color=\"cell\",\n    size=100,\n    title=\"WNN UMAP\",\n    ax=ax0,\n    legend_loc=\"on data\",\n    legend_fontoutline=2,\n    show=False,\n)\nmu.pl.embedding(\n    mdata,\n    basis=\"WNN_UMAP\",\n    color=\"P04223\",\n    size=100,\n    ax=ax1,\n    title=\"HA1K (Protein)\",\n    colorbar_loc=None,\n    show=False,\n    cmap=\"Blues\",\n)\nmu.pl.embedding(\n    mdata,\n    basis=\"WNN_UMAP\",\n    color=\"H2-K1\",\n    size=100,\n    ax=ax2,\n    title=\"\",\n    colorbar_loc=None,\n    show=False,\n    cmap=\"Reds\",\n)\n\n\nfig.colorbar(mappable=ax1.collections[0], ax=ax1, fraction=0.05, aspect=20, pad=0.02, shrink=0.875, anchor=(1, 0))\nfig.colorbar(mappable=ax2.collections[0], ax=ax2, fraction=0.05, aspect=20, pad=0.02, shrink=0.875, anchor=(1, 0))\n\nax1.collections[0].colorbar.set_label(\n    \"Intensity\\n(log$_2$)\",\n    rotation=0,\n    ha=\"left\",\n    va=\"bottom\",\n    x=0,\n    y=1.025,\n    labelpad=-30,\n)\nax2.collections[0].colorbar.set_label(\n    \"Read Count\\n(log$_{10}$)\",\n    rotation=0,\n    ha=\"left\",\n    va=\"bottom\",\n    x=0,\n    y=1.025,\n    labelpad=-24,\n)\nax2.text(0.5, 1.0175, \"H2-K1\", ha=\"right\", va=\"bottom\", transform=ax2.transAxes, fontstyle=\"italic\", size=12)\nax2.text(0.51, 1.0175, \"(RNA)\", ha=\"left\", va=\"bottom\", transform=ax2.transAxes, size=12)\n\nfig.savefig(\"Fig2B_WNN_UMAP.svg\", dpi=300, bbox_inches=\"tight\")\n</pre> fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(14, 4)) mu.pl.embedding(     mdata,     basis=\"WNN_UMAP\",     color=\"cell\",     size=100,     title=\"WNN UMAP\",     ax=ax0,     legend_loc=\"on data\",     legend_fontoutline=2,     show=False, ) mu.pl.embedding(     mdata,     basis=\"WNN_UMAP\",     color=\"P04223\",     size=100,     ax=ax1,     title=\"HA1K (Protein)\",     colorbar_loc=None,     show=False,     cmap=\"Blues\", ) mu.pl.embedding(     mdata,     basis=\"WNN_UMAP\",     color=\"H2-K1\",     size=100,     ax=ax2,     title=\"\",     colorbar_loc=None,     show=False,     cmap=\"Reds\", )   fig.colorbar(mappable=ax1.collections[0], ax=ax1, fraction=0.05, aspect=20, pad=0.02, shrink=0.875, anchor=(1, 0)) fig.colorbar(mappable=ax2.collections[0], ax=ax2, fraction=0.05, aspect=20, pad=0.02, shrink=0.875, anchor=(1, 0))  ax1.collections[0].colorbar.set_label(     \"Intensity\\n(log$_2$)\",     rotation=0,     ha=\"left\",     va=\"bottom\",     x=0,     y=1.025,     labelpad=-30, ) ax2.collections[0].colorbar.set_label(     \"Read Count\\n(log$_{10}$)\",     rotation=0,     ha=\"left\",     va=\"bottom\",     x=0,     y=1.025,     labelpad=-24, ) ax2.text(0.5, 1.0175, \"H2-K1\", ha=\"right\", va=\"bottom\", transform=ax2.transAxes, fontstyle=\"italic\", size=12) ax2.text(0.51, 1.0175, \"(RNA)\", ha=\"left\", va=\"bottom\", transform=ax2.transAxes, size=12)  fig.savefig(\"Fig2B_WNN_UMAP.svg\", dpi=300, bbox_inches=\"tight\") In\u00a0[6]: Copied! <pre>mdata = mm.read_h5mu(\"multimodal.h5mu\")\nmdata_subset = mu.MuData({\"protein\": mdata.mod[\"protein\"].copy(), \"rna\": mdata.mod[\"rna\"].copy()})\n\nmdata_subset\n</pre> mdata = mm.read_h5mu(\"multimodal.h5mu\") mdata_subset = mu.MuData({\"protein\": mdata.mod[\"protein\"].copy(), \"rna\": mdata.mod[\"rna\"].copy()})  mdata_subset Out[6]: <pre>MuData object with n_obs \u00d7 n_vars = 70 \u00d7 16505\n  2 modalities\n    protein:\t70 x 3054\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'count_psm', 'count_stripped_peptide', 'PEP', 'q_value'\n      uns:\t'decoy', 'decoy_filter', 'filter', 'level'\n      varm:\t'filter'\n      layers:\t'imputed'\n    rna:\t70 x 13451\n      obs:\t'filename', 'set', 'sample_id', 'sample', 'cell', 'condition', 'sample_rna', 'n_genes'\n      var:\t'n_cells'\n      uns:\t'log1p'\n      layers:\t'counts'</pre> In\u00a0[7]: Copied! <pre>mu.tl.mofa(mdata_subset, outfile=\"multimodal_model.hdf5\", seed=random_state)\n</pre> mu.tl.mofa(mdata_subset, outfile=\"multimodal_model.hdf5\", seed=random_state) <pre>\n        #########################################################\n        ###           __  __  ____  ______                    ### \n        ###          |  \\/  |/ __ \\|  ____/\\    _             ### \n        ###          | \\  / | |  | | |__ /  \\ _| |_           ### \n        ###          | |\\/| | |  | |  __/ /\\ \\_   _|          ###\n        ###          | |  | | |__| | | / ____ \\|_|            ###\n        ###          |_|  |_|\\____/|_|/_/    \\_\\              ###\n        ###                                                   ### \n        ######################################################### \n       \n \n        \n</pre> <pre>Loaded view='protein' group='group1' with N=70 samples and D=3054 features...\nLoaded view='rna' group='group1' with N=70 samples and D=13451 features...\n\n\nModel options:\n- Automatic Relevance Determination prior on the factors: True\n- Automatic Relevance Determination prior on the weights: True\n- Spike-and-slab prior on the factors: False\n- Spike-and-slab prior on the weights: True\nLikelihoods:\n- View 0 (protein): gaussian\n- View 1 (rna): gaussian\n\n\n\n\n######################################\n## Training the model with seed 42 ##\n######################################\n\n\n\nConverged!\n\n\n\n#######################\n## Training finished ##\n#######################\n\n\nWarning: Output file multimodal_model.hdf5 already exists, it will be replaced\nSaving model in multimodal_model.hdf5...\nSaved MOFA embeddings in .obsm['X_mofa'] slot and their loadings in .varm['LFs'].\n</pre> In\u00a0[8]: Copied! <pre>model = mofa.mofa_model(\"multimodal_model.hdf5\")\nmodel\n</pre> model = mofa.mofa_model(\"multimodal_model.hdf5\") model Out[8]: <pre>MOFA+ model: multimodal model\nSamples (cells): 70\nFeatures: 16505\nGroups: group1 (70)\nViews: protein (3054), rna (13451)\nFactors: 10\nExpectations: W, Z</pre> In\u00a0[9]: Copied! <pre>r2 = model.get_variance_explained(views=[\"protein\", \"rna\"])\n\nr2[\"View\"] = r2[\"View\"].map({\"protein\": \"Protein\", \"rna\": \"RNA\"})\nr2[\"Factor\"] = pd.Categorical(\n    r2[\"Factor\"],\n    categories=[f\"Factor{i+1}\" for i in range(r2[\"Factor\"].nunique())],\n    ordered=True,\n)\nr2_mat = r2.pivot_table(index=\"Factor\", columns=\"View\", values=\"R2\")\n\n# Plot\nfig = plt.figure(figsize=(3, 5))\nax = sns.heatmap(\n    r2_mat,\n    cmap=\"Greens\",\n    linecolor=\"black\",\n    linewidth=0.5,\n    fmt=\".2f\",\n    cbar_kws=dict(shrink=0.9, anchor=(1, 0), aspect=25, pad=0.05, fraction=0.15),\n)\n\nax.collections[0].colorbar.set_label(\n    \"Explained\\nVariance (%)\",\n    rotation=0,\n    ha=\"left\",\n    va=\"bottom\",\n    x=0,\n    y=1.025,\n    labelpad=-30,\n)\nax.invert_yaxis()\n\nfor spine in ax.spines.values():\n    spine.set_edgecolor(\"black\")\n    spine.set_linewidth(0.75)\n    spine.set_visible(True)\n\ncbar = ax.collections[0].colorbar\ncbar.set_ticks([0, 5, 10, 15])\n\nfor spine in cbar.ax.spines.values():\n    spine.set_edgecolor(\"black\")\n    spine.set_linewidth(0.75)\n\nfig.tight_layout()\nfig.show()\n\nfig.savefig(\"Fig2C_MOFA_R2.svg\", bbox_inches=\"tight\")\n</pre> r2 = model.get_variance_explained(views=[\"protein\", \"rna\"])  r2[\"View\"] = r2[\"View\"].map({\"protein\": \"Protein\", \"rna\": \"RNA\"}) r2[\"Factor\"] = pd.Categorical(     r2[\"Factor\"],     categories=[f\"Factor{i+1}\" for i in range(r2[\"Factor\"].nunique())],     ordered=True, ) r2_mat = r2.pivot_table(index=\"Factor\", columns=\"View\", values=\"R2\")  # Plot fig = plt.figure(figsize=(3, 5)) ax = sns.heatmap(     r2_mat,     cmap=\"Greens\",     linecolor=\"black\",     linewidth=0.5,     fmt=\".2f\",     cbar_kws=dict(shrink=0.9, anchor=(1, 0), aspect=25, pad=0.05, fraction=0.15), )  ax.collections[0].colorbar.set_label(     \"Explained\\nVariance (%)\",     rotation=0,     ha=\"left\",     va=\"bottom\",     x=0,     y=1.025,     labelpad=-30, ) ax.invert_yaxis()  for spine in ax.spines.values():     spine.set_edgecolor(\"black\")     spine.set_linewidth(0.75)     spine.set_visible(True)  cbar = ax.collections[0].colorbar cbar.set_ticks([0, 5, 10, 15])  for spine in cbar.ax.spines.values():     spine.set_edgecolor(\"black\")     spine.set_linewidth(0.75)  fig.tight_layout() fig.show()  fig.savefig(\"Fig2C_MOFA_R2.svg\", bbox_inches=\"tight\") In\u00a0[10]: Copied! <pre>def fetch_protein_name(accession):\n    url = f\"https://rest.uniprot.org/uniprotkb/{accession}\"\n    r = requests.get(url)\n    r.raise_for_status()\n    data = r.json()\n\n    name = data.get(\"uniProtkbId\", None)\n\n    return name.split(\"_\")[0]\n</pre> def fetch_protein_name(accession):     url = f\"https://rest.uniprot.org/uniprotkb/{accession}\"     r = requests.get(url)     r.raise_for_status()     data = r.json()      name = data.get(\"uniProtkbId\", None)      return name.split(\"_\")[0] In\u00a0[11]: Copied! <pre>df_f2 = model.get_weights(\n    views=\"protein\",\n    factors=1,\n    df=True,\n)\ndf_f2 = pd.melt(\n    df_f2.reset_index().rename(columns={\"index\": \"feature\"}),\n    id_vars=\"feature\",\n    var_name=\"factor\",\n    value_name=\"value\",\n)\ndf_f2[\"abs_value\"] = abs(df_f2.value)\ndf_f2[\"sign\"] = df_f2[\"value\"].apply(lambda x: \"Positive\" if x &gt;= 0 else \"Negative\")\ndf_f2[\"sign\"] = pd.Categorical(df_f2[\"sign\"], categories=[\"Positive\", \"Negative\"], ordered=True)\n\n# Assign ranks to features, per factor\ndf_f2[\"abs_rank\"] = df_f2.groupby(\"factor\")[\"abs_value\"].rank(ascending=False)\ndf_f2 = df_f2.sort_values([\"factor\", \"abs_rank\"], ascending=True)\ndf_f2 = df_f2[df_f2[\"abs_rank\"] &lt;= 15]\ndf_f2[\"gene\"] = df_f2[\"feature\"].apply(lambda x: fetch_protein_name(x))\n\nfig = plt.figure(figsize=(4, 5))\nax = sns.barplot(\n    data=df_f2,\n    x=\"abs_value\",\n    y=\"gene\",\n    hue=\"sign\",\n    dodge=False,\n    palette={\"Positive\": \"#5DA5D1\", \"Negative\": \"#D6E6F4\"},\n    width=0.75,\n    edgecolor=\"black\",\n)\n\nfor container, hatch in zip(ax.containers, [\"\", \"//\"]):\n    for bar in container:\n        bar.set_hatch(hatch)\n\nax.set_title(\"Protein\")\nax.xaxis.set_ticks([0, 0.5, 1.0, 1.5])\nax.set_xlabel(\"Absolute Weight\")\nax.set_ylabel(\"Top Factor2 Features\")\nax.legend(title=\"Direction\")\n\nfig.tight_layout()\nfig.savefig(\"Fig2D_f2_prot.svg\", bbox_inches=\"tight\")\n</pre> df_f2 = model.get_weights(     views=\"protein\",     factors=1,     df=True, ) df_f2 = pd.melt(     df_f2.reset_index().rename(columns={\"index\": \"feature\"}),     id_vars=\"feature\",     var_name=\"factor\",     value_name=\"value\", ) df_f2[\"abs_value\"] = abs(df_f2.value) df_f2[\"sign\"] = df_f2[\"value\"].apply(lambda x: \"Positive\" if x &gt;= 0 else \"Negative\") df_f2[\"sign\"] = pd.Categorical(df_f2[\"sign\"], categories=[\"Positive\", \"Negative\"], ordered=True)  # Assign ranks to features, per factor df_f2[\"abs_rank\"] = df_f2.groupby(\"factor\")[\"abs_value\"].rank(ascending=False) df_f2 = df_f2.sort_values([\"factor\", \"abs_rank\"], ascending=True) df_f2 = df_f2[df_f2[\"abs_rank\"] &lt;= 15] df_f2[\"gene\"] = df_f2[\"feature\"].apply(lambda x: fetch_protein_name(x))  fig = plt.figure(figsize=(4, 5)) ax = sns.barplot(     data=df_f2,     x=\"abs_value\",     y=\"gene\",     hue=\"sign\",     dodge=False,     palette={\"Positive\": \"#5DA5D1\", \"Negative\": \"#D6E6F4\"},     width=0.75,     edgecolor=\"black\", )  for container, hatch in zip(ax.containers, [\"\", \"//\"]):     for bar in container:         bar.set_hatch(hatch)  ax.set_title(\"Protein\") ax.xaxis.set_ticks([0, 0.5, 1.0, 1.5]) ax.set_xlabel(\"Absolute Weight\") ax.set_ylabel(\"Top Factor2 Features\") ax.legend(title=\"Direction\")  fig.tight_layout() fig.savefig(\"Fig2D_f2_prot.svg\", bbox_inches=\"tight\") In\u00a0[12]: Copied! <pre>df_f2 = model.get_weights(\n    views=\"rna\",\n    factors=1,\n    df=True,\n)\ndf_f2 = pd.melt(\n    df_f2.reset_index().rename(columns={\"index\": \"feature\"}),\n    id_vars=\"feature\",\n    var_name=\"factor\",\n    value_name=\"value\",\n)\ndf_f2[\"abs_value\"] = abs(df_f2.value)\ndf_f2[\"sign\"] = df_f2[\"value\"].apply(lambda x: \"Positive\" if x &gt;= 0 else \"Negative\")\ndf_f2[\"sign\"] = pd.Categorical(df_f2[\"sign\"], categories=[\"Positive\", \"Negative\"], ordered=True)\n\n# Assign ranks to features, per factor\ndf_f2[\"abs_rank\"] = df_f2.groupby(\"factor\")[\"abs_value\"].rank(ascending=False)\ndf_f2 = df_f2.sort_values([\"factor\", \"abs_rank\"], ascending=True)\ndf_f2 = df_f2[df_f2[\"abs_rank\"] &lt;= 15]\n\nfig = plt.figure(figsize=(4, 5))\nax = sns.barplot(\n    data=df_f2,\n    x=\"abs_value\",\n    y=\"feature\",\n    hue=\"sign\",\n    dodge=False,\n    palette={\"Positive\": \"#FF6262\", \"Negative\": \"#FCBEA5\"},\n    width=0.75,\n    edgecolor=\"black\",\n)\n\nfor container, hatch in zip(ax.containers, [\"\", \"//\"]):\n    for bar in container:\n        bar.set_hatch(hatch)\n\nax.set_title(\"RNA\")\nax.xaxis.set_ticks([0.0, 0.5, 1.0, 1.5, 2.0, 2.5])\nax.set_xlabel(\"Absolute Weight\")\nax.set_ylabel(\"Top Factor2 Features\")\nfor tick in ax.get_yticklabels():\n    tick.set_fontstyle(\"italic\")\nax.legend(title=\"Direction\")\n\nfig.tight_layout()\nfig.savefig(\"Fig2D_f2_rna.svg\", bbox_inches=\"tight\")\n</pre> df_f2 = model.get_weights(     views=\"rna\",     factors=1,     df=True, ) df_f2 = pd.melt(     df_f2.reset_index().rename(columns={\"index\": \"feature\"}),     id_vars=\"feature\",     var_name=\"factor\",     value_name=\"value\", ) df_f2[\"abs_value\"] = abs(df_f2.value) df_f2[\"sign\"] = df_f2[\"value\"].apply(lambda x: \"Positive\" if x &gt;= 0 else \"Negative\") df_f2[\"sign\"] = pd.Categorical(df_f2[\"sign\"], categories=[\"Positive\", \"Negative\"], ordered=True)  # Assign ranks to features, per factor df_f2[\"abs_rank\"] = df_f2.groupby(\"factor\")[\"abs_value\"].rank(ascending=False) df_f2 = df_f2.sort_values([\"factor\", \"abs_rank\"], ascending=True) df_f2 = df_f2[df_f2[\"abs_rank\"] &lt;= 15]  fig = plt.figure(figsize=(4, 5)) ax = sns.barplot(     data=df_f2,     x=\"abs_value\",     y=\"feature\",     hue=\"sign\",     dodge=False,     palette={\"Positive\": \"#FF6262\", \"Negative\": \"#FCBEA5\"},     width=0.75,     edgecolor=\"black\", )  for container, hatch in zip(ax.containers, [\"\", \"//\"]):     for bar in container:         bar.set_hatch(hatch)  ax.set_title(\"RNA\") ax.xaxis.set_ticks([0.0, 0.5, 1.0, 1.5, 2.0, 2.5]) ax.set_xlabel(\"Absolute Weight\") ax.set_ylabel(\"Top Factor2 Features\") for tick in ax.get_yticklabels():     tick.set_fontstyle(\"italic\") ax.legend(title=\"Direction\")  fig.tight_layout() fig.savefig(\"Fig2D_f2_rna.svg\", bbox_inches=\"tight\")"},{"location":"tutorials/2024_Fulcher/03_handle_multi-omics_data/#handle-multi-omics-data-with-msmu","title":"Handle multi-omics Data with msmu\u00b6","text":""},{"location":"tutorials/2024_Fulcher/03_handle_multi-omics_data/#merge-modalities","title":"Merge modalities\u00b6","text":""},{"location":"tutorials/2024_Fulcher/03_handle_multi-omics_data/#wnn-umap","title":"WNN UMAP\u00b6","text":""},{"location":"tutorials/2024_Fulcher/03_handle_multi-omics_data/#fig-2b","title":"Fig 2B\u00b6","text":""},{"location":"tutorials/2024_Fulcher/03_handle_multi-omics_data/#mofa","title":"MOFA\u00b6","text":""},{"location":"tutorials/2024_Fulcher/03_handle_multi-omics_data/#creating-model","title":"Creating Model\u00b6","text":""},{"location":"tutorials/2024_Fulcher/03_handle_multi-omics_data/#model-inspection","title":"Model Inspection\u00b6","text":""},{"location":"tutorials/2024_Fulcher/03_handle_multi-omics_data/#fig-2c","title":"Fig 2C\u00b6","text":""},{"location":"tutorials/2024_Fulcher/03_handle_multi-omics_data/#fig-2d","title":"Fig 2D\u00b6","text":""}]}