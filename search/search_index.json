{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"HOME","text":"<p>Python toolkit for modular and traceable LC-MS/MS proteomics analysis based on MuData</p>"},{"location":"#overview","title":"Overview","text":"<p><code>msmu</code> is an open-source Python package for modular and traceable post-DB search preprocessing and statistical analysis of bottom-up proteomics data.</p> <p>It supports modules for every step of end-to-end processing\u2014from search output parsing through hierarchical summarization, normalization, batch correction, statistical analysis, and visualization\u2014implemented with commonly used analytical and statistical methods. </p> <p>Central to <code>msmu</code> is the highly versatile and standardized <code>MuData</code> (and <code>AnnData</code>) as a unifying, provenance-aware data container for organizing and storing annotations and representations of multi-dimensional MS data and processing history.</p> <p>This unique marriage between flexible processing pipeline and <code>MuData</code> empowers FAIR principle-aligned downstream analysis for biomarker discovery and systems biology.</p> <p></p>"},{"location":"#key_features","title":"Key Features","text":"<ul> <li>Flexible data ingestion from Sage, DIA-NN, and other popular DB search tools</li> <li>MuData/AnnData-compatible object structure for organizing multi-level MS data</li> <li>Protein inference: infer protein groups from peptide evidence using parsimony rule</li> <li>Normalization: median centering, quantile normalization, etc.</li> <li>Batch correction for discrete and continuous variations</li> <li>Built-in QC: identification count, peptide length, charge, missed cleavage, intensity distribution, etc.</li> <li>Statistical analysis: differential expression analysis, dimensionality reduction</li> <li>PTM data support and stoichiometry adjustment with matched global dataset (if available)</li> <li>Visualization: PCA, UMAP, volcano plots, heatmaps, QC metrics</li> </ul>"},{"location":"#supporting_db_search_tools","title":"Supporting DB Search Tools","text":"<ul> <li>Sage: https://sage-docs.vercel.app</li> <li>DIA-NN: https://github.com/vdemichev/DIA-NN</li> <li>MaxQuant: https://www.maxquant.org/</li> <li>FragPipe: https://fragpipe.nesvilab.org/</li> <li>and more upcoming.</li> </ul>"},{"location":"#citation","title":"Citation","text":"<p>If you use <code>msmu</code> in your research, please cite the following publication (preprint):</p> <p>msmu: a Python toolkit for modular and traceable LC-MS proteomics data analysis based on MuData</p> <p>Hyung-Wook Choi, Byeongchan Lee, Un-Beom Kang, Sunghyun Huh</p> <p>bioRxiv 2026.01.07.698308; doi: 10.64898/2026.01.07.698308</p>"},{"location":"#license","title":"License","text":"<p>BSD 3-Clause License. See LICENSE for details.</p>"},{"location":"gen_ref_pages/","title":"Gen ref pages","text":"In\u00a0[\u00a0]: Copied! <pre># scripts/gen_ref_pages.py\nfrom pathlib import Path\nimport mkdocs_gen_files\nimport msmu\nimport inspect\n</pre> # scripts/gen_ref_pages.py from pathlib import Path import mkdocs_gen_files import msmu import inspect In\u00a0[\u00a0]: Copied! <pre>PACKAGE = \"msmu\"  # ./msmu \ub808\uc774\uc544\uc6c3 \uac00\uc815\nsrc_dir = Path(msmu.__file__).parent  # msmu/ \ub514\ub809\ud1a0\ub9ac\nnav = mkdocs_gen_files.Nav()\n</pre> PACKAGE = \"msmu\"  # ./msmu \ub808\uc774\uc544\uc6c3 \uac00\uc815 src_dir = Path(msmu.__file__).parent  # msmu/ \ub514\ub809\ud1a0\ub9ac nav = mkdocs_gen_files.Nav() In\u00a0[\u00a0]: Copied! <pre>def map_alias(name):\n    if name == \"pp\":\n        return \"preprocessing: &lt;b&gt;&lt;code&gt;pp&lt;/code&gt;&lt;/b&gt;\"\n    if name == \"pl\":\n        return \"plotting: &lt;b&gt;&lt;code&gt;pl&lt;/code&gt;&lt;/b&gt;\"\n    if name == \"tl\":\n        return \"tools: &lt;b&gt;&lt;code&gt;tl&lt;/code&gt;&lt;/b&gt;\"\n    return name\n</pre> def map_alias(name):     if name == \"pp\":         return \"preprocessing: <code>pp</code>\"     if name == \"pl\":         return \"plotting: <code>pl</code>\"     if name == \"tl\":         return \"tools: <code>tl</code>\"     return name In\u00a0[\u00a0]: Copied! <pre>def iterate_modules(parent, parent_alias=[]):\n    if not hasattr(parent, \"__all__\"):\n        return\n\n    for module_name in parent.__all__:\n        child = getattr(parent, module_name)\n        if child.__name__.startswith(\"_\"):\n            continue\n\n        if inspect.ismodule(child):\n            yield from iterate_modules(child, parent_alias + [module_name])\n\n        if inspect.isfunction(child) or inspect.isclass(child) or callable(child):\n            parts = parent_alias + [child.__name__]  # ['module', 'function']\n            ident = \".\".join([PACKAGE] + parts)  # msmu.module.function\n\n            doc = Path(\"reference\", *parts).with_suffix(\".md\")\n\n            with mkdocs_gen_files.open(doc, \"w\") as f:\n                f.write(\"---\\n\")\n                f.write(f\"title: '{child.__name__}'\\n\")\n                f.write(\"hide:\\n\")\n                f.write(\"  - toc\\n\")\n                f.write(\"---\\n\\n\")\n                f.write(f\"# `{ident}`\\n\\n::: {ident}\\n\")\n\n            nav[[map_alias(p) for p in parts]] = Path(\"reference\", *parts).with_suffix(\".md\").as_posix()\n\n            yield child.__name__, child\n</pre> def iterate_modules(parent, parent_alias=[]):     if not hasattr(parent, \"__all__\"):         return      for module_name in parent.__all__:         child = getattr(parent, module_name)         if child.__name__.startswith(\"_\"):             continue          if inspect.ismodule(child):             yield from iterate_modules(child, parent_alias + [module_name])          if inspect.isfunction(child) or inspect.isclass(child) or callable(child):             parts = parent_alias + [child.__name__]  # ['module', 'function']             ident = \".\".join([PACKAGE] + parts)  # msmu.module.function              doc = Path(\"reference\", *parts).with_suffix(\".md\")              with mkdocs_gen_files.open(doc, \"w\") as f:                 f.write(\"---\\n\")                 f.write(f\"title: '{child.__name__}'\\n\")                 f.write(\"hide:\\n\")                 f.write(\"  - toc\\n\")                 f.write(\"---\\n\\n\")                 f.write(f\"# `{ident}`\\n\\n::: {ident}\\n\")              nav[[map_alias(p) for p in parts]] = Path(\"reference\", *parts).with_suffix(\".md\").as_posix()              yield child.__name__, child In\u00a0[\u00a0]: Copied! <pre>list(iterate_modules(msmu))\n</pre> list(iterate_modules(msmu)) In\u00a0[\u00a0]: Copied! <pre># Add indents to the generated nav.md\nnav_template = Path(\"docs\", \"nav.md\").read_text()\nif not nav_template.endswith(\"\\n\"):\n    nav_template += \"\\n\"\n</pre> # Add indents to the generated nav.md nav_template = Path(\"docs\", \"nav.md\").read_text() if not nav_template.endswith(\"\\n\"):     nav_template += \"\\n\" In\u00a0[\u00a0]: Copied! <pre>def format_api(line):\n    return \"    \" + line.replace(\"\\\\\", \"\")\n</pre> def format_api(line):     return \"    \" + line.replace(\"\\\\\", \"\") In\u00a0[\u00a0]: Copied! <pre>api_nav = [format_api(line) for line in nav.build_literate_nav()]\nwith mkdocs_gen_files.open(\"nav.md\", \"w\") as nav_file:\n    nav_file.write(nav_template)\n    nav_file.writelines(api_nav)\n</pre> api_nav = [format_api(line) for line in nav.build_literate_nav()] with mkdocs_gen_files.open(\"nav.md\", \"w\") as nav_file:     nav_file.write(nav_template)     nav_file.writelines(api_nav)"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#requirements","title":"Requirements","text":"<ul> <li>Python 3.11 or newer</li> <li>(Recommended) A virtual environment such as <code>venv</code>, <code>pipenv</code>, or <code>uv</code></li> </ul>"},{"location":"installation/#install_with_pip","title":"Install with pip","text":"<p>It is strongly recommended to create virtual environment.</p>"},{"location":"installation/#from_source_distribution","title":"From Source Distribution","text":"pippipenv <pre><code>curl &lt;_RELEASE_BINARY_URL_&gt;\npip install msmu-&lt;version&gt;.tar.gz\npython -c \"import msmu; print('msmu:', msmu.__version__)\"\n</code></pre> <pre><code>curl &lt;_RELEASE_BINARY_URL_&gt;\npipenv install msmu-&lt;version&gt;.tar.gz\npipenv run python -c \"import msmu; print('msmu:', msmu.__version__)\"\n</code></pre>"},{"location":"installation/#from_pypi","title":"From PyPI","text":"pippipenv <pre><code>pip install msmu\npython -c \"import msmu; print('msmu:', msmu.__version__)\"\n</code></pre> <pre><code>pipenv install msmu\npipenv run python -c \"import msmu; print('msmu:', msmu.__version__)\"\n</code></pre>"},{"location":"installation/#from_source_repository","title":"From Source Repository","text":"<p>If you want the latest version from the repository:</p> pippipenv <pre><code>git clone https://github.com/bertis-informatics/msmu.git\ncd msmu\npip install -e .\npython -c \"import msmu; print('msmu:', msmu.__version__)\"\n</code></pre> <pre><code>git clone https://github.com/bertis-informatics/msmu.git\ncd msmu\npipenv install -e .\npipenv run python -c \"import msmu; print('msmu:', msmu.__version__)\"\n</code></pre>"},{"location":"nav/","title":"Nav","text":"<ul> <li>HOME</li> <li>INSTALLATION</li> <li>TUTORIALS<ul> <li><code>QUICK START</code></li> <li>DDA-TMT</li> <li>DDA-LFQ</li> <li>DIA-LFQ</li> <li>DE Analysis</li> <li>PTM Processing</li> <li>DDA-LFQ w. FlashLFQ</li> <li>2024 Fulcher et al.<ul> <li>01 Process scRNAseq Data</li> <li>02 Process Proteomics Data</li> <li>03 Handle Multi-omics Data</li> </ul> </li> </ul> </li> <li>HOW IT WORKS<ul> <li>Data</li> <li>Filter</li> <li>Normalization</li> <li>Batch Correction</li> <li>Summarization</li> <li>Protein Inference</li> <li>Precursor Isolation Purity</li> <li>DE Analysis</li> <li>Visualization</li> </ul> </li> <li>API<ul> <li>read_h5mu</li> <li>read_sage</li> <li>read_diann</li> <li>read_maxquant</li> <li>read_fragpipe</li> <li>merge_mudata</li> <li>preprocessing: <code>pp</code><ul> <li>add_filter</li> <li>apply_filter</li> <li>log2_transform</li> <li>normalise</li> <li>normalize</li> <li>correct_batch_effect</li> <li>to_peptide</li> <li>to_protein</li> <li>to_ptm</li> <li>infer_protein</li> <li>adjust_ptm_by_protein</li> <li>scale_data</li> </ul> </li> <li>plotting: <code>pl</code><ul> <li>plot_correlation</li> <li>plot_id</li> <li>plot_intensity</li> <li>plot_missingness</li> <li>plot_pca</li> <li>plot_umap</li> <li>plot_upset</li> <li>plot_var</li> </ul> </li> <li>tools: <code>tl</code><ul> <li>compute_precursor_isolation_purity</li> <li>compute_precursor_isolation_purity_from_mzml</li> <li>pca</li> <li>umap</li> <li>corr</li> <li>run_de</li> <li>PermTestResult</li> <li>StatTestResult</li> </ul> </li> <li>utils<ul> <li>subset</li> <li>split_tmt</li> <li>get_modality_dict</li> <li>map_fasta</li> <li>attach_fasta</li> <li>get_label</li> <li>uns_logger</li> <li>add_quant</li> <li>reindex_obs</li> <li>select_repr_protein</li> <li>parse_uniprot_accession</li> </ul> </li> <li>io<ul> <li>read_sage</li> <li>read_diann</li> <li>read_maxquant</li> <li>read_fragpipe</li> <li>to_readable</li> <li>write_csv</li> <li>write_flashlfq_input</li> </ul> </li> </ul> </li> </ul>"},{"location":"how-it-works/batch_correction/","title":"Batch Correction","text":""},{"location":"how-it-works/batch_correction/#overview","title":"Overview","text":"<p>Batch effects are unwanted variations in the data that arise from differences in experimental conditions, such as different lots, runs, days, or operators. These variations can obscure true biological signals and lead to misleading conclusions. <code>msmu</code> provides functions to correct for discrete batch effects using methods like median centering and GIS/IRS for TMT data. Support for batch effects arising from continuous variables (e.g., run order) will be added in future releases.</p>"},{"location":"how-it-works/batch_correction/#correct_batch_effect","title":"<code>correct_batch_effect()</code>","text":"<p>The <code>correct_batch_effect()</code> function either:</p> <ul> <li>Median centering, which standardizes each features to have zero median (can be re-scaled).</li> <li>GIS/IRS normalization, which rescales and corrects batch effect in TMT data using Global Internal Standard (GIS) channels.</li> <li>Combat batch effect correction (pycombat).</li> <li>Continuous batch effect correction using lowess regression (referred from Diagnostics and correction of batch effects in large\u2010scale proteomic studies: a tutorial).</li> </ul> <pre><code>mdata = mm.pp.correct_batch_effect(\n    mdata,\n    modality=\"feature\",                      # or \"peptide\", \"protein\"\n    layer=None,                              # layer to correct, default is .X\n    category=\"batch\",                        # batch information column in .obs\n    method=\"gis\",                            # options: \"median_center\", \"gis\", \"combat\", \"continuous\"\n    rescale=True,                            # whether to rescale data with median value of original data. Default is True (for GIS, median_center, continuous)\n    gis_sample=[\"POOLED_1\", \"POOLED_2\"],     # GIS channel names (for TMT data only)\n    drop_gis=True,                           # whether to drop GIS channels after correction. Default is True\n    log_transformed=True                     # whether data is log-transformed. Default is True\n)\n\n# or\nmdata = mm.pp.correct_batch_effect(\n    mdata,\n    modality=\"feature\",            \n    category=\"batch\",\n    method=\"median_center\",\n)\n\n# or\nmdata = mm.pp.correct_batch_effect(\n    mdata,\n    modality=\"protein\",\n    category=\"run_order\",\n    method=\"continuous\",\n)\n</code></pre>"},{"location":"how-it-works/data/","title":"Data in msmu","text":""},{"location":"how-it-works/data/#overview","title":"Overview","text":"<p>In LC-MS/MS \"shotgun\" <code>proteomics</code>, data analysis typically follows a hierarchical path\u2014starting from PSM-level data (PSM or precursor), progressing to peptides, and finally reaching proteins. Each stage introduces its own set of feature annotations, quantification matrices, and tool-specific metadata. As a result, shotgun proteomics data naturally form a multi-level and multi-dimensional structure: PSM/precursor, peptide, protein; feature metadata; sample annotations; and QC metrics.</p> <p>To manage these properties consistently, <code>msmu</code> adopts <code>MuData</code> from the <code>scverse</code> ecosystem as the fundamental data format. <code>MuData</code>, together with its constituent <code>AnnData</code> objects, is widely used in scRNA-seq to manage complex data matrices and their associated metadata. The same structure fits proteomics naturally: identification-level attributes, quantification values, and sample information can all be stored cleanly and explored in an integrated way.</p> <p><code>msmu</code> works with data formatted as a <code>MuData</code> object composed of multiple <code>AnnData</code> modalities. Therefore, understanding the usage of <code>MuData</code> and <code>AnnData</code> helps when working with <code>msmu</code>.</p> <p>A <code>MuData</code> object used in <code>msmu</code> is organized by modalities, each corresponding to a specific processing level such as <code>psm</code>, <code>peptide</code>, and <code>protein</code>:</p> <pre><code>mdata\n</code></pre> <pre><code>mdata[\"psm\"]\n\n# or\nmdata[\"protein\"]\n</code></pre> <p>As a general AnnData object, each individual modality contains <code>.X</code>, <code>.var</code>, <code>.varm</code>, <code>.obs</code>, <code>.obsm</code>, <code>.uns</code>, etc.</p> <ul> <li><code>.X</code> is a matrix holding the quantification data.</li> <li><code>.var</code> is a dataframe containing metadata of features for each level. As an example, <code>.var</code> in <code>psm</code> modality (for PSMs or precursors) contains information describing scan number, filename, PEP, q-value, etc., with <code>filename.scan</code> as index.</li> <li><code>.varm</code> is a dictionary-like structure to store additional per-feature matrices, such as boolean masks for filtering features.</li> <li><code>.obs</code> is a dataframe containing metadata of samples, such as sample name, condition, replicate number, etc., with <code>filename</code> or <code>channel</code> as index.</li> <li><code>.obsm</code> is a dictionary-like structure to store additional per-sample matrices, such as PCA or UMAP coordinates.</li> <li><code>.uns</code> is a dictionary-like structure to store unstructured annotations, such as decoy features pulled from search results.</li> <li><code>.layers</code> is a dictionary-like structure to store additional per-feature quantification matrices, such as imputed values. Some functions in <code>msmu</code> provide options to read from or write to <code>.layers</code>.</li> </ul> <p></p>"},{"location":"how-it-works/data/#data_ingestion_from_db_search_tools","title":"Data Ingestion from DB search tools","text":"<p>Although different search tools return result files with heterogenous formats, their contents can typically be organized into two main conceptual parts to construct peptide- and protein-level data.</p> <ul> <li>Identification data - Identified features with associated annotations</li> <li>Quantification data - Quantitative values for features across samples</li> </ul> <p><code>read_*</code> functions in <code>msmu</code> extract the essential columns required for QC and downstream processing and migrate them into the <code>.var</code> of the <code>psm</code> modality. <code>read_*</code> functions are implemented in <code>msmu/_read_write/_reader_registry</code></p> <ul> <li><code>read_*</code> functions (currently available)<ul> <li><code>read_sage()</code></li> <li><code>read_diann()</code></li> <li><code>read_maxquant()</code></li> <li><code>read_fragpipe()</code></li> </ul> </li> <li>Inputs<ul> <li><code>identification_file</code>: A file path to identification data</li> <li><code>quantification_file</code>: A file path to quantification data (if applicable) (for tools outputting separate quantification files like Sage)</li> <li><code>label</code>: used label (<code>tmt</code> or <code>label_free</code>)</li> <li><code>acquisition</code>: acquisition method (<code>dda</code>, or <code>dia</code>) (for tools supporting both DDA and DIA like MaxQuant)</li> </ul> </li> <li>Output<ul> <li><code>mudata</code>: Data ingested MuData object</li> </ul> </li> <li>Columns migrated into <code>mdata[\"psm\"].var</code><ul> <li><code>filename</code>, <code>peptide</code>(modified), <code>stripped_peptide</code>, <code>scan_num</code>, <code>proteins</code>, <code>missed_cleavages</code>, <code>peptide_length</code>, <code>charge</code>, <code>PEP</code>, <code>q-value</code></li> </ul> </li> <li>Decoy features are isolated from <code>.var</code> and stored in <code>.uns[\"decoy\"]</code> for later use in FDR calculation.</li> <li>Quantification data for LFQ (DDA) is stored in <code>peptide</code> modality.</li> <li>Raw information from a search tool is stored in <code>mdata[\"psm\"].varm[\"search_result\"]</code></li> </ul> <pre><code>mdata = mm.read_sage(\n    identification_file=\"path/to/results.sage.tsv\",\n    quantification_file=\"path/to/tmt.tsv\",\n    label=\"tmt\",  # or \"label_free\"\n)\n\nmdata = mm.read_diann(\n    identification_file=\"path/to/report.tsv\",\n)\n\nmdata = mm.read_maxquant(\n    identification_file=\"path/to/output_file\",\n    label=\"tmt\",  # or \"label_free\"\n    acquisition=\"dda\",  # or \"dia\"\n)\n\nmdata = mm.read_fragpipe(\n    identification_file=\"path/to/output_file/psm.tsv\",\n    quantification_file=\"path/to/quantification_file/combined_modified_peptide.tsv\", # for LFQ\n    label=\"tmt\",  # or \"label_free\"\n)\n</code></pre>"},{"location":"how-it-works/dea/","title":"Differential Expression (DE) Analysis","text":""},{"location":"how-it-works/dea/#overview","title":"Overview","text":"<p>Differential Expression (DE) Analysis identifies proteins or peptides with significant abundance changes between experimental conditions. <code>msmu</code> provides permutation-based statistical testing to assess differential expression while controlling the false discovery rate (FDR).</p>"},{"location":"how-it-works/dea/#mmtlrun_de","title":"<code>mm.tl.run_de()</code>","text":"<p>The <code>run_de()</code> function performs a non-parametric permutation test to evaluate differential expression between two groups. It calculates p-values based on the distribution of test statistics obtained from permuted group labels.</p> <p>This function uses Welch's t-statistic by default, which is suitable for unequal variances between groups. Other statistics such as Student's t-statistics, Wilcoxon's W-statistics (rank-sum) test, and median difference are also available.</p> <p>For multiple testing correction, <code>msmu</code> supports empirical FDR, and Benjamini-Hochberg method. Empirical FDR is recommended when using permutation tests.</p> <p><code>n_resamples</code> specifies the number of random permutations to generate the null distribution. If set to <code>None</code>, a simple hypothesis test without permutations is performed. The default of <code>1000</code> permutations provides a practical balance between statistical accuracy and computational cost.</p> <p>If sample sizes are too small to meet <code>n_resamples</code>, all possible permutations are used to compute exact p-values (exact test).</p> <p>Log2 fold-change (<code>log2FC</code>) between the two groups is calculated as the difference of log2-transformed median values.</p> <p><code>p-value</code> from the test is computed with the proportion of permuted statistics that are as extreme or more extreme than the observed statistic in null distribution with two-sided test.</p> <p><code>q-value</code> with <code>empirical</code> FDR is calculated by <code>E[FDR] = pi0 * E[FP] / E[TP]</code> referred to Yang Xie et al., Bioinformatics, 2011. and Storey et al., 2003.</p> <p>See more details in the <code>msmu.tl.run_de</code> and usage examples in the tutorial <code>DE Analysis</code>.</p> <pre><code>de_res = mm.tl.run_de(\n    mdata,\n    modality=\"protein\",      # or \"peptide\"\n    category=\"condition\",    # column in .obs defining groups\n    ctrl=\"control\",          # control group label\n    expr=\"treated\",          # experimental group label\n    stat_method=\"welch\",     # options: \"welch\", \"student\", \"wilcoxon\", default \"welch\"\n    measure=\"median\",        # options: \"mean\", \"median\", default \"median\"\n    min_pct=0.5,             # minimum fraction of non-missing values in at least one group, default 0.5\n    fdr=\"empirical\",         # options: \"empirical\", \"bh\", or False, default \"empirical\"\n    n_resamples=1000,        # number of permutations, default 1000, if None, simple hypothesis test is performed\n    log_transformed=True     # whether data is log-transformed, default True\n)\n\nde_res.to_df() # get results as pandas DataFrame\n</code></pre> <p>DE analysis results are stored in <code>DeaResult</code> object, which contains: Feature names, test statistics, log2 fold-changes, p-values, q-values, and other relevant information.</p> <p>DE results can be accessed as a pandas <code>DataFrame</code> using the <code>to_df()</code> method.</p>"},{"location":"how-it-works/dea/#visualization_of_dea_results","title":"Visualization of DEA Results","text":"<p><code>msmu</code> provides visualization function to explore DEA results with volcano plots.</p> <pre><code>de_res.plot_volcano(\n    log2fc_cutoff=None, # (optional) log2 fold-change cutoff line, default None which shows fc_pct_5 line\n    pval_cutoff=0.05,   # (optional) p-value cutoff line, default 0.05\n    label_top_n=5,      # (optional) number of top significant features to label, default None (no labels)\n)\n</code></pre>"},{"location":"how-it-works/filter/","title":"Filter","text":""},{"location":"how-it-works/filter/#on_var","title":"on <code>.var</code>","text":"<p>Functions related to filtering features (<code>.var</code>) are implemented in <code>msmu.pp.add_filter</code> and <code>msmu.pp.apply_filter</code>.</p> <p>In <code>msmu</code>, filtering features consists of 2 stages.</p> <ol> <li> <p><code>add_filter()</code> to modality</p> <ul> <li>The column name should be present in <code>.var</code></li> <li>The <code>keep</code> argument accepts general expressions for condition, such as <code>lt</code>, <code>le</code>, <code>gt</code>, <code>ge</code>, <code>equal</code>, etc.</li> <li>Boolean masking will be stored in <code>mdata[modality].varm[\"filter\"]</code> by the column name of <code>column_keep_value</code> from parameters, e.g. <code>q_value_lt_0.01</code></li> </ul> </li> <li> <p><code>apply_filter()</code></p> <ul> <li>filter features based on boolean masks from <code>mdata[modality].varm[\"filter\"]</code></li> </ul> </li> </ol> <pre><code># filter PSM with q_value &lt; 0.01\nmdata = mm.pp.add_filter(\n    mdata,\n    modality=\"psm\",\n    column=\"q_value\", # a column in .var\n    keep=\"lt\",\n    value=0.01\n    )\n\nmdata = mm.pp.apply_filter(mdata, modality=\"psm\")\n</code></pre>"},{"location":"how-it-works/filter/#on_obs","title":"on <code>.obs</code>","text":"<p>Filtering on <code>.obs</code> is not implemented as an utility function. <code>.obs</code> can be filtered with slicing function on <code>MuData</code></p> <pre><code># filter BLANK channels for TMT studies\nmdata = mdata[mdata.obs[\"group\"] != \"BLANK\", ]\n</code></pre>"},{"location":"how-it-works/inference/","title":"Protein Inference","text":"<p>This page explains how <code>msmu</code> infers proteins from peptide-level features through <code>msmu.pp.infer_protein</code>.</p>"},{"location":"how-it-works/inference/#how_proteins_are_inferred","title":"How proteins are inferred","text":"<p>Protein inference in <code>msmu</code> is performed through a series of incremental refinement steps. By modifying the initial peptide-protein relationship, proteins are grouped based on shared peptide evidence, following principles outlined in Nesvizhskii &amp; Aebersold (2005). The main steps are as follows:</p> <ol> <li>Construct initial peptide-protein graph    A initial graph explaining peptide-protein relationships is constructed.</li> <li>Merge indistinguishable proteins (<code>_find_indistinguishable</code>)    Proteins associated with identical sets of peptides are merged into a single protein group. The protein group is named as a comma-separated list of members.</li> <li>Collapse subsettable proteins (<code>_find_subsettable</code>)    If the peptide set of one protein group is a strict subset of another, protein with smaller peptide set is reassigned to the protein group that has larger peptide set.</li> <li>Resolve subsumable proteins (<code>_find_subsumable</code>)    Proteins lacking unique peptides are evaluated within connected components of shared peptides. Proteins that cannot be distinguished are merged, while components without unique peptide evidence are dropped.</li> <li>Finalize protein group assignment    After above steps, all remaining protein groups are distinguishable (i.e., having at least one unique peptide). Mappings explaining peptide-protein relationship and annotations describing how each protein was handled are stored in <code>mdata.uns</code>.</li> </ol>"},{"location":"how-it-works/inference/#input","title":"Input","text":"<p>A <code>MuData</code> that has:</p> <ul> <li>A <code>peptide</code> modality containing <code>var[\"stripped_peptide\"]</code> and <code>var[\"proteins\"]</code> (semicolon-separated accessions per peptide). If decoys exist, they are pulled from <code>mdata[\"peptide\"].uns[\"decoy\"]</code>.</li> </ul>"},{"location":"how-it-works/inference/#output","title":"Output","text":"<p>A <code>MuData</code> with:</p> <ul> <li><code>mdata[\"peptide\"].var[\"protein_group\"]</code>: Newly inferred protein group</li> <li><code>mdata[\"peptide\"].var[\"peptide_type\"]</code>: Peptide type (<code>unique</code> or <code>shared</code>).</li> <li>Decoys receive the same annotations under <code>mdata.uns[\"decoy\"]</code>.</li> </ul> <p>Output <code>MuData</code> also contains mapping information inside <code>uns</code></p> <ul> <li><code>mdata.uns[\"peptide_map\"]</code>: peptide \u2192 protein group mapping.</li> <li><code>mdata.uns[\"protein_map\"]</code>: per-protein mapping with flags for <code>indistinguishable/subset/subsumable</code> status.</li> </ul>"},{"location":"how-it-works/inference/#citation","title":"Citation","text":"<p>Nesvizhskii, A. I., &amp; Aebersold, R. (2005). Interpretation of shotgun proteomic data. Molecular &amp; cellular proteomics, 4(10), 1419-1440.</p>"},{"location":"how-it-works/normalization/","title":"Normalization","text":""},{"location":"how-it-works/normalization/#overview","title":"Overview","text":"<p>Normalization is a crucial step in proteomics data analysis to correct for systematic biases and ensure comparability across samples. <code>msmu</code> provides several normalization methods to address different experimental designs and data characteristics.</p>"},{"location":"how-it-works/normalization/#log2_transform","title":"<code>log2_transform()</code>","text":"<p>The <code>log2_transform()</code> function applies a log2 transformation to the quantification data in the specified modality. This transformation helps stabilize variance and make the data more normally distributed, which is beneficial for downstream statistical analyses. <code>msmu</code> assumes that <code>log2_transform()</code> is applied on basal level of data before applying normalization methods.</p> <pre><code>mdata = mm.pp.log2_transform(\n    mdata,\n    modality=\"psm\"  # or \"peptide\", \"protein\"\n)\n</code></pre>"},{"location":"how-it-works/normalization/#normalize_or_normalise","title":"<code>normalize()</code> (or <code>normalise()</code>)","text":"<p>The <code>normalize()</code> function offers multiple normalization methods, including median (<code>median</code>) and quantile (<code>quantile</code>) normalization. Users can select the method that best suits their data and experimental design. For fractionated TMT data, setting the <code>fraction</code> argument to <code>True</code> ensures that normalization is performed within each fraction separately.</p> <pre><code>mdata = mm.pp.normalize(\n    mdata,\n    modality=\"psm\",           # or \"peptide\", \"protein\"\n    method=\"median\",          # options: \"median\", \"quantile\", default \"median\"\n    fraction=False            # whether data is fractionated\n)\n</code></pre>"},{"location":"how-it-works/normalization/#adjust_ptm_by_protein","title":"<code>adjust_ptm_by_protein()</code>","text":"<p>The <code>adjust_ptm_by_protein()</code> function normalizes PTM site quantifications by their corresponding protein abundances from <code>global proteome</code> (if available) data to account for changes in protein expression levels.</p> <p>For <code>ridge</code> regression method, PTM site intensities are adjusted based on the fitted values from a ridge regression model that predicts PTM abundance using protein abundance as a predictor variable. This approach helps to isolate PTM-specific changes from overall protein expression variations.</p> <p>And for <code>ratio</code> method, PTM site intensities are normalized by calculating the ratio of PTM abundance to protein abundance, providing a simple measure of PTM changes relative to protein levels.</p> <pre><code>mdata = mm.pp.adjust_ptm_by_protein(\n    mdata,\n    global_mdata=global_mdata,   # MuData object for global proteome\n    ptm_mod=\"phospho_site\",      # ptm modality\n    method=\"ridge\",              # options: \"ridge\", \"ratio\". default \"ridge\"\n    rescale=True                 # whether to rescale adjusted values. default True\n)\n</code></pre>"},{"location":"how-it-works/purity/","title":"Precursor Isolation Purity","text":""},{"location":"how-it-works/purity/#overview","title":"Overview","text":"<p>Precursor Isolation Purity (PIP) is a metric that quantifies the proportion of the target precursor ion signal relative to the total signal within the isolation window during MS/MS acquisition. High PIP values indicate that the isolated precursor is relatively free from co-isolated contaminants, which is crucial for accurate quantification, especially in isobaric labeling experiments like TMT.</p> <p>In <code>msmu</code>, PIP is calculated using the <code>compute_precursor_isolation_purity()</code> function, which leverages the <code>pyopenms</code> library to analyze MS1 spectra and determine the purity of each precursor ion.</p> <pre><code>mdata = mm.pp.compute_precursor_isolation_purity(\n    mdata,\n    mzml_paths=[\"/path/to/mzml/files\"],  # path to mzML files\n    tolerance=20,                        # mass tolerance\n    unit_ppm=True                        # mass tolerance in ppm\n    )\n</code></pre>"},{"location":"how-it-works/summarization/","title":"Summarization","text":""},{"location":"how-it-works/summarization/#overview","title":"Overview","text":"<p>The term <code>Summarization</code> refers to aggregating identification features and quantitative values as data move from one hierarchical level to the next (i.e., PSM/precursor -&gt; peptide -&gt; protein).</p> <p>Summarization functions are provided as <code>to_*</code> methods, such as <code>to_peptide</code>, <code>to_protein</code>, and <code>to_ptm</code>.</p> <p>The <code>Summarization</code> process generally involves:</p> <ol> <li>Feature selection    Selecting features to include in the aggregation based on criteria such as peptide type (unique/shared), precursor isolation purity, or abundance.</li> <li>Intensity aggregation    Aggregation of quantification values using methods like <code>median</code>, <code>mean</code>, or <code>sum</code>.</li> <li>Computing identification confidence scores (PEP, q-value) at the new level when possible.    Calculating PEP and q-values for the aggregated features using appropriate methods.</li> </ol>"},{"location":"how-it-works/summarization/#to_peptide","title":"<code>to_peptide()</code>","text":"<p><code>to_peptide()</code> function takes:</p> <ul> <li><code>MuData</code> containing <code>psm</code> level modality</li> </ul> <p>and returns</p> <ul> <li><code>MuData</code> with <code>peptide</code> level modality</li> </ul> <p>This step aggregates PSMs and their quantification values by <code>peptide</code> (non-redundant modified peptide). Peptide-level PEP is calculated with <code>best_pep</code> method by default and peptide-level q-values are computed using a conservative approach when decoy information is available.</p> <p>For quantification aggregation, the default method is <code>median</code>, and an optional <code>top_n</code> argument can be used to restrict aggregation using top N (e.g., top 3) features within each peptide. Feature ranking is based on <code>median_intensity</code> unless specified otherwise.</p> <p>In TMT studies, PSMs with low precursor isolation purity may be excluded prior to quantification aggregation to remove spectra with low quantitative accuracy. Precursor isolation purity should be computed with <code>mm.pp.compute_precursor_isolation_purity()</code> before calling <code>to_peptide()</code>. A <code>purity_threshold</code> (commonly <code>0.7</code>) can be applied during aggregation.</p> <p>Note that filtering by <code>top_n</code> or <code>purity_threshold</code> affects quantification aggregation only and does not modify identification feature aggregation.</p> <pre><code>mdata = mm.pp.to_peptide(\n    mdata,\n    agg_method=\"median\",            # default\n    purity_threshold=0.7,           # for tmt data\n    top_n=None,                     # default\n    rank_method=\"median_intensity\",  # default\n    )\n</code></pre>"},{"location":"how-it-works/summarization/#to_protein","title":"<code>to_protein()</code>","text":"<p><code>to_protein()</code> function takes:</p> <ul> <li><code>MuData</code> containing <code>peptide</code> modality with inferred <code>protein_group</code> and <code>peptide_type</code></li> </ul> <p>and returns:</p> <ul> <li><code>MuData</code> with <code>protein</code> level modality</li> </ul> <p>Protein-level summarization requires the <code>protein_group</code> and <code>peptide_type</code> columns, which are generated by <code>mm.pp.infer_protein()</code> from peptide-level data. Details are provided in the Protein Inference section. Briefly:</p> <ul> <li><code>protein_group</code> contains the inferred proteins for each peptide.</li> <li><code>peptide_type</code> indicates whether a peptide is \"unique\" or \"shared\".</li> </ul> <p>Only \"unique\" peptides are used for protein group intensity aggregation; \"shared\" peptides are excluded.</p> <p>As in peptide-level aggregation, protein group level <code>PEP</code> and <code>q-value</code> are computed when possible.</p> <p>The default settings use <code>top_n=3</code> with ranking by <code>median_intensity</code>, so only the top three peptides per protein group contribute to quantification.</p> <pre><code># Infer protein group from mdata (containing peptide modality)\nmdata = mm.pp.infer_protein(mdata)\n\n# Summarize peptides to protein group\nmdata = mm.pp.to_protein(\n    mdata,\n    agg_method=\"median\",            # default\n    top_n=3,                        # default\n    rank_method=\"median_intensity\",  # default\n    )\n</code></pre>"},{"location":"how-it-works/summarization/#to_ptm","title":"<code>to_ptm()</code>","text":"<p>To summarize modified peptide into post-translational modification (PTM) sites, <code>to_ptm()</code> uses the subset of peptides that contain the specified modification and then performs several steps to assign PTM positions at the protein level.</p> <p>Internally, the function performs:</p> <ol> <li>Filtering data with only modified peptides with modi_identifier</li> <li>Extracting modified sites from peptide</li> <li>Assigning peptide-level site labels</li> <li>Exploding peptides to single proteins for per-protein site labeling</li> <li>Mapping the site to the corresponding position in each protein</li> <li>Merging single-protein results back into protein groups</li> <li>Grouping by modified peptide and peptide-site combination</li> <li>Merging site metadata with peptide-level quantification</li> </ol> <p><code>to_ptm()</code> function takes:</p> <ul> <li><code>MuData</code> containing <code>peptide</code> modality and attached FASTA file</li> </ul> <p>and returns:</p> <ul> <li><code>MuData</code> with <code>ptm_site</code> level modality</li> </ul> <p>A FASTA file is required because PTM sites must be mapped to protein-sequence coordinates. FASTA can be attached using <code>mm.utils.attach_fasta()</code>.</p> <p>The argument <code>modi_name</code> determines the modality name (e.g., \"phospho\" -&gt; \"phospho_site\"), and the <code>modification</code> string is used to identify modified peptides.</p> <p><code>agg_method</code> can be selected among methods as described in other summarization functions.</p> <pre><code>mdata = mm.utils.attach_fasta(\"fasta/file/path.fasta\")\n\nmdata = mm.pp.to_ptm(\n    mdata,\n    modi_name=\"phospho\",\n    modification=\"[+79.9663]\",\n    agg_method=\"median\",        # default\n    top_n=None                  # default\n    )\n</code></pre>"},{"location":"how-it-works/visualization/","title":"Visualization Overview","text":"<p><code>msmu._plotting</code> wraps Plotly to provide ready-made QC and exploratory plots for MuData objects. The module is structured around data preparation helpers and lightweight plot wrappers so you can compose figures with consistent defaults while still passing Plotly kwargs to tweak layout.</p>"},{"location":"how-it-works/visualization/#common_parameters_and_behaviors","title":"Common parameters and behaviors","text":"<ul> <li><code>mdata</code>: required <code>MuData</code> containing the modality to plot.</li> <li><code>modality</code>: defaults vary by plot (<code>feature</code>, <code>peptide</code>, <code>protein</code>)</li> <li><code>groupby</code>: observation column used to split traces/groups (e.g., <code>filename</code>, <code>condition</code>). If omitted, falls back to <code>obs_column</code>.</li> <li><code>obs_column</code>: observation column used for labeling/group resolution; all elements should be unique. If omitted or no column exists, creates <code>__obs_idx__</code> column from the index of <code>obs</code></li> <li><code>colorby</code>: optional obs column for coloring; only applied when <code>groupby</code> equals <code>obs_column</code>.</li> <li><code>ptype</code>: plot style selector (<code>hist</code>, <code>box</code>, <code>vln</code>, etc.).</li> <li><code>**kwargs</code>: forwarded to <code>go.Figure.update_layout</code> for per-plot overrides.</li> </ul>"},{"location":"how-it-works/visualization/#example","title":"Example","text":"<p>Uszkoreit, J., Barkovits, K., Pacharra, S., Pfeiffer, K., Steinbach, S., Marcus, K., &amp; Eisenacher, M. (2022). Dataset containing physiological amounts of spike-in proteins into murine C2C12 background as a ground truth quantitative LC-MS/MS reference. Data in Brief, 43, 108435.</p>"},{"location":"how-it-works/visualization/#mdataobs","title":"mdata.obs","text":"set sample_id sample_name condition replicate S1 QExHF04026 G1-1 G1 1 S1 QExHF04028 G2-1 G2 1 S1 QExHF04030 G3-1 G3 1 S1 QExHF04032 G4-1 G4 1 S1 QExHF04034 G5-1 G5 1 S1 QExHF04036 G1-2 G1 2 S1 QExHF04038 G2-2 G2 2 S1 QExHF04040 G3-2 G3 2 S1 QExHF04042 G4-2 G4 2 S1 QExHF04044 G5-2 G5 2 S1 QExHF04046 G1-3 G1 3 S1 QExHF04048 G2-3 G2 3 S1 QExHF04050 G3-3 G3 3 S1 QExHF04052 G4-3 G4 3 S1 QExHF04054 G5-3 G5 3"},{"location":"how-it-works/visualization/#plot_id","title":"<code>plot_id</code>","text":"<pre><code>mm.pl.plot_id(mdata, \"protein\", groupby=\"sample_name\")\n</code></pre> <pre><code>mm.pl.plot_id(mdata, \"protein\", groupby=\"condition\")\n</code></pre>"},{"location":"how-it-works/visualization/#plot_intensity","title":"<code>plot_intensity</code>","text":"<pre><code>mm.pl.plot_intensity(mdata, \"protein\", groupby=\"sample_name\", ptype=\"hist\")\n</code></pre>"},{"location":"how-it-works/visualization/#plot_missingness","title":"<code>plot_missingness</code>","text":"<pre><code>mm.pl.plot_missingness(mdata, \"protein\")\n</code></pre>"},{"location":"how-it-works/visualization/#plot_var","title":"<code>plot_var</code>","text":"<pre><code>mm.pl.plot_var(mdata, \"feature\", groupby=\"sample_name\", var_column=\"charge\", ptype=\"stacked_bar\")\n</code></pre> <pre><code>mm.pl.plot_var(mdata, \"feature\", groupby=\"sample_name\", var_column=\"peptide_length\", ptype=\"vln\")\n</code></pre>"},{"location":"how-it-works/visualization/#plot_pca_plot_umap","title":"<code>plot_pca</code> &amp; <code>plot_umap</code>","text":"<pre><code>mm.pl.plot_pca(mdata, \"protein\", groupby=\"condition\")\n</code></pre>"},{"location":"how-it-works/visualization/#plot_correlation","title":"<code>plot_correlation</code>","text":"<pre><code>mm.pl.plot_correlation(mdata, \"protein\")\n</code></pre>"},{"location":"how-it-works/visualization/#plot_upset","title":"<code>plot_upset</code>","text":"<pre><code>mm.pl.plot_upset(mdata, \"protein\", groupby=\"condition\")\n</code></pre>"},{"location":"reference/merge_mudata/","title":"<code>msmu.merge_mudata</code>","text":"<p>Merges multiple MuData objects into a single MuData object.</p> <p>Parameters:</p> Name Type Description Default <code>mdatas</code> <code>dict[str, MuData]</code> <p>Dictionary of MuData objects to merge.</p> required <p>Returns:</p> Type Description <code>MuData</code> <p>Merged MuData object.</p>"},{"location":"reference/read_diann/","title":"<code>msmu.read_diann</code>","text":"<p>Alias for :class:<code>_ReadDiannFacade</code>.</p> <p>Parameters:</p> Name Type Description Default <code>identification_file</code> <p>Path to the DIA-NN output directory.</p> required <p>Returns:</p> Type Description <code>_ReadDiannFacade</code> <p>A MuData object containing the DIA-NN data at precursor level</p> Usage <p>mdata_precursor = mm.read_diann(search_dir) mdata_protein_group = mm.read_diann.from_pg(search_dir)</p>"},{"location":"reference/read_fragpipe/","title":"<code>msmu.read_fragpipe</code>","text":"<p>Alias for :class:<code>FragPipeFacade</code>.</p> <p>Parameters:</p> Name Type Description Default <code>identification_file</code> <p>Path to the FragPipe output directory.</p> required <code>quantification_file</code> <p>Path to the FragPipe quantification file (if applicable, for LFQ).</p> required <code>label</code> <p>Label for the FragPipe output ('tmt' or 'label_free').</p> required <code>acquisition</code> <p>Acquisition method ('dda' or 'dia').</p> required <p>Returns:</p> Type Description <code>FragPipeFacade</code> <p>A MuData object containing the FragPipe data at PSM level</p> Usage <p>mdata = mm.read_fragpipe(identification_file, quantification_file, label, acquisition)</p>"},{"location":"reference/read_h5mu/","title":"<code>msmu.read_h5mu</code>","text":"<p>Reads an h5mu file (HDF5) and returns a MuData object.</p> <p>Parameters:</p> Name Type Description Default <code>h5mu_file</code> <code>str | Path</code> <p>Path to the H5MU file.</p> required <p>Returns:</p> Type Description <code>MuData</code> <p>A MuData object.</p>"},{"location":"reference/read_maxquant/","title":"<code>msmu.read_maxquant</code>","text":"<p>Alias for :class:<code>_MaxQuantFacade</code>.</p> <p>Parameters:</p> Name Type Description Default <code>identification_file</code> <p>Path to the MaxQuant output directory.</p> required <code>label</code> <p>Label for the MaxQuant output ('tmt' or 'label_free').</p> required <code>acquisition</code> <p>Acquisition method ('dda' or 'dia').</p> required <p>Returns:</p> Type Description <code>_MaxQuantFacade</code> <p>A MuData object containing the MaxQuant data at precursor level</p> Usage <p>mdata_precursor = mm.read_maxquant(search_dir) mdata_protein_group = mm.read_maxquant.from_pg(search_dir)</p>"},{"location":"reference/read_sage/","title":"<code>msmu.read_sage</code>","text":"<p>Reads Sage output and returns a MuData object.</p> <p>Parameters:</p> Name Type Description Default <code>identificaton_file</code> <p>Path to the results.sage.tsv.</p> required <code>label</code> <code>Literal['tmt', 'label_free']</code> <p>Label for the Sage output ('tmt' or 'label_free').</p> required <code>quantification_file</code> <code>str | Path | None</code> <p>Whether to include quantification data. Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>MuData</code> <p>A MuData object containing the Sage data.</p>"},{"location":"reference/io/read_diann/","title":"<code>msmu.io.read_diann</code>","text":"<p>Alias for :class:<code>_ReadDiannFacade</code>.</p> <p>Parameters:</p> Name Type Description Default <code>identification_file</code> <p>Path to the DIA-NN output directory.</p> required <p>Returns:</p> Type Description <code>_ReadDiannFacade</code> <p>A MuData object containing the DIA-NN data at precursor level</p> Usage <p>mdata_precursor = mm.read_diann(search_dir) mdata_protein_group = mm.read_diann.from_pg(search_dir)</p>"},{"location":"reference/io/read_fragpipe/","title":"<code>msmu.io.read_fragpipe</code>","text":"<p>Alias for :class:<code>FragPipeFacade</code>.</p> <p>Parameters:</p> Name Type Description Default <code>identification_file</code> <p>Path to the FragPipe output directory.</p> required <code>quantification_file</code> <p>Path to the FragPipe quantification file (if applicable, for LFQ).</p> required <code>label</code> <p>Label for the FragPipe output ('tmt' or 'label_free').</p> required <code>acquisition</code> <p>Acquisition method ('dda' or 'dia').</p> required <p>Returns:</p> Type Description <code>FragPipeFacade</code> <p>A MuData object containing the FragPipe data at PSM level</p> Usage <p>mdata = mm.read_fragpipe(identification_file, quantification_file, label, acquisition)</p>"},{"location":"reference/io/read_maxquant/","title":"<code>msmu.io.read_maxquant</code>","text":"<p>Alias for :class:<code>_MaxQuantFacade</code>.</p> <p>Parameters:</p> Name Type Description Default <code>identification_file</code> <p>Path to the MaxQuant output directory.</p> required <code>label</code> <p>Label for the MaxQuant output ('tmt' or 'label_free').</p> required <code>acquisition</code> <p>Acquisition method ('dda' or 'dia').</p> required <p>Returns:</p> Type Description <code>_MaxQuantFacade</code> <p>A MuData object containing the MaxQuant data at precursor level</p> Usage <p>mdata_precursor = mm.read_maxquant(search_dir) mdata_protein_group = mm.read_maxquant.from_pg(search_dir)</p>"},{"location":"reference/io/read_sage/","title":"<code>msmu.io.read_sage</code>","text":"<p>Reads Sage output and returns a MuData object.</p> <p>Parameters:</p> Name Type Description Default <code>identificaton_file</code> <p>Path to the results.sage.tsv.</p> required <code>label</code> <code>Literal['tmt', 'label_free']</code> <p>Label for the Sage output ('tmt' or 'label_free').</p> required <code>quantification_file</code> <code>str | Path | None</code> <p>Whether to include quantification data. Default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>MuData</code> <p>A MuData object containing the Sage data.</p>"},{"location":"reference/io/to_readable/","title":"<code>msmu.io.to_readable</code>","text":"<p>Convert MuData modality to a human-readable format.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the data to convert.</p> required <code>modality</code> <code>str</code> <p>The modality to convert (e.g., 'psm', 'peptide', 'protein').</p> required <code>include</code> <code>str | list[str] | None</code> <p>List of columns to include.</p> <code>None</code> <code>exclude</code> <code>str | list[str] | None</code> <p>List of columns to exclude.</p> <code>None</code> <code>quantification</code> <code>bool</code> <p>Whether to include quantification data.</p> <code>True</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A pandas DataFrame in a human-readable format.</p>"},{"location":"reference/io/write_csv/","title":"<code>msmu.io.write_csv</code>","text":"<p>Exports MuData modalities to CSV/TSV files.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the data to export.</p> required <code>modality</code> <code>str</code> <p>The modality to export (e.g., 'psm', 'peptide', 'protein').</p> required <code>filename</code> <code>str | Path</code> <p>Path to the output file.</p> required <code>sep</code> <code>str</code> <p>Separator for the output file (e.g., ',', '        ').</p> required <code>include</code> <code>str | list[str] | None</code> <p>List of columns to include.</p> <code>None</code> <code>exclude</code> <code>str | list[str] | None</code> <p>List of columns to exclude.</p> <code>None</code> <code>quantification</code> <code>bool</code> <p>Whether to include quantification data.</p> <code>True</code>"},{"location":"reference/io/write_flashlfq_input/","title":"<code>msmu.io.write_flashlfq_input</code>","text":"<p>Exports MuData psm object to FlashLFQ format.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the data to export.</p> required <code>filename</code> <code>str | Path</code> <p>Path to the output FlashLFQ file.</p> required"},{"location":"reference/pl/plot_correlation/","title":"<code>msmu.pl.plot_correlation</code>","text":"<p>Plots a lower-triangular Pearson correlation heatmap of grouped medians.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing expression data.</p> required <code>modality</code> <code>str</code> <p>Target modality; defaults to 'protein'.</p> <code>'protein'</code> <code>groupby</code> <code>str | None</code> <p>Observation column used to group and average values.</p> <code>None</code> <code>obs_column</code> <code>str | None</code> <p>Observation column used for labeling/group resolution.</p> <code>None</code> <code>**kwargs</code> <code>str</code> <p>Additional layout options forwarded to Plotly.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Heatmap of pairwise correlations.</p>"},{"location":"reference/pl/plot_id/","title":"<code>msmu.pl.plot_id</code>","text":"<p>Plots identification counts per modality grouped by observations.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the modality to visualize.</p> required <code>modality</code> <code>str</code> <p>Target modality (psm, peptide, protein, or site).</p> required <code>groupby</code> <code>str | None</code> <p>Observation column used to group bars.</p> <code>None</code> <code>colorby</code> <code>str | None</code> <p>Observation column used for coloring (when applicable).</p> <code>None</code> <code>template</code> <code>str</code> <p>Plotly template for colorway.</p> <code>DEFAULT_TEMPLATE</code> <code>obs_column</code> <code>str | None</code> <p>Observation column used for labeling/group resolution.</p> <code>None</code> <code>**kwargs</code> <code>str</code> <p>Additional layout options forwarded to Plotly.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Bar chart of identification counts per group.</p>"},{"location":"reference/pl/plot_intensity/","title":"<code>msmu.pl.plot_intensity</code>","text":"<p>Visualizes intensity distributions for a modality using histograms, box, or violin plots.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the modality to visualize.</p> required <code>modality</code> <code>str</code> <p>Target modality (psm, peptide, protein, or site).</p> required <code>groupby</code> <code>str | None</code> <p>Observation column used to group traces.</p> <code>None</code> <code>colorby</code> <code>str | None</code> <p>Observation column used for coloring (when applicable).</p> <code>None</code> <code>ptype</code> <code>str</code> <p>Plot type: 'hist', 'box', or 'vln'.</p> <code>'hist'</code> <code>template</code> <code>str</code> <p>Plotly template for colorway.</p> <code>DEFAULT_TEMPLATE</code> <code>bins</code> <code>int</code> <p>Number of bins for histogram view.</p> <code>30</code> <code>obs_column</code> <code>str | None</code> <p>Observation column used for labeling/group resolution.</p> <code>None</code> <code>**kwargs</code> <code>str</code> <p>Additional layout options forwarded to Plotly.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Intensity distribution figure.</p>"},{"location":"reference/pl/plot_missingness/","title":"<code>msmu.pl.plot_missingness</code>","text":"<p>Plots cumulative data completeness percentages for a modality.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the modality to visualize.</p> required <code>modality</code> <code>str</code> <p>Target modality (psm, peptide, protein, or site).</p> required <code>obs_column</code> <code>str | None</code> <p>Observation column used to order samples.</p> <code>None</code> <code>**kwargs</code> <code>str</code> <p>Additional layout options forwarded to Plotly.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Step line plot of cumulative completeness.</p>"},{"location":"reference/pl/plot_pca/","title":"<code>msmu.pl.plot_pca</code>","text":"<p>Plots PCA scores for a modality colored/grouped by observation metadata.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing PCA results.</p> required <code>modality</code> <code>str</code> <p>Target modality; defaults to 'protein'.</p> <code>'protein'</code> <code>groupby</code> <code>str | None</code> <p>Observation column used to group traces.</p> <code>None</code> <code>colorby</code> <code>str | None</code> <p>Observation column used for coloring (when applicable).</p> <code>None</code> <code>template</code> <code>str</code> <p>Plotly template for colorway.</p> <code>DEFAULT_TEMPLATE</code> <code>pcs</code> <code>tuple[int, int] | list[int]</code> <p>Pair of principal component indices (1-based).</p> <code>(1, 2)</code> <code>obs_column</code> <code>str | None</code> <p>Observation column used for labeling/group resolution.</p> <code>None</code> <code>key</code> <code>str</code> <p>Key in .obsm where the PCA dimensions are stored; defaults to 'X_pca'.</p> <code>'X_pca'</code> <code>**kwargs</code> <code>str</code> <p>Additional layout options forwarded to Plotly.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Scatter plot of PCA scores.</p>"},{"location":"reference/pl/plot_umap/","title":"<code>msmu.pl.plot_umap</code>","text":"<p>Plots UMAP embeddings for a modality colored/grouped by observations.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing UMAP embeddings.</p> required <code>modality</code> <code>str</code> <p>Target modality; defaults to 'protein'.</p> <code>'protein'</code> <code>groupby</code> <code>str | None</code> <p>Observation column used to group traces.</p> <code>None</code> <code>colorby</code> <code>str | None</code> <p>Observation column used for coloring (when applicable).</p> <code>None</code> <code>template</code> <code>str</code> <p>Plotly template for colorway.</p> <code>DEFAULT_TEMPLATE</code> <code>obs_column</code> <code>str | None</code> <p>Observation column used for labeling/group resolution.</p> <code>None</code> <code>key</code> <code>str</code> <p>Key in .obsm where the UMAP dimensions are stored; defaults to 'X_umap'.</p> <code>'X_umap'</code> <code>**kwargs</code> <code>str</code> <p>Additional layout options forwarded to Plotly.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Scatter plot of UMAP embeddings.</p>"},{"location":"reference/pl/plot_upset/","title":"<code>msmu.pl.plot_upset</code>","text":"<p>Draws an Upset plot showing protein intersections across observation groups.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the modality to visualize.</p> required <code>modality</code> <code>str</code> <p>Target modality; defaults to 'protein'.</p> <code>'protein'</code> <code>subset</code> <code>str | None</code> <p>Specific observation value to subset on; optional.</p> <code>None</code> <code>subset_column</code> <code>str | None</code> <p>Observation column used for subsetting.</p> <code>None</code> <code>groupby</code> <code>str | None</code> <p>Observation column used to define sets.</p> <code>None</code> <code>obs_column</code> <code>str | None</code> <p>Observation column used for labeling/group resolution.</p> <code>None</code> <code>**kwargs</code> <code>str</code> <p>Additional layout options forwarded to Plotly.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Upset diagram of protein intersections.</p>"},{"location":"reference/pl/plot_var/","title":"<code>msmu.pl.plot_var</code>","text":"<p>Plots variable annotations using stacked bars, box/violin plots, or histograms.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the modality to visualize.</p> required <code>modality</code> <code>str</code> <p>Target modality; defaults to 'psm'.</p> <code>'psm'</code> <code>groupby</code> <code>str | None</code> <p>Observation column used to group traces.</p> <code>None</code> <code>var_column</code> <code>str | None</code> <p>Variable column to visualize.</p> <code>None</code> <code>obs_column</code> <code>str | None</code> <p>Observation column used for labeling/group resolution.</p> <code>None</code> <code>ptype</code> <code>str | None</code> <p>Plot type inferred for numeric/categorical data when None.</p> <code>None</code> <code>bins</code> <code>int</code> <p>Number of bins for histogram view.</p> <code>30</code> <code>**kwargs</code> <code>str</code> <p>Additional layout options forwarded to Plotly.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Figure</code> <p>Plot of variable annotation distributions.</p>"},{"location":"reference/pp/add_filter/","title":"<code>msmu.pp.add_filter</code>","text":"<p>Adds a filter to the specified modality in the MuData object based on the given condition.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object to which the filter will be added.</p> required <code>modality</code> <code>str</code> <p>The modality within the MuData object to which the filter will be applied</p> required <code>column</code> <code>str</code> <p>The column in the modality's var DataFrame to apply the filter on.</p> required <code>keep</code> <code>Literal['eq', 'ne', 'lt', 'le', 'gt', 'ge', 'contains', 'not_contains']</code> <p>The condition to apply for filtering.</p> required <code>value</code> <code>str | float | None</code> <p>The value to compare against for filtering.</p> required <p>Returns:</p> Type Description <code>MuData</code> <p>MuData object with the added filter.</p>"},{"location":"reference/pp/adjust_ptm_by_protein/","title":"<code>msmu.pp.adjust_ptm_by_protein</code>","text":"<p>Estimation of PTM stoichiometry by using Global Protein Data.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object to normalise.</p> required <code>global_mdata</code> <code>MuData</code> <p>MuData object which contains global protein expression.</p> required <code>modality</code> <code>str</code> <p>PTM modality to normalise (e.g. phospho_site, {ptm}_site).</p> <code>'phospho_site'</code> <code>layer</code> <code>str | None</code> <p>Layer to normalise. If None, the default layer (.X) will be used.</p> <code>None</code> <code>global_mod</code> <p>Modality in global_mdata to normalise PTM site. Default is 'protein'.</p> required <code>method</code> <code>Literal['ridge', 'ratio']</code> <p>A method for normalisation. Options: ridge, ratio. Default is 'ridge'.</p> <code>'ridge'</code> <code>rescale</code> <code>bool</code> <p>If True, rescale the data after normalisation with median value across dataset. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>MuData</code> <p>Normalised MuData object.</p>"},{"location":"reference/pp/apply_filter/","title":"<code>msmu.pp.apply_filter</code>","text":"<p>Applies the filter to the specified modality in the MuData object.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object to which the filter will be applied.</p> required <code>modality</code> <code>str</code> <p>The modality within the MuData object to which the filter will be applied.</p> required <p>Returns:</p> Type Description <code>MuData</code> <p>MuData object with the filter applied.</p>"},{"location":"reference/pp/correct_batch_effect/","title":"<code>msmu.pp.correct_batch_effect</code>","text":"<p>Batch correction methods for MuData object. GIS-based normalization, median centering, ComBat, and continuous batch correction (with lowess) are supported.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object to batch correct.</p> required <code>method</code> <code>Literal['gis', 'median_center', 'combat', 'continuous']</code> <p>Batch correction method to use. Options are 'gis', 'median_center', 'combat', 'continuous'.</p> required <code>category</code> <code>str</code> <p>Category in .obs to use for batch correction.</p> required <code>modality</code> <code>str</code> <p>Modality to batch correct.</p> required <code>layer</code> <code>str | None</code> <p>Layer to batch correct. If None, the default layer (.X) will be used.</p> <code>None</code> <code>gis_samples</code> <code>list[str] | None</code> <p>List of GIS samples.</p> <code>None</code> <code>drop_gis</code> <code>bool</code> <p>If True, GIS samples will be dropped after correction. Default is True.</p> <code>True</code> <code>rescale</code> <code>bool</code> <p>If True, rescale the data after batch correction with median value across dataset (except combat).</p> <code>True</code> <code>log_transformed</code> <code>bool</code> <p>If True, data is assumed to be log-transformed. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>MuData</code> <p>Batch corrected MuData object.</p>"},{"location":"reference/pp/infer_protein/","title":"<code>msmu.pp.infer_protein</code>","text":"<p>Infer protein group mappings and annotate peptides with uniqueness.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object to update</p> required <code>modality</code> <code>str</code> <p>modality holding peptide-level data</p> <code>'peptide'</code> <code>protein_colname</code> <code>str</code> <p>column in var with semicolon-delimited protein accessions</p> <code>'proteins'</code> <code>peptide_colname</code> <code>str</code> <p>column in var with stripped peptide sequences</p> <code>'stripped_peptide'</code> <code>propagated_from</code> <code>MuData | str | None</code> <p>optional MuData or path to reuse existing mappings (e.g., global reference for PTM work)</p> <code>None</code> <p>Returns:</p> Type Description <code>MuData</code> <p>MuData object with updated protein mappings and peptide annotations</p>"},{"location":"reference/pp/log2_transform/","title":"<code>msmu.pp.log2_transform</code>","text":"<p>Apply log2 transformation to the specified modality in MuData object.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object to transform.</p> required <code>modality</code> <code>str</code> <p>Modality to log2 transform.</p> required <code>layer</code> <code>str | None</code> <p>Layer to transform. If None, the default layer (.X) will be used.</p> <code>None</code> <p>Returns:</p> Type Description <code>MuData</code> <p>Transformed MuData object.</p>"},{"location":"reference/pp/normalise/","title":"<code>msmu.pp.normalise</code>","text":"<p>Normalise data in MuData object.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object to normalise.</p> required <code>method</code> <code>str</code> <p>Normalisation method to use. Options are 'quantile', 'median', 'total_sum (not implemented)'.</p> required <code>modality</code> <code>str</code> <p>Modality to normalise. If None, all modalities at the specified level will be normalised.</p> required <code>layer</code> <code>str | None</code> <p>Layer to normalise. If None, the default layer (.X) will be used.</p> <code>None</code> <code>fraction</code> <code>bool</code> <p>If True, normalise within fractions. If False, normalise across all data. \"fraction\" yet supports fractionated TMT.</p> <code>False</code> <p>Returns:</p> Type Description <code>MuData</code> <p>Normalised MuData object.</p>"},{"location":"reference/pp/normalize/","title":"<code>msmu.pp.normalize</code>","text":"<p>Alias for normalise function to support American English spelling.</p>"},{"location":"reference/pp/scale_data/","title":"<code>msmu.pp.scale_data</code>","text":"<p>Scale data in MuData object to have zero mean and unit variance.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object to scale.</p> required <code>modality</code> <code>str</code> <p>Modality to scale.</p> required <code>layer</code> <code>str | None</code> <p>Layer to scale. If None, the default layer (.X) will be used.</p> <code>None</code> <p>Returns:</p> Type Description <code>MuData</code> <p>Scaled MuData object.</p>"},{"location":"reference/pp/to_peptide/","title":"<code>msmu.pp.to_peptide</code>","text":"<p>Summarise PSM-level data to peptide-level data.</p> Usage <p>mdata = mm.pp.to_peptide(     mdata,     agg_method=\"median\",     purity_threshold=0.7,     calculate_q=True, )</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing PSM-level data.</p> required <code>layer</code> <code>str | None</code> <p>Layer to use for quantification aggregation. If None, the default layer (.X) will be used. Defaults to None.</p> <code>None</code> <code>agg_method</code> <code>Literal['median', 'mean', 'sum']</code> <p>Aggregation method for quantification to use. Defaults to \"median\".</p> <code>'median'</code> <code>purity_threshold</code> <code>float | None</code> <p>Purity threshold for TMT data quantification aggregation (does not filter out features). If None, no filtering is applied. Defaults to 0.7.</p> <code>0.7</code> <code>top_n</code> <code>int | None</code> <p>Number of top features to consider for summarisation. If None, all features are used. Defaults to None.</p> <code>None</code> <code>rank_method</code> <code>Literal['median_intensity', 'total_intensity', 'max_intensity', 'mean_intensity']</code> <p>Method to rank features when selecting top_n. Defaults to \"median_intensity\".</p> <code>'median_intensity'</code> <code>calculate_q</code> <code>bool</code> <p>Whether to calculate q-values. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>MuData</code> <p>MuData object containing peptide-level data.</p>"},{"location":"reference/pp/to_protein/","title":"<code>msmu.pp.to_protein</code>","text":"<p>Summarise peptide-level data to protein-level data. By default, uses <code>top 3</code> peptides in their <code>median_intensity</code> and <code>unique</code> (_shared_peptide = \"discard\") per protein_group for quantification aggregation with median.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing Peptide-level data.</p> required <code>layer</code> <code>str | None</code> <p>Layer to use for quantification aggregation. If None, the default layer (.X) will be used. Defaults to None.</p> <code>None</code> <code>agg_method</code> <code>Literal['median', 'mean', 'sum']</code> <p>Aggregation method to use. Defaults to \"median\".</p> <code>'median'</code> <code>top_n</code> <code>int | None</code> <p>Number of top peptides to consider for summarisation. If None, all peptides are used. Defaults to None.</p> <code>3</code> <code>rank_method</code> <code>Literal['median_intensity', 'total_intensity', 'max_intensity', 'mean_intensity']</code> <p>Method to rank features when selecting top_n. Defaults to \"median_intensity\".</p> <code>'median_intensity'</code> <code>calculate_q</code> <code>bool</code> <p>Whether to calculate q-values. Defaults to True.</p> <code>True</code> <code>_shared_peptide</code> <code>Literal['discard']</code> <p>How to handle shared peptides. Currently only \"discard\" is implemented. Defaults to \"discard\".</p> <code>'discard'</code> <p>Returns:</p> Type Description <code>MuData</code> <p>MuData object containing protein-level data.</p>"},{"location":"reference/pp/to_ptm/","title":"<code>msmu.pp.to_ptm</code>","text":"<p>Summarise peptide-level data to PTM-level data.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing peptide-level data.</p> required <code>modi_name</code> <code>str</code> <p>Name of the PTM to summarise (e.g., \"phospho\"). Will be used in the output modality name (eg. phospho_site).</p> required <code>modification</code> <code>str</code> <p>Modification string (e.g., \"[+79.96633]\", \"(unimod:21)\").</p> required <code>layer</code> <code>str | None</code> <p>Layer to use for quantification aggregation. If None, the default layer (.X) will be used. Defaults to None.</p> <code>None</code> <code>agg_method</code> <code>Literal['median', 'mean', 'sum']</code> <p>Aggregation method to use. Defaults to \"median\".</p> <code>'median'</code> <code>top_n</code> <code>int | None</code> <p>Number of top features to consider for summarisation. If None, all features are used. Defaults to None.</p> <code>None</code> <code>rank_method</code> <code>Literal['median_intensity', 'total_intensity', 'max_intensity', 'mean_intensity']</code> <p>Method to rank features when selecting top_n. Defaults to \"median_intensity\".</p> <code>'median_intensity'</code> <p>Returns:</p> Name Type Description <code>MuData</code> <code>MuData</code> <p>MuData object containing PTM-level data.</p>"},{"location":"reference/tl/PermTestResult/","title":"<code>msmu.tl.PermTestResult</code>","text":"<p>               Bases: <code>StatTestResult</code></p> <p>Data class to store results from permutation tests in DEA.</p> <p>Attributes:</p> Name Type Description <code>permutation_method</code> <code>Literal['exact', 'randomised'] | None</code> <p>The permutation method used (\"exact\" or \"randomised\").</p> <code>n_permutations</code> <code>int | None</code> <p>Number of permutations performed.</p> <code>fc_pct_1</code> <code>float | None</code> <p>Fold change at the 1st percentile.</p> <code>fc_pct_5</code> <code>float | None</code> <p>Fold change at the 5th percentile.</p>"},{"location":"reference/tl/StatTestResult/","title":"<code>msmu.tl.StatTestResult</code>","text":"<p>Data class to store results from statistical tests in DEA.</p> <p>Attributes:</p> Name Type Description <code>stat_method</code> <code>str</code> <p>The statistical method used.</p> <code>ctrl</code> <code>str</code> <p>Name of the control group.</p> <code>expr</code> <code>str</code> <p>Name of the experimental group.</p> <code>features</code> <code>str</code> <p>List or array of feature names.</p> <code>median_ctrl</code> <code>str</code> <p>Median values for the control group.</p> <code>median_expr</code> <code>str</code> <p>Median values for the experimental group.</p> <code>pct_ctrl</code> <code>str</code> <p>Percentage of non-zero values in the control group.</p> <code>pct_expr</code> <code>str</code> <p>Percentage of non-zero values in the experimental group.</p> <code>log2fc</code> <code>str</code> <p>Log2 fold change between experimental and control groups.</p> <code>p_value</code> <code>ndarray | None</code> <p>P-values from the statistical test.</p> <code>q_value</code> <code>ndarray | None</code> <p>Adjusted p-values (q-values) after multiple testing correction.</p> <p>Methods:</p> Name Description <code>to_df</code> <p>Convert the results to a pandas DataFrame.</p> <code>plot_volcano</code> <p>Plot a volcano plot of the DEA results.</p>"},{"location":"reference/tl/compute_precursor_isolation_purity/","title":"<code>msmu.tl.compute_precursor_isolation_purity</code>","text":"<p>Calculate precursor isolation purity for PSMs in the given MuData object and mzML file.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing PSM data.</p> required <code>mzml_paths</code> <code>str | Path | list</code> <p>Full path(s) to the mzML file.</p> required <code>tolerance</code> <code>float</code> <p>Tolerance for precursor purity calculation. Default is 20.</p> <code>20.0</code> <code>unit_ppm</code> <code>bool</code> <p>Whether to use ppm for tolerance. Default is True.</p> <code>True</code> <p>Returns:</p> Type Description <code>MuData</code> <p>md.MuData: MuData object containing purity results.</p>"},{"location":"reference/tl/compute_precursor_isolation_purity_from_mzml/","title":"<code>msmu.tl.compute_precursor_isolation_purity_from_mzml</code>","text":"<p>Calculate precursor isolation purity for all MS2 scans in the given mzML file.</p> <p>Parameters:</p> Name Type Description Default <code>mzml_paths</code> <code>str | Path | list</code> <p>Full path(s) to the mzML file.</p> required <code>tolerance</code> <code>float</code> <p>Tolerance for precursor purity calculation.</p> <code>20.0</code> <code>unit_ppm</code> <code>bool</code> <p>Whether to use ppm for tolerance.</p> <code>True</code> <p>Returns:</p> Type Description <code>PurityResult</code> <p>pd.DataFrame: DataFrame with scan numbers and their corresponding purity scores.</p>"},{"location":"reference/tl/corr/","title":"<code>msmu.tl.corr</code>","text":"<p>Compute the correlation matrix for the specified modality in a MuData object.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the data.</p> required <code>modality</code> <code>str</code> <p>The modality to compute correlations on.</p> required <code>layer</code> <code>str | None</code> <p>Layer to use for quantification aggregation. If None, the default layer (.X) will be used. Defaults to None.</p> <code>None</code> <code>method</code> <code>Literal['pearson', 'spearman', 'kendall']</code> <p>Correlation method to use: \"pearson\", \"spearman\", or \"kendall\". Defaults to \"pearson\".</p> <code>'pearson'</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame representing the correlation matrix.</p>"},{"location":"reference/tl/pca/","title":"<code>msmu.tl.pca</code>","text":"<p>Perform Principal Component Analysis (PCA) on the specified modality of the MuData object.</p> <ul> <li>Repository</li> <li>Documentation</li> </ul> References <p>Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel, O., ... &amp; Duchesnay, E. (2011). Scikit-learn: Machine learning in Python. Journal of machine learning research, 12(Oct), 2825-2830.</p> <p>Andrzej M., Waldemar R. (1993). Principal Component Analysis (PCA). Computers &amp; Geosciences, 19(3), 303-342.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the data.</p> required <code>modality</code> <code>str</code> <p>The modality to perform PCA on.</p> required <code>layer</code> <code>str | None</code> <p>Layer to use for quantification aggregation. If None, the default layer (.X) will be used. Defaults to \"scaled\".</p> <code>None</code> <code>n_components</code> <code>int | None</code> <p>Number of components to keep. if n_components is not set all components are kept::</p> <pre><code>n_components == min(n_samples, n_features)\n</code></pre> <p>If <code>n_components == 'mle'</code> and <code>svd_solver == 'full'</code>, Minka's MLE is used to guess the dimension. Use of <code>n_components == 'mle'</code> will interpret <code>svd_solver == 'auto'</code> as <code>svd_solver == 'full'</code>.</p> <p>If <code>0 &lt; n_components &lt; 1</code> and <code>svd_solver == 'full'</code>, select the number of components such that the amount of variance that needs to be explained is greater than the percentage specified by n_components.</p> <p>If <code>svd_solver == 'arpack'</code>, the number of components must be strictly less than the minimum of n_features and n_samples.</p> <p>Hence, the None case results in:</p> <pre><code>n_components == min(n_samples, n_features) - 1\n</code></pre> <code>None</code> <code>svd_solver</code> <code>Literal['auto', 'full', 'arpack', 'randomized']</code> <p>\"auto\":     The solver is selected by a default 'auto' policy is based on <code>X.shape</code> and     <code>n_components</code>: if the input data has fewer than 1000 features and     more than 10 times as many samples, then the \"covariance_eigh\"     solver is used. Otherwise, if the input data is larger than 500x500     and the number of components to extract is lower than 80% of the     smallest dimension of the data, then the more efficient     \"randomized\" method is selected. Otherwise the exact \"full\" SVD is     computed and optionally truncated afterwards.</p> <p>\"full\" :     Run exact full SVD calling the standard LAPACK solver via     <code>scipy.linalg.svd</code> and select the components by postprocessing</p> <p>\"arpack\" :     Run SVD truncated to <code>n_components</code> calling ARPACK solver via     <code>scipy.sparse.linalg.svds</code>. It requires strictly     <code>0 &lt; n_components &lt; min(X.shape)</code></p> <p>\"randomized\" :     Run randomized SVD by the method of Halko et al.</p> <code>'auto'</code> <code>random_state</code> <code>int | None</code> <p>Used when the 'arpack' or 'randomized' solvers are used. Pass an int for reproducible results across multiple function calls.</p> <code>0</code> <code>key_added</code> <code>str</code> <p>Key in .obsm where the PCA dimensions will be stored. Defaults to \"X_pca\".</p> <code>'X_pca'</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to PCA constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>MuData</code> <p>Updated MuData object with PCA results.</p>"},{"location":"reference/tl/run_de/","title":"<code>msmu.tl.run_de</code>","text":"<p>Run Differential Expression Analysis (DEA) between two groups in a MuData object.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the data.</p> required <code>modality</code> <code>str</code> <p>Modality name within the MuData to analyze.</p> required <code>category</code> <code>str</code> <p>Observation category to define groups.</p> required <code>ctrl</code> <code>str</code> <p>Name of the control group.</p> required <code>expr</code> <code>str | None</code> <p>Name of the experimental group. If None, all other groups are used.</p> <code>None</code> <code>layer</code> <code>str | None</code> <p>Layer to use for quantification aggregation. If None, the default layer (.X) will be used. Defaults to None.</p> <code>None</code> <code>stat_method</code> <code>Literal['welch', 'student', 'wilcoxon']</code> <p>Statistical test to use (\"welch\", \"student\", \"wilcoxon\").</p> <code>'welch'</code> <code>measure</code> <code>Literal['median', 'mean']</code> <p>Measure of central tendency to use (\"median\" or \"mean\") for fold-change.</p> <code>'median'</code> <code>n_resamples</code> <code>int | None</code> <p>Number of resamples for permutation test. If None, no permutation test is performed.</p> <code>1000</code> <code>fdr</code> <code>bool | Literal['empirical', 'bh']</code> <p>Method for multiple test correction (\"empirical\", \"bh\", or False).</p> <code>'empirical'</code> <code>log_transformed</code> <code>bool</code> <p>If True, data is assumed to be log-transformed. Defaults to True.</p> <code>True</code> <code>_force_resample</code> <code>bool</code> <p>If True, forces resampling even if the number of resamples exceeds the number of combinations.</p> <code>False</code> <p>Returns:</p> Type Description <code>DeaResult</code> <p>DeaResult containing DE analysis results.</p>"},{"location":"reference/tl/umap/","title":"<code>msmu.tl.umap</code>","text":"<p>Calculate UMAP embedding for a given modality in MuData object.</p> <ul> <li>Repository</li> <li>Documentation</li> </ul> References <p>McInnes, L., Healy, J., &amp; Melville, J. (2018). UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction. arXiv preprint arXiv:1802.03426.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the data.</p> required <code>modality</code> <code>str</code> <p>The modality to perform UMAP on.</p> required <code>n_components</code> <code>int</code> <p>The dimension of the space to embed into. This defaults to 2 to provide easy visualization, but can reasonably be set to any integer value in the range 2 to 100.</p> <code>2</code> <code>n_neighbors</code> <code>int | None</code> <p>The size of local neighborhood (in terms of number of neighboring sample points) used for manifold approximation. Larger values result in more global views of the manifold, while smaller values result in more local data being preserved. In general values should be in the range 2 to 100.</p> <code>15</code> <code>layer</code> <code>str | None</code> <p>Layer to use for quantification aggregation. If None, the default layer (.X) will be used. Defaults to None.</p> <code>None</code> <code>metric</code> <code>str</code> <p>The metric to use to compute distances in high dimensional space. If a string is passed it must match a valid predefined metric. If a general metric is required a function that takes two 1d arrays and returns a float can be provided. For performance purposes it is required that this be a numba jit'd function. Valid string metrics include:</p> <ul> <li>euclidean</li> <li>manhattan</li> <li>chebyshev</li> <li>minkowski</li> <li>canberra</li> <li>braycurtis</li> <li>mahalanobis</li> <li>wminkowski</li> <li>seuclidean</li> <li>cosine</li> <li>correlation</li> <li>haversine</li> <li>hamming</li> <li>jaccard</li> <li>dice</li> <li>russelrao</li> <li>kulsinski</li> <li>ll_dirichlet</li> <li>hellinger</li> <li>rogerstanimoto</li> <li>sokalmichener</li> <li>sokalsneath</li> <li>yule</li> </ul> <p>Metrics that take arguments (such as minkowski, mahalanobis etc.) can have arguments passed via the metric_kwds dictionary. At this time care must be taken and dictionary elements must be ordered appropriately; this will hopefully be fixed in the future.</p> <code>'euclidean'</code> <code>init</code> <code>str</code> <p>How to initialize the low dimensional embedding. Options are:</p> <ul> <li>'spectral': use a spectral embedding of the fuzzy 1-skeleton</li> <li>'random': assign initial embedding positions at random.</li> <li>'pca': use the first n_components from PCA applied to the     input data.</li> <li>'tswspectral': use a spectral embedding of the fuzzy     1-skeleton, using a truncated singular value decomposition to     \"warm\" up the eigensolver. This is intended as an alternative     to the 'spectral' method, if that takes an  excessively long     time to complete initialization (or fails to complete).</li> <li>A numpy array of initial embedding positions.</li> </ul> <code>'random'</code> <code>min_dist</code> <code>float</code> <p>The effective minimum distance between embedded points. Smaller values will result in a more clustered/clumped embedding where nearby points on the manifold are drawn closer together, while larger values will result on a more even dispersal of points. The value should be set relative to the <code>spread</code> value, which determines the scale at which embedded points will be spread out.</p> <code>0.1</code> <code>random_state</code> <code>int | None</code> <p>RandomState instance or None, optional (default: None) If int, random_state is the seed used by the random number generator; If RandomState instance, random_state is the random number generator; If None, the random number generator is the RandomState instance used by <code>np.random</code>.</p> <code>None</code> <code>key_added</code> <code>str</code> <p>Key in .obsm where the UMAP dimensions will be stored. Defaults to \"X_umap\".</p> <code>'X_umap'</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments passed to UMAP constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>MuData</code> <p>Updated MuData object with UMAP results.</p>"},{"location":"reference/utils/add_quant/","title":"<code>msmu.utils.add_quant</code>","text":"<p>Add quantification data to the MuData object as a new modality.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>The MuData object to which the quantification data will be added.</p> required <code>quant_data</code> <code>str | DataFrame</code> <p>The quantification data, either as a file path or a DataFrame.</p> required <code>quant_tool</code> <code>str</code> <p>The tool used for quantification (e.g., \"flashlfq\").</p> required <code>index_name</code> <code>str | None</code> <p>Optional; the name of the index column in the quantification data (when changed obs.index with reindex_obs function). default is None.</p> <code>None</code> <p>Returns:</p> Type Description <code>MuData</code> <p>The modified MuData object with the added quantification modality.</p>"},{"location":"reference/utils/attach_fasta/","title":"<code>msmu.utils.attach_fasta</code>","text":"<p>Attach FASTA metadata to the MuData object.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object to attach FASTA metadata to.</p> required <code>fasta_file</code> <code>str | None</code> <p>Path to the FASTA file. If None, fetch from UniProt (not implemented).</p> required <p>Returns:</p> Type Description <code>MuData</code> <p>MuData object with attached FASTA metadata.</p>"},{"location":"reference/utils/get_label/","title":"<code>msmu.utils.get_label</code>","text":""},{"location":"reference/utils/get_modality_dict/","title":"<code>msmu.utils.get_modality_dict</code>","text":"<p>Get modality data from MuData object</p>"},{"location":"reference/utils/map_fasta/","title":"<code>msmu.utils.map_fasta</code>","text":"<p>Map protein groups to gene names using a FASTA metadata DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object containing the modality to map.</p> required <code>modality</code> <code>str</code> <p>The modality in the MuData object to map.</p> required <code>categories</code> <code>list[str]</code> <p>List of categories to map from fasta metadata.</p> <code>['Protein ID', 'Gene', 'Description', 'Organism']</code> <p>Returns:</p> Type Description <code>MuData</code> <p>MuData object with updated modality var.</p>"},{"location":"reference/utils/parse_uniprot_accession/","title":"<code>msmu.utils.parse_uniprot_accession</code>","text":""},{"location":"reference/utils/reindex_obs/","title":"<code>msmu.utils.reindex_obs</code>","text":"<p>Reindex the observation (obs) of the MuData object to ensure consistency across modalities.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>The MuData object containing the observations to reindex.</p> required <code>column</code> <code>str</code> <p>The column name in mdata.obs to use for reindexing.</p> required <p>Returns:</p> Type Description <code>MuData</code> <p>md.MuData: The modified MuData object with reindexed observations.</p>"},{"location":"reference/utils/select_repr_protein/","title":"<code>msmu.utils.select_repr_protein</code>","text":"<p>Select canonical protein from protein list based on priority. canonical &gt; swissprot &gt; trembl &gt; contam</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object with protein groups inferred</p> required <code>modality</code> <code>str</code> <p>Modality name for protein data</p> required <p>Returns:</p> Type Description <code>MuData</code> <p>MuData object with representative proteins selected</p>"},{"location":"reference/utils/split_tmt/","title":"<code>msmu.utils.split_tmt</code>","text":"<p>Split TMT channels in a MuData object into separate modalities based on a mapping.</p>"},{"location":"reference/utils/split_tmt/#msmu.utils.split_tmt--parameters","title":"Parameters","text":"<p>mdata : MuData     The MuData object containing TMT data. map : dict[str, str] | pd.Series | pd.DataFrame     A mapping of filenames to set names. If a DataFrame is provided, it should have two columns: the first for filenames and the second for set names.</p>"},{"location":"reference/utils/split_tmt/#msmu.utils.split_tmt--returns","title":"Returns","text":"<p>MuData     The modified MuData object with TMT channels split into separate modalities.</p>"},{"location":"reference/utils/subset/","title":"<code>msmu.utils.subset</code>","text":""},{"location":"reference/utils/subset/#msmu.utils.subset.split_tmt","title":"split_tmt","text":"<pre><code>split_tmt(mdata, map)\n</code></pre> <p>Split TMT channels in a MuData object into separate modalities based on a mapping.</p>"},{"location":"reference/utils/subset/#msmu.utils.subset.split_tmt--parameters","title":"Parameters","text":"<p>mdata : MuData     The MuData object containing TMT data. map : dict[str, str] | pd.Series | pd.DataFrame     A mapping of filenames to set names. If a DataFrame is provided, it should have two columns: the first for filenames and the second for set names.</p>"},{"location":"reference/utils/subset/#msmu.utils.subset.split_tmt--returns","title":"Returns","text":"<p>MuData     The modified MuData object with TMT channels split into separate modalities.</p>"},{"location":"reference/utils/subset/#msmu.utils.subset.subset","title":"subset","text":"<pre><code>subset(mdata, modality, cond_var=None, cond_obs=None)\n</code></pre> <p>Subset MuData object based on condition.</p> <p>Parameters:</p> Name Type Description Default <code>mdata</code> <code>MuData</code> <p>MuData object to subset.</p> required <code>modality</code> <code>str</code> <p>Modality to subset.</p> required <code>cond_var</code> <code>str</code> <p>Condition to subset variables.</p> <code>None</code> <code>cond_obs</code> <code>str</code> <p>Condition to subset observations.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>mdata</code> <code>MuData</code> <p>Subsetted MuData object.</p>"},{"location":"reference/utils/uns_logger/","title":"<code>msmu.utils.uns_logger</code>","text":""},{"location":"tutorials/dda-lfq/","title":"DDA-LFQ","text":"In\u00a0[\u00a0]: Copied! <pre>base_dir = \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/sage_lfq\"\nsage_idents = f\"{base_dir}/sage/results.sage.tsv\"\nsage_quants = f\"{base_dir}/sage/lfq.tsv\"\nmeta = f\"{base_dir}/meta.csv\"\n</pre> base_dir = \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/sage_lfq\" sage_idents = f\"{base_dir}/sage/results.sage.tsv\" sage_quants = f\"{base_dir}/sage/lfq.tsv\" meta = f\"{base_dir}/meta.csv\" In\u00a0[25]: Copied! <pre>import msmu as mm\nimport pandas as pd\nimport plotly.io as pio\n\npio.renderers.default = \"png\"\n</pre> import msmu as mm import pandas as pd import plotly.io as pio  pio.renderers.default = \"png\" In\u00a0[26]: Copied! <pre># Sage format\nmdata = mm.read_sage(identification_file=sage_idents, quantification_file=sage_quants, label=\"label_free\")\n\n# MaxQuant format\n# mdata = mm.read_maxquant(identification_file=\"path_to_maxquant_output\", label=\"label_free\", acquisition=\"dda\")\n\n# FragPipe format\n# mdata = mm.read_fragpipe(identification_file=\"path_to_fragpipe_output\", label=\"label_free\", acquisition=\"dda\")\n</pre> # Sage format mdata = mm.read_sage(identification_file=sage_idents, quantification_file=sage_quants, label=\"label_free\")  # MaxQuant format # mdata = mm.read_maxquant(identification_file=\"path_to_maxquant_output\", label=\"label_free\", acquisition=\"dda\")  # FragPipe format # mdata = mm.read_fragpipe(identification_file=\"path_to_fragpipe_output\", label=\"label_free\", acquisition=\"dda\") <pre>INFO - Identification file loaded: (5000, 40)\nINFO - Quantification file loaded: (3578, 12)\nINFO - Decoy entries separated: (345, 15)\n</pre> In\u00a0[27]: Copied! <pre>mdata\n</pre> mdata Out[27]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 8233\n  2 modalities\n    psm:\t6 x 4655\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value', 'rt', 'calcmass'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy'\n      varm:\t'search_result'\n    peptide:\t6 x 3578\n      uns:\t'level'</pre> In\u00a0[\u00a0]: Copied! <pre>meta_df = pd.read_csv(\n    \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/sage_lfq/meta.csv\"\n)\nmeta_df = meta_df.set_index(\"sample_id\")  # set the index to match sample id in mdata.obs\n\nmdata.obs = mdata.obs.join(meta_df)\nmdata.push_obs()  # update all modalities with the new obs data\nmdata.obs\n</pre> meta_df = pd.read_csv(     \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/sage_lfq/meta.csv\" ) meta_df = meta_df.set_index(\"sample_id\")  # set the index to match sample id in mdata.obs  mdata.obs = mdata.obs.join(meta_df) mdata.push_obs()  # update all modalities with the new obs data mdata.obs Out[\u00a0]: set sample_name condition replicate QExHF04026 S1 G1-1 G1 1 QExHF04028 S1 G2-1 G2 1 QExHF04036 S1 G1-2 G1 2 QExHF04038 S1 G2-2 G2 2 QExHF04046 S1 G1-3 G1 3 QExHF04048 S1 G2-3 G2 3 In\u00a0[\u00a0]: Copied! <pre>mdata.write_h5mu(\"dda_lfq_PXD012986_raw.h5mu\")\n</pre> mdata.write_h5mu(\"dda_lfq_PXD012986_raw.h5mu\") In\u00a0[29]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\")\nmdata = mm.pp.apply_filter(mdata, modality=\"psm\")\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\") mdata = mm.pp.apply_filter(mdata, modality=\"psm\")  mdata Out[29]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 7837\n  obs:\t'set', 'sample_name', 'condition', 'replicate'\n  uns:\t'_cmd'\n  2 modalities\n    psm:\t6 x 4259\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value', 'rt', 'calcmass'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t6 x 3578\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      uns:\t'level'</pre> In\u00a0[30]: Copied! <pre>mdata = mm.pp.to_peptide(mdata)\n</pre> mdata = mm.pp.to_peptide(mdata) <pre>INFO - Peptide-level identifications: 3634 (3615 at 1% FDR)\n</pre> <pre>Using existing peptide quantification data.\n</pre> In\u00a0[31]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"peptide\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"peptide\")\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"peptide\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"peptide\")  mdata Out[31]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 7874\n  obs:\t'set', 'sample_name', 'condition', 'replicate'\n  uns:\t'_cmd'\n  2 modalities\n    psm:\t6 x 4259\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value', 'rt', 'calcmass'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t6 x 3615\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'</pre> In\u00a0[\u00a0]: Copied! <pre>mdata = mm.pp.log2_transform(mdata, modality=\"peptide\")\nmdata = mm.pp.normalize(mdata, modality=\"peptide\", method=\"median\")\n</pre> mdata = mm.pp.log2_transform(mdata, modality=\"peptide\") mdata = mm.pp.normalize(mdata, modality=\"peptide\", method=\"median\") In\u00a0[33]: Copied! <pre>mdata = mm.pp.infer_protein(mdata)\n</pre> mdata = mm.pp.infer_protein(mdata) <pre>INFO - Starting protein inference\nINFO - Initial proteins: 3651\nINFO - Removed indistinguishable: 1586\nINFO - Removed subsettable: 539\nINFO - Removed subsumable: 2\nINFO - Total protein groups: 1524\n</pre> In\u00a0[34]: Copied! <pre>mdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"median_intensity\")\n</pre> mdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"median_intensity\") <pre>INFO - Ranking features by 'median_intensity' to select top 3 features.\nINFO - Protein-level identifications :  1489 (1463 at 1% FDR)\n</pre> In\u00a0[35]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"protein\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"protein\")\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"protein\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"protein\")  mdata Out[35]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 9337\n  obs:\t'set', 'sample_name', 'condition', 'replicate'\n  uns:\t'_cmd'\n  3 modalities\n    psm:\t6 x 4259\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value', 'rt', 'calcmass'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t6 x 3615\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value', 'protein_group', 'peptide_type'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'\n    protein:\t6 x 1463\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'count_psm', 'count_stripped_peptide', 'PEP', 'q_value'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'</pre> In\u00a0[13]: Copied! <pre>mm.pl.plot_id(mdata, modality=\"protein\", colorby=\"condition\", obs_column=\"sample_name\")\n</pre> mm.pl.plot_id(mdata, modality=\"protein\", colorby=\"condition\", obs_column=\"sample_name\") In\u00a0[14]: Copied! <pre>mm.pl.plot_intensity(mdata, modality=\"protein\", groupby=\"condition\", obs_column=\"sample_name\")\n</pre> mm.pl.plot_intensity(mdata, modality=\"protein\", groupby=\"condition\", obs_column=\"sample_name\") In\u00a0[15]: Copied! <pre>mdata.write_h5mu(\"dda_lfq_PXD012986.h5mu\")\n</pre> mdata.write_h5mu(\"dda_lfq_PXD012986.h5mu\")"},{"location":"tutorials/dda-lfq/#dda-label-free","title":"DDA - Label-Free\u00b6","text":"<p>This tutorial demonstrates how to analyze label-free quantification (LFQ) data from data-dependent acquisition (DDA) using the <code>msmu</code> package.</p>"},{"location":"tutorials/dda-lfq/#data-preparation","title":"Data Preparation\u00b6","text":"<p>Original dataset is from PXD012986 (Uszkoreit et al., 2022) and search was performed with <code>Sage</code> v0.14.7.</p> <p>For demonstration purposes, the example dataset was reduced to six samples and a total of 5,000 PSMs.</p>"},{"location":"tutorials/dda-lfq/#load-required-packages","title":"Load Required Packages\u00b6","text":"<p>If you haven't installed the <code>msmu</code> package yet, please follow the installation guide.</p>"},{"location":"tutorials/dda-lfq/#read-data","title":"Read Data\u00b6","text":"<p>You can read data from various proteomics software outputs. Below are examples for <code>Sage</code>, <code>MaxQuant</code>, and <code>FragPipe</code> formats.</p> <p>For this tutorial, we will use the <code>Sage</code> output as an example.</p> <p><code>read_sage()</code> function reads the <code>Sage</code> output files (<code>lfq.tsv</code>, <code>results.sage.tsv</code>) and creates modalities at MuData object.</p>"},{"location":"tutorials/dda-lfq/#adding-metadata","title":"Adding Metadata\u00b6","text":"<p>Optionally, you can add metadata for samples to the <code>mdata.obs</code> dataframe. Make sure that the index of the metadata dataframe matches the sample names in <code>mdata.obs</code>.</p>"},{"location":"tutorials/dda-lfq/#saving-raw-mudata-object","title":"Saving Raw MuData Object\u00b6","text":"<p>After reading the search output, saving the MuData object as an <code>h5mu</code> file is recommended for future use.</p>"},{"location":"tutorials/dda-lfq/#handling-psm-level","title":"Handling PSM level\u00b6","text":""},{"location":"tutorials/dda-lfq/#filtering-psm","title":"Filtering - PSM\u00b6","text":"<p>You can filter the data based on the column values, such as q-value. You can also filter the data based on string containment, which can be useful for removing contaminants or decoys.</p> <p>Filtering is split into two steps: first, you mark a filter condition using <code>mm.pp.add_filter()</code>, and then you apply the filter using <code>mm.pp.apply_filter()</code>.</p> <p>Here, we keep protein groups with q-value &lt; 0.01 and remove contaminants (protein IDs containing \"contam_\").</p>"},{"location":"tutorials/dda-lfq/#handling-peptide-level","title":"Handling peptide level\u00b6","text":""},{"location":"tutorials/dda-lfq/#summarization-peptide","title":"Summarization - peptide\u00b6","text":"<p>You can summarize psm-level data to peptide-level data using the <code>mm.pp.to_peptide()</code> function.</p>"},{"location":"tutorials/dda-lfq/#filtering-peptide","title":"Filtering - peptide\u00b6","text":""},{"location":"tutorials/dda-lfq/#normalization","title":"Normalization\u00b6","text":"<p>Here, we log2 transform and normalize the data at the peptide level.</p> <p>Median centering normalization is applied using <code>mm.pp.normalize()</code> function.</p>"},{"location":"tutorials/dda-lfq/#protein-inference","title":"Protein inference\u00b6","text":"<p>You can infer protein-level data from peptide-level data using the <code>mm.pp.infer_protein()</code> function.</p>"},{"location":"tutorials/dda-lfq/#handling-protein-level","title":"Handling protein level\u00b6","text":""},{"location":"tutorials/dda-lfq/#summarization-protein","title":"Summarization - protein\u00b6","text":"<p>You can summarize peptide-level data to protein-level data using the <code>mm.pp.to_protein()</code> function.</p> <p>As default, top 3 peptides within protein group can be used for protein group quantification aggregation. If top_n is None, all peptides will be used.</p>"},{"location":"tutorials/dda-lfq/#filtering-protein","title":"Filtering - protein\u00b6","text":""},{"location":"tutorials/dda-lfq/#visualization","title":"Visualization\u00b6","text":""},{"location":"tutorials/dda-lfq/#id-plot","title":"ID plot\u00b6","text":""},{"location":"tutorials/dda-lfq/#intensity-distribution-plot","title":"Intensity distribution plot\u00b6","text":""},{"location":"tutorials/dda-lfq/#saving-processed-mudata-object","title":"Saving Processed MuData Object\u00b6","text":"<p>You can save MuData object into an <code>h5mu</code> file. This allows you to easily reload the processed data in future sessions without repeating the entire analysis pipeline.</p>"},{"location":"tutorials/dda-lfq/#citation","title":"Citation\u00b6","text":"<p>Uszkoreit, J., Barkovits, K., Pacharra, S., Pfeiffer, K., Steinbach, S., Marcus, K., &amp; Eisenacher, M. (2022). Dataset containing physiological amounts of spike-in proteins into murine C2C12 background as a ground truth quantitative LC-MS/MS reference. Data in Brief, 43, 108435.</p> <p>Lazear, M. R. (2023). Sage: an open-source tool for fast proteomics searching and quantification at scale. Journal of Proteome Research, 22(11), 3652-3659.</p>"},{"location":"tutorials/dda-tmt/","title":"DDA-TMT","text":"In\u00a0[\u00a0]: Copied! <pre>base_dir = \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/sage_tmt\"\nsage_idents = f\"{base_dir}/sage/results.sage.tsv\"\nsage_quants = f\"{base_dir}/sage/tmt.tsv\"\nmeta = f\"{base_dir}/meta.csv\"\n</pre> base_dir = \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/sage_tmt\" sage_idents = f\"{base_dir}/sage/results.sage.tsv\" sage_quants = f\"{base_dir}/sage/tmt.tsv\" meta = f\"{base_dir}/meta.csv\" In\u00a0[24]: Copied! <pre>import msmu as mm\nimport pandas as pd\nimport plotly.io as pio\n\npio.renderers.default = \"png\"\n</pre> import msmu as mm import pandas as pd import plotly.io as pio  pio.renderers.default = \"png\" In\u00a0[3]: Copied! <pre># Sage format\nmdata = mm.read_sage(identification_file=sage_idents, quantification_file=sage_quants, label=\"tmt\")\n\n# MaxQuant format\n# mdata = mm.read_maxquant(identification_file=\"path_to_maxquant_output\", label=\"tmt\", acquisition=\"dda\")\n\n# FragPipe format\n# mdata = mm.read_fragpipe(identification_file=\"path_to_fragpipe_output\", label=\"tmt\", acquisition=\"dda\")\n</pre> # Sage format mdata = mm.read_sage(identification_file=sage_idents, quantification_file=sage_quants, label=\"tmt\")  # MaxQuant format # mdata = mm.read_maxquant(identification_file=\"path_to_maxquant_output\", label=\"tmt\", acquisition=\"dda\")  # FragPipe format # mdata = mm.read_fragpipe(identification_file=\"path_to_fragpipe_output\", label=\"tmt\", acquisition=\"dda\") <pre>INFO - Identification file loaded: (5000, 40)\nINFO - Quantification file loaded: (5000, 9)\nINFO - Decoy entries separated: (1195, 13)\n</pre> In\u00a0[4]: Copied! <pre>mdata\n</pre> mdata Out[4]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 3805\n  1 modality\n    psm:\t6 x 3805\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy'\n      varm:\t'search_result'</pre> In\u00a0[5]: Copied! <pre>meta_df = pd.read_csv(meta, dtype=str)\nmeta_df = meta_df.set_index(\"tag\")  # set the index to match sample id in mdata.obs\n\nmdata.obs = mdata.obs.join(meta_df)\nmdata.push_obs()  # update all modalities with the new obs data\nmdata.obs\n</pre> meta_df = pd.read_csv(meta, dtype=str) meta_df = meta_df.set_index(\"tag\")  # set the index to match sample id in mdata.obs  mdata.obs = mdata.obs.join(meta_df) mdata.push_obs()  # update all modalities with the new obs data mdata.obs Out[5]: set sample_id sample_name condition 126 S1 t0h t0h t0 127 S1 t1h t1h t1 128 S1 t2h t2h t2 129 S1 t6h t6h t6 130 S1 t24h t24h t24 131 S1 t120h t120h t120 In\u00a0[6]: Copied! <pre>mdata = mdata[(mdata.obs[\"condition\"] != \"BLANK\"), :]\n</pre> mdata = mdata[(mdata.obs[\"condition\"] != \"BLANK\"), :] In\u00a0[\u00a0]: Copied! <pre>mdata.write_h5mu(\"dda_tmt_PXD013361_raw.h5mu\")\n</pre> mdata.write_h5mu(\"dda_tmt_PXD013361_raw.h5mu\") In\u00a0[7]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\")\nmdata = mm.pp.apply_filter(mdata, modality=\"psm\")\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\") mdata = mm.pp.apply_filter(mdata, modality=\"psm\")  mdata Out[7]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 2264\n  obs:\t'set', 'sample_id', 'sample_name', 'condition'\n  uns:\t'_cmd'\n  1 modality\n    psm:\t6 x 2264\n      obs:\t'set', 'sample_id', 'sample_name', 'condition'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'</pre> In\u00a0[\u00a0]: Copied! <pre>mdata = mm.pp.log2_transform(mdata, modality=\"psm\")\nmdata = mm.pp.normalize(mdata, modality=\"psm\", method=\"median\", fraction=True)\n\n# GIS-based scaling (if needed)\n# mdata = mm.pp.correct_batch_effect(mdata=mdata, modality=\"psm\", method=\"gis\", gis_prefix=\"POOLED_\")\n</pre> mdata = mm.pp.log2_transform(mdata, modality=\"psm\") mdata = mm.pp.normalize(mdata, modality=\"psm\", method=\"median\", fraction=True)  # GIS-based scaling (if needed) # mdata = mm.pp.correct_batch_effect(mdata=mdata, modality=\"psm\", method=\"gis\", gis_prefix=\"POOLED_\") In\u00a0[9]: Copied! <pre># Computing precursor isolation purity\n# mdata = mm.pp.compute_precursor_isolation_purity(mdata, mzml_paths=[\"path/to/sample1.mzML\", \"path/to/sample2.mzML\", ...])\n</pre> # Computing precursor isolation purity # mdata = mm.pp.compute_precursor_isolation_purity(mdata, mzml_paths=[\"path/to/sample1.mzML\", \"path/to/sample2.mzML\", ...]) In\u00a0[10]: Copied! <pre>mdata = mm.pp.to_peptide(mdata, purity_threshold=0.7)\n\n# If precursor purity is computed, filter low-purity features\n# mdata = mm.pp.to_peptide(mdata, purity_threshold=0.7)\n</pre> mdata = mm.pp.to_peptide(mdata, purity_threshold=0.7)  # If precursor purity is computed, filter low-purity features # mdata = mm.pp.to_peptide(mdata, purity_threshold=0.7) <pre>WARNING - Purity column not found in psm modality for TMT data. Skipping purity filtering.\nINFO - Peptide-level identifications: 2204 (2151 at 1% FDR)\n</pre> <pre>Building new peptide quantification data.\n</pre> In\u00a0[11]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"peptide\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"peptide\")\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"peptide\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"peptide\")  mdata Out[11]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 4415\n  obs:\t'set', 'sample_id', 'sample_name', 'condition'\n  uns:\t'_cmd'\n  2 modalities\n    psm:\t6 x 2264\n      obs:\t'set', 'sample_id', 'sample_name', 'condition'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t6 x 2151\n      obs:\t'set', 'sample_id', 'sample_name', 'condition'\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'</pre> In\u00a0[12]: Copied! <pre>mdata = mm.pp.infer_protein(mdata)\n</pre> mdata = mm.pp.infer_protein(mdata) <pre>INFO - Starting protein inference\nINFO - Initial proteins: 1722\nINFO - Removed indistinguishable: 175\nINFO - Removed subsettable: 62\nINFO - Removed subsumable: 0\nINFO - Total protein groups: 1485\n</pre> In\u00a0[13]: Copied! <pre>mdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"median_intensity\")\n</pre> mdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"median_intensity\") <pre>INFO - Ranking features by 'median_intensity' to select top 3 features.\nINFO - Protein-level identifications :  1465 (1432 at 1% FDR)\n</pre> In\u00a0[14]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"protein\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"protein\")\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"protein\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"protein\")  mdata Out[14]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 5847\n  obs:\t'set', 'sample_id', 'sample_name', 'condition'\n  uns:\t'_cmd'\n  3 modalities\n    psm:\t6 x 2264\n      obs:\t'set', 'sample_id', 'sample_name', 'condition'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t6 x 2151\n      obs:\t'set', 'sample_id', 'sample_name', 'condition'\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value', 'protein_group', 'peptide_type'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'\n    protein:\t6 x 1432\n      obs:\t'set', 'sample_id', 'sample_name', 'condition'\n      var:\t'count_psm', 'count_stripped_peptide', 'PEP', 'q_value'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'</pre> In\u00a0[15]: Copied! <pre>mm.pl.plot_id(mdata, modality=\"protein\", obs_column=\"sample_name\")\n</pre> mm.pl.plot_id(mdata, modality=\"protein\", obs_column=\"sample_name\") In\u00a0[16]: Copied! <pre>mm.pl.plot_intensity(mdata, modality=\"protein\", groupby=\"condition\", obs_column=\"sample_name\")\n</pre> mm.pl.plot_intensity(mdata, modality=\"protein\", groupby=\"condition\", obs_column=\"sample_name\") In\u00a0[17]: Copied! <pre>mdata.write_h5mu(\"dda_tmt_PXD013361.h5mu\")\n</pre> mdata.write_h5mu(\"dda_tmt_PXD013361.h5mu\")"},{"location":"tutorials/dda-tmt/#dda-tmt","title":"DDA - TMT\u00b6","text":"<p>This tutorial demonstrates how to analyze Tandem Mass Tag (TMT) labeled data from data-dependent acquisition (DDA) using <code>msmu</code> package.</p>"},{"location":"tutorials/dda-tmt/#data-preparation","title":"Data Preparation\u00b6","text":"<p>Original dataset is from PXD013361 (Magnusson et al., 2019) and the search was performed with <code>Sage</code> v0.14.7.</p> <p>For demonstration purposes, the example dataset has been trimmed to include only 5,000 PSMs.</p>"},{"location":"tutorials/dda-tmt/#load-required-packages","title":"Load Required Packages\u00b6","text":"<p>If you haven't installed the <code>msmu</code> package yet, please follow the installation guide.</p>"},{"location":"tutorials/dda-tmt/#read-data","title":"Read Data\u00b6","text":"<p>You can read data from various proteomics software outputs. Below are examples for <code>Sage</code>, <code>MaxQuant</code>, and <code>FragPipe</code> formats.</p> <p>For this tutorial, we will use the <code>Sage</code> output as an example.</p> <p><code>read_sage()</code> function reads the <code>Sage</code> output files (<code>tmt.tsv</code>, <code>results.sage.tsv</code>) and creates modalities at MuData object.</p>"},{"location":"tutorials/dda-tmt/#adding-metadata","title":"Adding Metadata\u00b6","text":"<p>Optionally, you can add metadata for samples to the <code>mdata.obs</code> dataframe. Make sure that the index of the metadata dataframe matches the sample names in <code>mdata.obs</code>.</p>"},{"location":"tutorials/dda-tmt/#removing-blank-channels","title":"Removing Blank Channels\u00b6","text":"<p>If your TMT data contains blank channels, you can remove them by subsetting <code>MuData</code> object.</p>"},{"location":"tutorials/dda-tmt/#saving-raw-mudata-object","title":"Saving Raw MuData Object\u00b6","text":"<p>After reading the search output, saving the MuData object as an <code>h5mu</code> file is recommended for future use.</p>"},{"location":"tutorials/dda-tmt/#handling-psm-level","title":"Handling PSM level\u00b6","text":""},{"location":"tutorials/dda-tmt/#filtering-psm","title":"Filtering - PSM\u00b6","text":"<p>You can filter the data based on the column values, such as q-value. You can also filter the data based on string containment, which can be useful for removing contaminants or decoys.</p> <p>Filtering is split into two steps: first, you mark a filter condition using <code>mm.pp.add_filter()</code>, and then you apply the filter using <code>mm.pp.apply_filter()</code>.</p> <p>Here, we keep protein groups with q-value &lt; 0.01 and remove contaminants (protein IDs containing \"contam_\").</p>"},{"location":"tutorials/dda-tmt/#normalization","title":"Normalization\u00b6","text":"<p>Here, we log2 transform and normalize the data at the PSM level.</p> <p>Median centering normalization is applied using <code>mm.pp.normalize()</code> function.</p> <p>Optionally, if you need to correct batch effects using Global Internal Standard (GIS) channels, you can scale the data using <code>mm.pp.scale_feature()</code> function. Make sure to have GIS channels in each TMT batch. The example code below assumes that the GIS channels are named with prefix \"POOLED_\".</p>"},{"location":"tutorials/dda-tmt/#computing-precursor-isolation-purity","title":"Computing precursor isolation purity\u00b6","text":"<p>For TMT data, it is recommended to compute precursor isolation purity to exclude low-purity features from quantification aggregation. <code>compute_precursor_isolation_purity()</code> function calculates precursor isolation purity using mzML files.</p> <p>For demonstration purposes, we will skip this step in the tutorial.</p>"},{"location":"tutorials/dda-tmt/#handling-peptide-level","title":"Handling peptide level\u00b6","text":""},{"location":"tutorials/dda-tmt/#summarization-peptide","title":"Summarization - peptide\u00b6","text":"<p>You can summarize psm-level data to peptide-level data using the <code>mm.pp.to_peptide()</code> function.</p> <p>If isolation purity was calculated and <code>purity_threshold</code> parameter is set, features below this cutoff are excluded from quantification aggregation.</p>"},{"location":"tutorials/dda-tmt/#filtering-peptide","title":"Filtering - peptide\u00b6","text":""},{"location":"tutorials/dda-tmt/#protein-inference","title":"Protein inference\u00b6","text":"<p>You can infer protein-level data from peptide-level data using the <code>mm.pp.infer_protein()</code> function.</p>"},{"location":"tutorials/dda-tmt/#handling-protein-level","title":"Handling protein level\u00b6","text":""},{"location":"tutorials/dda-tmt/#summarization-protein","title":"Summarization - protein\u00b6","text":"<p>You can summarize peptide-level data to protein-level data using the <code>mm.pp.to_protein()</code> function.</p> <p>As default, top 3 peptides within protein group can be used for protein group quantification aggregation. If top_n is None, all peptides will be used.</p>"},{"location":"tutorials/dda-tmt/#filtering-protein","title":"Filtering - protein\u00b6","text":""},{"location":"tutorials/dda-tmt/#visualization","title":"Visualization\u00b6","text":""},{"location":"tutorials/dda-tmt/#id-plot","title":"ID plot\u00b6","text":""},{"location":"tutorials/dda-tmt/#intensity-distribution-plot","title":"Intensity distribution plot\u00b6","text":""},{"location":"tutorials/dda-tmt/#saving-processed-mudata-object","title":"Saving Processed MuData Object\u00b6","text":"<p>You can save MuData object into an <code>h5mu</code> file. This allows you to easily reload the processed data in future sessions without repeating the entire analysis pipeline.</p>"},{"location":"tutorials/dda-tmt/#citation","title":"Citation\u00b6","text":"<p>Magnusson, R., Rundquist, O., Kim, M. J., Hellberg, S., Na, C. H., Benson, M., ... &amp; Gustafsson, M. (2019). A validated strategy to infer protein biomarkers from RNA-Seq by combining multiple mRNA splice variants and time-delay. BioRxiv, 599373.</p> <p>Lazear, M. R. (2023). Sage: an open-source tool for fast proteomics searching and quantification at scale. Journal of Proteome Research, 22(11), 3652-3659.</p>"},{"location":"tutorials/dea/","title":"DE Analysis","text":"In\u00a0[28]: Copied! <pre>import msmu as mm\nimport pandas as pd\n\nimport plotly.io as pio\npio.renderers.default = \"png\"\n</pre> import msmu as mm import pandas as pd  import plotly.io as pio pio.renderers.default = \"png\" In\u00a0[29]: Copied! <pre>base_dir = \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/sage_lfq\"\nsage_idents = f\"{base_dir}/sage/results.sage.tsv\"\nsage_quants = f\"{base_dir}/sage/lfq.tsv\"\nmeta = f\"{base_dir}/meta.csv\"\n\nmdata = mm.read_sage(identification_file=sage_idents, quantification_file=sage_quants, label=\"label_free\")\n\nmeta_df = pd.read_csv(\"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/sage_lfq/meta.csv\")\nmeta_df = meta_df.set_index(\"sample_id\")  # set the index to match sample id in mdata.obs\n\nmdata.obs = mdata.obs.join(meta_df)\nmdata.push_obs()  # update all modalities with the new obs data\n\nmdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\")\nmdata = mm.pp.apply_filter(mdata, modality=\"psm\")\n\nmdata = mm.pp.to_peptide(mdata)\nmdata = mm.pp.add_filter(mdata, modality=\"peptide\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"peptide\")\n\nmdata = mm.pp.log2_transform(mdata, modality=\"peptide\")\nmdata = mm.pp.normalise(mdata, modality=\"peptide\", method=\"median\")\n\nmdata = mm.pp.infer_protein(mdata)\n\nmdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"median_intensity\")\nmdata = mm.pp.add_filter(mdata, modality=\"protein\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"protein\")\n\nmdata\n</pre> base_dir = \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/sage_lfq\" sage_idents = f\"{base_dir}/sage/results.sage.tsv\" sage_quants = f\"{base_dir}/sage/lfq.tsv\" meta = f\"{base_dir}/meta.csv\"  mdata = mm.read_sage(identification_file=sage_idents, quantification_file=sage_quants, label=\"label_free\")  meta_df = pd.read_csv(\"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/sage_lfq/meta.csv\") meta_df = meta_df.set_index(\"sample_id\")  # set the index to match sample id in mdata.obs  mdata.obs = mdata.obs.join(meta_df) mdata.push_obs()  # update all modalities with the new obs data  mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\") mdata = mm.pp.apply_filter(mdata, modality=\"psm\")  mdata = mm.pp.to_peptide(mdata) mdata = mm.pp.add_filter(mdata, modality=\"peptide\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"peptide\")  mdata = mm.pp.log2_transform(mdata, modality=\"peptide\") mdata = mm.pp.normalise(mdata, modality=\"peptide\", method=\"median\")  mdata = mm.pp.infer_protein(mdata)  mdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"median_intensity\") mdata = mm.pp.add_filter(mdata, modality=\"protein\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"protein\")  mdata  <pre>INFO - Identification file loaded: (5000, 40)\nINFO - Quantification file loaded: (3578, 12)\nINFO - Decoy entries separated: (345, 15)\nINFO - Peptide-level identifications: 3634 (3615 at 1% FDR)\nINFO - Starting protein inference\nINFO - Initial proteins: 3651\n</pre> <pre>Using existing peptide quantification data.\n</pre> <pre>INFO - Removed indistinguishable: 1586\nINFO - Removed subsettable: 539\nINFO - Removed subsumable: 2\nINFO - Total protein groups: 1524\nINFO - Ranking features by 'median_intensity' to select top 3 features.\nINFO - Protein-level identifications :  1489 (1463 at 1% FDR)\n</pre> Out[29]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 9337\n  obs:\t'set', 'sample_name', 'condition', 'replicate'\n  uns:\t'_cmd'\n  3 modalities\n    psm:\t6 x 4259\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value', 'rt', 'calcmass'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t6 x 3615\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value', 'protein_group', 'peptide_type'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'\n    protein:\t6 x 1463\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'count_psm', 'count_stripped_peptide', 'PEP', 'q_value'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'</pre> In\u00a0[27]: Copied! <pre># mdata = mm.read_h5mu(\"dda_lfq_PXD012986.h5mu\")\n\n# mdata\n</pre> # mdata = mm.read_h5mu(\"dda_lfq_PXD012986.h5mu\")  # mdata In\u00a0[30]: Copied! <pre>de_res = mm.tl.run_de(\n    mdata,\n    modality=\"protein\",\n    category=\"condition\",  # category in .obs to define groups\n    ctrl=\"G1\",             # control group\n    expr=\"G2\",             # experimental group\n    stat_method=\"welch\",   # statistical test method: \"welch\", \"student\", \"wilcoxon\", default \"welch\"\n    measure=\"median\",      # measure of central tendancy for calculating fold-change: \"median\", \"mean\", default \"median\"\n    min_pct=0.5,           # minimum fraction of non-missing values in at least one group, default 0.5\n    fdr=\"empirical\",       # multiple testing correction method: \"empirical\", \"bh\", or None, default \"empirical\"\n    n_resamples=1000,      # by default, 1000 resamples; if None, simple parametric p-values are computed\n    log_transformed=True,  # whether data is log-transformed, default True\n)\n</pre> de_res = mm.tl.run_de(     mdata,     modality=\"protein\",     category=\"condition\",  # category in .obs to define groups     ctrl=\"G1\",             # control group     expr=\"G2\",             # experimental group     stat_method=\"welch\",   # statistical test method: \"welch\", \"student\", \"wilcoxon\", default \"welch\"     measure=\"median\",      # measure of central tendancy for calculating fold-change: \"median\", \"mean\", default \"median\"     min_pct=0.5,           # minimum fraction of non-missing values in at least one group, default 0.5     fdr=\"empirical\",       # multiple testing correction method: \"empirical\", \"bh\", or None, default \"empirical\"     n_resamples=1000,      # by default, 1000 resamples; if None, simple parametric p-values are computed     log_transformed=True,  # whether data is log-transformed, default True ) <pre>Running Permutations: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 20/20 [00:00&lt;00:00, 549.98it/s]\n</pre> In\u00a0[31]: Copied! <pre>de_res\n</pre> de_res Out[31]: <pre>DeaResult(stat_method='welch', ctrl='G1', expr='G2', features=array(['A0A023T778,G3UZW7,P61327,Q9CQL1',\n       'A0A068CB13,A2QBC3,B2CNX8,B2CNX9,G3XSF9,I6VCW8,P13006',\n       'A0A087WNT1,A0A087WPE4,A0A087WQE6,P83940', ..., 'Q9Z2U0', 'Q9Z2X1',\n       'Q9Z315'], shape=(1463,), dtype=object), repr_ctrl=array([23.032452, 25.08355 , 25.420649, ..., 26.587545, 25.655592,\n       22.321047], shape=(1463,), dtype=float32), repr_expr=array([23.090721, 28.73562 , 25.331665, ..., 26.365978, 25.997116,\n       22.347776], shape=(1463,), dtype=float32), pct_ctrl=array([100., 100., 100., ..., 100., 100., 100.], shape=(1463,)), pct_expr=array([100., 100., 100., ..., 100., 100., 100.], shape=(1463,)), log2fc=array([ 0.0582695 ,  3.652071  , -0.08898354, ..., -0.22156715,\n        0.34152412,  0.02672958], shape=(1463,), dtype=float32))</pre> In\u00a0[32]: Copied! <pre>de_res.to_df().head()\n</pre> de_res.to_df().head() Out[32]: features repr_ctrl repr_expr pct_ctrl pct_expr log2fc p_value q_value 0 A0A023T778,G3UZW7,P61327,Q9CQL1 23.032452 23.090721 100.0 100.0 0.058270 0.443105 0.813088 1 A0A068CB13,A2QBC3,B2CNX8,B2CNX9,G3XSF9,I6VCW8,... 25.083549 28.735620 100.0 100.0 3.652071 0.000174 0.075433 2 A0A087WNT1,A0A087WPE4,A0A087WQE6,P83940 25.420649 25.331665 100.0 100.0 -0.088984 0.970467 0.904035 3 A0A087WNT3,A0A087WNU9,A0A087WP64,A0A087WPE6,A0... NaN NaN 0.0 0.0 NaN NaN NaN 4 A0A087WNY6,A0A087WQA5,A0A087WQX8,A0A087WRP4,A0... 25.827114 25.794582 100.0 100.0 -0.032532 0.821479 0.880609 <p>After permutation test, guidance for log2FC threshold at 5% (or 1%) on two-sided tails of null distribution from permutations is also provided.</p> In\u00a0[33]: Copied! <pre>print(f\"Log2FC threshold at 5%: {de_res.fc_pct_5}\")\n</pre> print(f\"Log2FC threshold at 5%: {de_res.fc_pct_5}\") <pre>Log2FC threshold at 5%: 0.33\n</pre> <p>To visualize the DE results, <code>plot_volcano()</code> method is available. Log2FC and p-value thresholds can be set manually or automatically using the <code>fc_pct_5</code> attribute from the result object and p-value of <code>0.05</code>.</p> <p>Top significant features can be labelled using <code>label_top</code> parameter (sorted by log2FC).</p> In\u00a0[34]: Copied! <pre>de_res.plot_volcano()\n</pre> de_res.plot_volcano() In\u00a0[35]: Copied! <pre>de_res.plot_volcano(label_top=3)\n</pre> de_res.plot_volcano(label_top=3)"},{"location":"tutorials/dea/#differential-expression-de-analysis","title":"Differential Expression (DE) Analysis\u00b6","text":"<p>This tutorial demonstrates how to perform differential expression analysis using the <code>msmu</code> package. Details about DE analysis methods can be found in the Differential Expression (DE) Analysis section.</p>"},{"location":"tutorials/dea/#load-required-packages","title":"Load Required Packages\u00b6","text":""},{"location":"tutorials/dea/#data-preparation","title":"Data Preparation\u00b6","text":"<p>Use the <code>MuData</code> object as <code>mdata</code> processed in tutorials DDA-TMT, DDA-LFQ, or DIA-LFQ. It should have a modality to test, in this case, <code>protein</code>.</p> <p>In this tutorial, we will use the <code>mdata</code> processed in DDA-LFQ tutorial.</p>"},{"location":"tutorials/dea/#optional-load-mudata-from-local-file","title":"(Optional) Load MuData from local file\u00b6","text":"<p>If <code>MuData</code> were saved locally, provide the path to the file in <code>mm.read_h5mu()</code> function.</p>"},{"location":"tutorials/dea/#run-de-analysis","title":"Run DE analysis\u00b6","text":"<p>Permutation-based DE analysis basically provided by <code>mm.tl.run_de()</code> function. Here, we will compare two conditions, <code>G1</code> and <code>G2</code>, in the <code>condition</code> column of <code>mdata.obs</code>.</p> <p><code>modality</code> specifies which modality to perform DE analysis on. <code>category</code> indicates the column name in <code>mdata.obs</code> that contains the group labels.</p> <p><code>ctrl</code> and <code>expr</code> define the control and experimental groups, respectively.</p> <p><code>stat_method</code> allows you to choose the statistical test method, such as <code>welch</code>, <code>student</code>, or <code>wilcoxon</code>.</p> <p><code>measure</code> defines the measure of central tendency used for calculating fold-change, either <code>median</code> or <code>mean</code>.</p> <p><code>min_pct</code> sets the minimum fraction of non-missing values required in at least one group for a feature to be considered in the analysis.</p> <p><code>n_resamples</code> sets the number of resampling iterations for permutation testing; if set to <code>None</code>, simple parametric p-values are computed.</p> <p><code>fdr</code> specifies the multiple testing correction method, which can be <code>empirical</code>, <code>bh</code> (Benjamini-Hochberg), or <code>None</code>.</p> <p><code>log_transformed</code> indicates whether the data is log-transformed.</p> <p>More explanation for <code>run_de()</code> can be found in the DE Analysis documentation and the <code>mm.tl.run_de()</code> API reference.</p> <p>In an example below, we assign 1000 resamples, but only 20 permutations are performed because each group has 3 samples and 3 by 3 gives 20 combinations, which is <code>exact</code> test.</p>"},{"location":"tutorials/dea/#explore-de-results","title":"Explore DE results\u00b6","text":"<p>Result is stored in <code>DeaResult</code> object. And the object provides few methods to explore the results. This object provides <code>to_df()</code> method to convert the results into a pandas DataFrame for further exploration. And <code>plot_volcano()</code> method to visualize the results as a volcano plot.</p>"},{"location":"tutorials/dia-lfq/","title":"DIA-LFQ","text":"In\u00a0[\u00a0]: Copied! <pre>base_dir = \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/diann_dia\"\ndiann_idents = f\"{base_dir}/diann/report.parquet\"\nmeta = f\"{base_dir}/meta.csv\"\n</pre> base_dir = \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/diann_dia\" diann_idents = f\"{base_dir}/diann/report.parquet\" meta = f\"{base_dir}/meta.csv\" In\u00a0[2]: Copied! <pre>import msmu as mm\nimport pandas as pd\nimport plotly.io as pio\n\npio.renderers.default = \"png\"\n</pre> import msmu as mm import pandas as pd import plotly.io as pio  pio.renderers.default = \"png\" <pre>Determination of memory status is not supported on this \n platform, measuring for memoryleaks will never fail\n</pre> In\u00a0[3]: Copied! <pre># DIA-NN format\nmdata = mm.read_diann(identification_file=diann_idents)\n\n# MaxQuant format\n# mdata = mm.read_maxquant(identification_file=\"path_to_maxquant_output\", label=\"label_free\", acquisition=\"dia\")\n\n# FragPipe format\n# mdata = mm.read_fragpipe(identification_file=\"path_to_fragpipe_output\", label=\"label_free\", acquisition=\"dia\")\n</pre> # DIA-NN format mdata = mm.read_diann(identification_file=diann_idents)  # MaxQuant format # mdata = mm.read_maxquant(identification_file=\"path_to_maxquant_output\", label=\"label_free\", acquisition=\"dia\")  # FragPipe format # mdata = mm.read_fragpipe(identification_file=\"path_to_fragpipe_output\", label=\"label_free\", acquisition=\"dia\") <pre>INFO - Identification file loaded: (5069, 71)\nINFO - Identification and quantification data split: (5069, 73), (5069, 6)\nINFO - Decoy entries separated: (31, 9)\n</pre> In\u00a0[4]: Copied! <pre>mdata\n</pre> mdata Out[4]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 5038\n  1 modality\n    psm:\t6 x 5038\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'charge', 'peptide_length', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy'\n      varm:\t'search_result'</pre> In\u00a0[5]: Copied! <pre>meta_df = pd.read_csv(meta)\nmeta_df = meta_df.set_index(\"sample_id\")  # set the index to match sample id in mdata.obs\n\nmdata.obs = mdata.obs.join(meta_df)\nmdata.push_obs()  # update all modalities with the new obs data\nmdata.obs\n</pre> meta_df = pd.read_csv(meta) meta_df = meta_df.set_index(\"sample_id\")  # set the index to match sample id in mdata.obs  mdata.obs = mdata.obs.join(meta_df) mdata.push_obs()  # update all modalities with the new obs data mdata.obs Out[5]: set sample_name condition replicate QExHF03751 S1 G1-1 G1 1 QExHF03753 S1 G2-1 G2 1 QExHF03761 S1 G1-2 G1 2 QExHF03763 S1 G2-2 G2 2 QExHF03771 S1 G1-3 G1 3 QExHF03773 S1 G2-3 G2 3 In\u00a0[\u00a0]: Copied! <pre>mdata.write_h5mu(\"dia_lfq_PXD012988_raw.h5mu\")\n</pre> mdata.write_h5mu(\"dia_lfq_PXD012988_raw.h5mu\") In\u00a0[6]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\")\nmdata = mm.pp.apply_filter(mdata, modality=\"psm\")\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\") mdata = mm.pp.apply_filter(mdata, modality=\"psm\")  mdata Out[6]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 4985\n  obs:\t'set', 'sample_name', 'condition', 'replicate'\n  uns:\t'_cmd'\n  1 modality\n    psm:\t6 x 4985\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'charge', 'peptide_length', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'</pre> In\u00a0[\u00a0]: Copied! <pre>mdata = mm.pp.log2_transform(mdata, modality=\"psm\")\nmdata = mm.pp.normalize(mdata, modality=\"psm\", method=\"median\", fraction=True)\n</pre> mdata = mm.pp.log2_transform(mdata, modality=\"psm\") mdata = mm.pp.normalize(mdata, modality=\"psm\", method=\"median\", fraction=True) In\u00a0[8]: Copied! <pre>mdata = mm.pp.to_peptide(mdata)\n</pre> mdata = mm.pp.to_peptide(mdata) <pre>INFO - Peptide-level identifications: 972 (956 at 1% FDR)\n</pre> <pre>Building new peptide quantification data.\n</pre> In\u00a0[9]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"peptide\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"peptide\")\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"peptide\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"peptide\")  mdata Out[9]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 5941\n  obs:\t'set', 'sample_name', 'condition', 'replicate'\n  uns:\t'_cmd'\n  2 modalities\n    psm:\t6 x 4985\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'charge', 'peptide_length', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t6 x 956\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'</pre> In\u00a0[10]: Copied! <pre>mdata = mm.pp.infer_protein(mdata)\n</pre> mdata = mm.pp.infer_protein(mdata) <pre>INFO - Starting protein inference\nINFO - Initial proteins: 1643\nINFO - Removed indistinguishable: 789\nINFO - Removed subsettable: 57\nINFO - Removed subsumable: 0\nINFO - Total protein groups: 797\n</pre> In\u00a0[11]: Copied! <pre>mdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"total_intensity\")\n</pre> mdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"total_intensity\") <pre>INFO - Ranking features by 'total_intensity' to select top 3 features.\nINFO - Protein-level identifications :  792 (790 at 1% FDR)\n</pre> In\u00a0[12]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"protein\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"protein\")\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"protein\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"protein\")  mdata Out[12]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 6731\n  obs:\t'set', 'sample_name', 'condition', 'replicate'\n  uns:\t'_cmd'\n  3 modalities\n    psm:\t6 x 4985\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'charge', 'peptide_length', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t6 x 956\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value', 'protein_group', 'peptide_type'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'\n    protein:\t6 x 790\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'count_psm', 'count_stripped_peptide', 'PEP', 'q_value'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'</pre> In\u00a0[13]: Copied! <pre>mm.pl.plot_id(mdata, modality=\"protein\", colorby=\"condition\", obs_column=\"sample_name\")\n</pre> mm.pl.plot_id(mdata, modality=\"protein\", colorby=\"condition\", obs_column=\"sample_name\") In\u00a0[14]: Copied! <pre>mm.pl.plot_intensity(mdata, modality=\"protein\", groupby=\"condition\", obs_column=\"sample_name\")\n</pre> mm.pl.plot_intensity(mdata, modality=\"protein\", groupby=\"condition\", obs_column=\"sample_name\") In\u00a0[15]: Copied! <pre>mdata.write_h5mu(\"dia_lfq_PXD012988.h5mu\")\n</pre> mdata.write_h5mu(\"dia_lfq_PXD012988.h5mu\") In\u00a0[16]: Copied! <pre># Removing decoy features from DIA-NN output for mimicking data without decoy\n\nmdata = mm.read_diann(identification_file=diann_idents)\ndel mdata[\"psm\"].uns[\"decoy\"]\n\nmdata\n</pre> # Removing decoy features from DIA-NN output for mimicking data without decoy  mdata = mm.read_diann(identification_file=diann_idents) del mdata[\"psm\"].uns[\"decoy\"]  mdata <pre>INFO - Identification file loaded: (5069, 71)\nINFO - Identification and quantification data split: (5069, 73), (5069, 6)\nINFO - Decoy entries separated: (31, 9)\n</pre> Out[16]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 5038\n  1 modality\n    psm:\t6 x 5038\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'charge', 'peptide_length', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file'\n      varm:\t'search_result'</pre> In\u00a0[17]: Copied! <pre># Adding PG Q-value column for filtering\nmdata[\"psm\"].var[\"pg_q_value\"] = mdata[\"psm\"].varm[\"search_result\"][\"Lib.PG.Q.Value\"]\n\nmdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"pg_q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\")\nmdata = mm.pp.apply_filter(mdata, modality=\"psm\")\n\nmdata\n</pre> # Adding PG Q-value column for filtering mdata[\"psm\"].var[\"pg_q_value\"] = mdata[\"psm\"].varm[\"search_result\"][\"Lib.PG.Q.Value\"]  mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"pg_q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\") mdata = mm.pp.apply_filter(mdata, modality=\"psm\")  mdata Out[17]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 4946\n  uns:\t'_cmd'\n  1 modality\n    psm:\t6 x 4946\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'charge', 'peptide_length', 'PEP', 'q_value', 'pg_q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'filter'\n      varm:\t'search_result', 'filter'</pre> In\u00a0[\u00a0]: Copied! <pre>mdata = mm.pp.log2_transform(mdata, modality=\"psm\")\nmdata = mm.pp.normalize(mdata, modality=\"psm\", method=\"median\")\n</pre> mdata = mm.pp.log2_transform(mdata, modality=\"psm\") mdata = mm.pp.normalize(mdata, modality=\"psm\", method=\"median\") In\u00a0[19]: Copied! <pre>mdata = mm.pp.to_peptide(mdata, calculate_q=False)\n\nmap_df = mdata[\"psm\"].varm[\"search_result\"][[\"Modified.Sequence\", \"Protein.Group\", \"Proteotypic\"]]\nmap_df = map_df.drop_duplicates().set_index(\"Modified.Sequence\")\n\nmdata[\"peptide\"].var[\"protein_group\"] = mdata[\"peptide\"].var_names.map(map_df[\"Protein.Group\"])\nmdata[\"peptide\"].var[\"peptide_type\"] = mdata[\"peptide\"].var_names.map(map_df[\"Proteotypic\"])\nmdata[\"peptide\"].var[\"peptide_type\"] = [\"unique\" if x else \"shared\" for x in mdata[\"peptide\"].var[\"peptide_type\"]]\n</pre> mdata = mm.pp.to_peptide(mdata, calculate_q=False)  map_df = mdata[\"psm\"].varm[\"search_result\"][[\"Modified.Sequence\", \"Protein.Group\", \"Proteotypic\"]] map_df = map_df.drop_duplicates().set_index(\"Modified.Sequence\")  mdata[\"peptide\"].var[\"protein_group\"] = mdata[\"peptide\"].var_names.map(map_df[\"Protein.Group\"]) mdata[\"peptide\"].var[\"peptide_type\"] = mdata[\"peptide\"].var_names.map(map_df[\"Proteotypic\"]) mdata[\"peptide\"].var[\"peptide_type\"] = [\"unique\" if x else \"shared\" for x in mdata[\"peptide\"].var[\"peptide_type\"]] <pre>WARNING - Decoy data not found. Skipping decoy aggregation.\n</pre> <pre>Building new peptide quantification data.\n</pre> In\u00a0[20]: Copied! <pre>mdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"total_intensity\", calculate_q=False)\n</pre> mdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"total_intensity\", calculate_q=False) <pre>INFO - Ranking features by 'total_intensity' to select top 3 features.\nWARNING - Decoy data not found. Skipping decoy aggregation.\n</pre> In\u00a0[21]: Copied! <pre>mdata\n</pre> mdata Out[21]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 6656\n  uns:\t'_cmd'\n  3 modalities\n    psm:\t6 x 4946\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'charge', 'peptide_length', 'PEP', 'q_value', 'pg_q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t6 x 959\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'protein_group', 'peptide_type'\n      uns:\t'level'\n    protein:\t6 x 751\n      var:\t'count_psm', 'count_stripped_peptide', 'PEP'\n      uns:\t'level'</pre>"},{"location":"tutorials/dia-lfq/#dia-label-free","title":"DIA - Label-Free\u00b6","text":"<p>This tutorial demonstrates how to analyze label-free quantification (LFQ) data from data-independent acquisition (DIA) using the <code>msmu</code> package.</p>"},{"location":"tutorials/dia-lfq/#data-preparation","title":"Data Preparation\u00b6","text":"<p>Original dataset is from PXD012988 (Uszkoreit et al., 2022) and search was performed with <code>DIA-NN</code> v2.1.0.</p> <p>For demonstration purposes, the example dataset was reduced to six samples and a total of 1,000 peptides.</p>"},{"location":"tutorials/dia-lfq/#load-required-packages","title":"Load Required Packages\u00b6","text":"<p>If you haven't installed the <code>msmu</code> package yet, please follow the installation guide.</p>"},{"location":"tutorials/dia-lfq/#read-data","title":"Read Data\u00b6","text":"<p>You can read data from various proteomics software outputs. Below are examples for <code>DIA-NN</code>, <code>MaxQuant</code>, and <code>FragPipe</code> formats.</p> <p>For this tutorial, we will use <code>DIA-NN</code> output as an example.</p> <p><code>read_diann()</code> function reads <code>DIA-NN</code> output file (<code>report.parquet</code> or <code>report.tsv</code>) and creates modalities at MuData object.</p>"},{"location":"tutorials/dia-lfq/#adding-metadata","title":"Adding Metadata\u00b6","text":"<p>Optionally, you can add metadata for samples to the <code>mdata.obs</code> dataframe. Make sure that the index of the metadata dataframe matches the sample names in <code>mdata.obs</code>.</p>"},{"location":"tutorials/dia-lfq/#saving-raw-mudata-object","title":"Saving Raw MuData Object\u00b6","text":"<p>After reading the search output, saving the MuData object as an <code>h5mu</code> file is recommended for future use.</p>"},{"location":"tutorials/dia-lfq/#handling-psm-level","title":"Handling PSM level\u00b6","text":"<p>If you are using <code>DIA-NN</code> version under 2.0, or the data doesn't contain decoy features, please jump to this section.</p>"},{"location":"tutorials/dia-lfq/#filtering-psm","title":"Filtering - PSM\u00b6","text":"<p>You can filter the data based on the column values, such as q-value. You can also filter the data based on string containment, which can be useful for removing contaminants or decoys.</p> <p>Filtering is split into two steps: first, you mark a filter condition using <code>mm.pp.add_filter()</code>, and then you apply the filter using <code>mm.pp.apply_filter()</code>.</p> <p>Here, we keep protein groups with q-value &lt; 0.01 and remove contaminants (protein IDs containing \"contam_\").</p>"},{"location":"tutorials/dia-lfq/#normalization","title":"Normalization\u00b6","text":"<p>Here, we log2 transform and normalize the data at the PSM level.</p> <p>Median centering normalization is applied using <code>mm.pp.normalize()</code> function.</p>"},{"location":"tutorials/dia-lfq/#handling-peptide-level","title":"Handling peptide level\u00b6","text":""},{"location":"tutorials/dia-lfq/#summarization-peptide","title":"Summarization - peptide\u00b6","text":"<p>You can summarize psm-level data to peptide-level data using the <code>mm.pp.to_peptide()</code> function.</p>"},{"location":"tutorials/dia-lfq/#filtering-peptide","title":"Filtering - peptide\u00b6","text":""},{"location":"tutorials/dia-lfq/#protein-inference","title":"Protein inference\u00b6","text":"<p>You can infer protein-level data from peptide-level data using the <code>mm.pp.infer_protein()</code> function.</p>"},{"location":"tutorials/dia-lfq/#handling-protein-level","title":"Handling protein level\u00b6","text":""},{"location":"tutorials/dia-lfq/#summarization-protein","title":"Summarization - protein\u00b6","text":"<p>You can summarize peptide-level data to protein-level data using the <code>mm.pp.to_protein()</code> function.</p> <p>As default, top 3 peptides within protein group can be used for protein group quantification aggregation. If top_n is None, all peptides will be used.</p>"},{"location":"tutorials/dia-lfq/#filtering-protein","title":"Filtering - protein\u00b6","text":""},{"location":"tutorials/dia-lfq/#visualization","title":"Visualization\u00b6","text":""},{"location":"tutorials/dia-lfq/#id-plot","title":"ID plot\u00b6","text":""},{"location":"tutorials/dia-lfq/#intensity-distribution-plot","title":"Intensity distribution plot\u00b6","text":""},{"location":"tutorials/dia-lfq/#saving-processed-mudata-object","title":"Saving Processed MuData Object\u00b6","text":"<p>You can save MuData object into an <code>h5mu</code> file. This allows you to easily reload the processed data in future sessions without repeating the entire analysis pipeline.</p>"},{"location":"tutorials/dia-lfq/#for-dia-nn-without-decoy","title":"For DIA-NN without decoy\u00b6","text":"<p><code>DIA-NN</code> versions earlier than 2.0 do not include decoy features in the final report.tsv.</p> <p>Also, even in <code>DIA-NN</code> version higher than 2.0, if the search settings in <code>DIA-NN</code> does not contain <code>--report-decoys</code>, the final will still lack decoy features.</p> <p>As a result, step-wise q-value estimation cannot be performed and <code>mm.pp.infer_protein()</code> cannot be applied to <code>DIA-NN</code> version under 2.0.</p> <p>Therefore, the protein groups reported directly by <code>DIA-NN</code> should be used without re-inferring them in msmu.</p>"},{"location":"tutorials/dia-lfq/#filtering-without-decoy","title":"Filtering - without decoy\u00b6","text":"<p>For protein group\u2013level q-values, use <code>Lib.PG.Q.Value</code> (when MBR is enabled) or <code>Global.PG.Q.Value</code> (when MBR is disabled) from the <code>DIA-NN</code> search results.</p>"},{"location":"tutorials/dia-lfq/#normalization-without-decoy","title":"Normalization - without decoy\u00b6","text":"<p>Once filtering is done, you can process and summarize the data to peptide and protein levels as shown below.</p>"},{"location":"tutorials/dia-lfq/#summarization-without-decoy","title":"Summarization - without decoy\u00b6","text":"<p>Manually add protein group and peptide-type information from the <code>DIA-NN</code> search results into the peptide var:</p> <ul> <li><code>protein_group</code> from <code>DIA-NN</code>'s <code>Protein.Group</code> (string value representing the protein group IDs associated with the peptide)</li> <li><code>peptide_type</code> from <code>DIA-NN</code>'s <code>Proteotypic</code> (boolean value indicating whether the peptide is unique to a single protein group or shared among multiple protein groups).</li> </ul> <p>No peptide filtering is performed at this stage.</p>"},{"location":"tutorials/dia-lfq/#citation","title":"Citation\u00b6","text":"<p>Uszkoreit, J., Barkovits, K., Pacharra, S., Pfeiffer, K., Steinbach, S., Marcus, K., &amp; Eisenacher, M. (2022). Dataset containing physiological amounts of spike-in proteins into murine C2C12 background as a ground truth quantitative LC-MS/MS reference. Data in Brief, 43, 108435.</p> <p>Demichev, V., Messner, C. B., Vernardis, S. I., Lilley, K. S., &amp; Ralser, M. (2020). DIA-NN: neural networks and interference correction enable deep proteome coverage in high throughput. Nature methods, 17(1), 41-44.</p>"},{"location":"tutorials/flashlfq/","title":"DDA-LFQ w. FlashLFQ","text":"In\u00a0[2]: Copied! <pre>import msmu as mm\nimport pandas as pd\n</pre> import msmu as mm import pandas as pd In\u00a0[3]: Copied! <pre>base_dir = \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/sage_lfq\"\nsage_idents = f\"{base_dir}/sage/results.sage.tsv\"\nmeta = f\"{base_dir}/meta.csv\"\n\nmdata = mm.read_sage(identification_file=sage_idents, label=\"label_free\")\n\nmeta_df = pd.read_csv(\"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/sage_lfq/meta.csv\")\nmeta_df = meta_df.set_index(\"sample_id\")\n\nmdata.obs = mdata.obs.join(meta_df)\nmdata.push_obs()\nmdata.obs\n\nmdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"psm\")\n\nmdata\n</pre> base_dir = \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/sage_lfq\" sage_idents = f\"{base_dir}/sage/results.sage.tsv\" meta = f\"{base_dir}/meta.csv\"  mdata = mm.read_sage(identification_file=sage_idents, label=\"label_free\")  meta_df = pd.read_csv(\"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/sage_lfq/meta.csv\") meta_df = meta_df.set_index(\"sample_id\")  mdata.obs = mdata.obs.join(meta_df) mdata.push_obs() mdata.obs  mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"psm\")  mdata <pre>INFO - Identification file loaded: (5000, 40)\nINFO - Decoy entries separated: (345, 15)\n</pre> Out[3]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 4336\n  obs:\t'set', 'sample_name', 'condition', 'replicate'\n  uns:\t'_cmd'\n  1 modality\n    psm:\t6 x 4336\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value', 'rt', 'calcmass'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'</pre> In\u00a0[4]: Copied! <pre>mm.io.write_flashlfq_input(mdata, \"flashlfq_input.tsv\")\n</pre> mm.io.write_flashlfq_input(mdata, \"flashlfq_input.tsv\") In\u00a0[\u00a0]: Copied! <pre># bash\n\n# dotnet CMD.dll --idt \"flashlfq_input.tsv\" --rep \"/path/to/spectra/directory/\" --ppm 5 --chg\n\n# or using Docker\n\n# docker run --rm -v /path/to/local/directory:/data smithchemwisc/flashlfq:1.0.3 \\\n#     --idt \"/data/flashlfq_input.tsv\" \\\n#     --rep \"/data/spectra/\" \\\n#     --ppm 5 \\\n#     --chg\n</pre> # bash  # dotnet CMD.dll --idt \"flashlfq_input.tsv\" --rep \"/path/to/spectra/directory/\" --ppm 5 --chg  # or using Docker  # docker run --rm -v /path/to/local/directory:/data smithchemwisc/flashlfq:1.0.3 \\ #     --idt \"/data/flashlfq_input.tsv\" \\ #     --rep \"/data/spectra/\" \\ #     --ppm 5 \\ #     --chg In\u00a0[5]: Copied! <pre>flashlfq_dir = f\"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/flashlfq\"\nflashlfq_peptides = f\"{flashlfq_dir}/QuantifiedPeptides.tsv\"\n\nmdata = mm.pp.to_peptide(mdata)\n\nmdata = mm.utils.add_quant(mdata, quant_data=flashlfq_peptides, quant_tool=\"flashlfq\")\n\nmdata = mm.pp.log2_transform(mdata, modality=\"peptide\")\n\nmdata\n</pre> flashlfq_dir = f\"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/flashlfq\" flashlfq_peptides = f\"{flashlfq_dir}/QuantifiedPeptides.tsv\"  mdata = mm.pp.to_peptide(mdata)  mdata = mm.utils.add_quant(mdata, quant_data=flashlfq_peptides, quant_tool=\"flashlfq\")  mdata = mm.pp.log2_transform(mdata, modality=\"peptide\")  mdata <pre>INFO - Peptide-level identifications: 3683 (3664 at 1% FDR)\n</pre> <pre>Building new peptide quantification data.\n</pre> <pre>INFO - Added quantification modality 'peptide' using flashlfq data.\nINFO - Quantification data shape: (3547, 6)\n\n</pre> Out[5]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 7883\n  obs:\t'set', 'sample_name', 'condition', 'replicate'\n  uns:\t'_cmd'\n  2 modalities\n    psm:\t6 x 4336\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value', 'rt', 'calcmass'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t6 x 3547\n      obs:\t'set', 'sample_name', 'condition', 'replicate'\n      uns:\t'level'</pre>"},{"location":"tutorials/flashlfq/#dda-label-free-with-flashlfq","title":"DDA - Label-Free (with FlashLFQ)\u00b6","text":"<p>This tutorial involves how to analyze DDA LFQ data with combining DB search tools and FlashLFQ (for quantification).</p> <p>For DDA label-free analysis, sometimes, we need to use stand-alone Label-free quantifcation tools such as FlashLFQ to quantify with more detailed options (e.g. MBR).</p> <p>To utilize FlashLFQ, please find tutorials and installation guides in FlashLFQ documentation. This supports Docker, GUI, and conda environment.</p>"},{"location":"tutorials/flashlfq/#data-preparation","title":"Data Preparation\u00b6","text":""},{"location":"tutorials/flashlfq/#load-required-pacakages","title":"Load Required Pacakages\u00b6","text":""},{"location":"tutorials/flashlfq/#read-data-and-psm-filtering","title":"Read Data and PSM Filtering\u00b6","text":"<p>In this tutorial, we will use PXD012986 (Uszkoreit et al., 2022) dataset which is mentioned in DDA-LFQ tutorial section.</p> <p>To combine FlashLFQ quantification result with msmu, we need to read PSM result file from DB search tools and filter PSMs based on q-value or other criteria, which is because FlashLFQ assumes that the input PSMs are already filtered.</p>"},{"location":"tutorials/flashlfq/#export-flashlfq-input-file","title":"Export FlashLFQ Input File\u00b6","text":"<p>After filtering PSMs, we can export the PSMs to FlashLFQ input format using <code>mm.io.write_flashlfq_input</code> function.</p>"},{"location":"tutorials/flashlfq/#optional-in-here-run-flashlfq","title":"(optional in here) Run FlashLFQ\u00b6","text":"<p>After exporting FlashLFQ input file, we can run FlashLFQ with proper parameters (e.g. MBR) to quantify peptides.</p> <p>The command line example below shows how to run FlashLFQ in Linux. Please adjust the parameters based on your experimental design and FlashLFQ documentation.</p> <p>You can skip this step in this tutorial and directly use the provided FlashLFQ quantification result file.</p>"},{"location":"tutorials/flashlfq/#attach-flashlfq-result-to-mdata","title":"Attach FlashLFQ result to mdata\u00b6","text":"<p>Peptide quantification result from FlashLFQ can be attached to <code>mdata</code> using <code>mm.utils.add_quant</code> function with <code>quant_tool=\"flashlfq\"</code> parameter with a file named \"QuantifiedPeptides.tsv\" containing peptide level quantification values and evidences.</p>"},{"location":"tutorials/ptm/","title":"PTM Processing","text":"In\u00a0[71]: Copied! <pre>import msmu as mm\nimport pandas as pd\n</pre> import msmu as mm import pandas as pd In\u00a0[72]: Copied! <pre>base_dir = \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/sage_tmt\"\nsage_idents = f\"{base_dir}/sage/results.sage.tsv\"\nsage_quants = f\"{base_dir}/sage/tmt.tsv\"\nmeta = f\"{base_dir}/meta.csv\"\n\nptm_mdata = mm.read_sage(identification_file=sage_idents, quantification_file=sage_quants, label=\"tmt\")\n\nmeta_df = pd.read_csv(\"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/sage_tmt/meta.csv\")\nmeta_df = meta_df.set_index(\"tag\")  # set the index to match sample id in ptm_mdata.obs\n\nptm_mdata.obs = ptm_mdata.obs.join(meta_df)\nptm_mdata.push_obs()  # update all modalities with the new obs data\n\nptm_mdata = mm.pp.add_filter(ptm_mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01)\nptm_mdata = mm.pp.add_filter(ptm_mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\")\nptm_mdata = mm.pp.apply_filter(ptm_mdata, modality=\"psm\")\n\nptm_mdata = mm.pp.to_peptide(ptm_mdata)\nptm_mdata = mm.pp.log2_transform(ptm_mdata, modality=\"peptide\")\nptm_mdata = mm.pp.normalise(ptm_mdata, modality=\"peptide\", method=\"median\")\n\nptm_mdata = mm.pp.add_filter(ptm_mdata, modality=\"peptide\", column=\"q_value\", keep=\"lt\", value=0.01)\nptm_mdata = mm.pp.apply_filter(ptm_mdata, modality=\"peptide\")\n\nptm_mdata\n</pre> base_dir = \"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/sage_tmt\" sage_idents = f\"{base_dir}/sage/results.sage.tsv\" sage_quants = f\"{base_dir}/sage/tmt.tsv\" meta = f\"{base_dir}/meta.csv\"  ptm_mdata = mm.read_sage(identification_file=sage_idents, quantification_file=sage_quants, label=\"tmt\")  meta_df = pd.read_csv(\"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/sage_tmt/meta.csv\") meta_df = meta_df.set_index(\"tag\")  # set the index to match sample id in ptm_mdata.obs  ptm_mdata.obs = ptm_mdata.obs.join(meta_df) ptm_mdata.push_obs()  # update all modalities with the new obs data  ptm_mdata = mm.pp.add_filter(ptm_mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01) ptm_mdata = mm.pp.add_filter(ptm_mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\") ptm_mdata = mm.pp.apply_filter(ptm_mdata, modality=\"psm\")  ptm_mdata = mm.pp.to_peptide(ptm_mdata) ptm_mdata = mm.pp.log2_transform(ptm_mdata, modality=\"peptide\") ptm_mdata = mm.pp.normalise(ptm_mdata, modality=\"peptide\", method=\"median\")  ptm_mdata = mm.pp.add_filter(ptm_mdata, modality=\"peptide\", column=\"q_value\", keep=\"lt\", value=0.01) ptm_mdata = mm.pp.apply_filter(ptm_mdata, modality=\"peptide\")  ptm_mdata <pre>INFO - Identification file loaded: (5000, 40)\nINFO - Quantification file loaded: (5000, 9)\nINFO - Decoy entries separated: (1195, 13)\nWARNING - Purity column not found in psm modality for TMT data. Skipping purity filtering.\nINFO - Peptide-level identifications: 2204 (2151 at 1% FDR)\n</pre> <pre>Building new peptide quantification data.\n</pre> Out[72]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 4415\n  obs:\t'set', 'sample_id', 'sample_name', 'condition'\n  uns:\t'_cmd'\n  2 modalities\n    psm:\t6 x 2264\n      obs:\t'set', 'sample_id', 'sample_name', 'condition'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t6 x 2151\n      obs:\t'set', 'sample_id', 'sample_name', 'condition'\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'</pre> In\u00a0[73]: Copied! <pre>global_mdata = ptm_mdata.copy()\nglobal_mdata = mm.pp.infer_protein(global_mdata)\nglobal_mdata = mm.pp.to_protein(global_mdata)\nglobal_mdata = mm.pp.add_filter(global_mdata, modality=\"protein\", column=\"q_value\", keep=\"lt\", value=0.01)\nglobal_mdata = mm.pp.apply_filter(global_mdata, modality=\"protein\")\n</pre> global_mdata = ptm_mdata.copy() global_mdata = mm.pp.infer_protein(global_mdata) global_mdata = mm.pp.to_protein(global_mdata) global_mdata = mm.pp.add_filter(global_mdata, modality=\"protein\", column=\"q_value\", keep=\"lt\", value=0.01) global_mdata = mm.pp.apply_filter(global_mdata, modality=\"protein\") <pre>INFO - Starting protein inference\nINFO - Initial proteins: 1722\nINFO - Removed indistinguishable: 175\nINFO - Removed subsettable: 62\nINFO - Removed subsumable: 0\nINFO - Total protein groups: 1485\nINFO - Ranking features by 'total_intensity' to select top 3 features.\nINFO - Protein-level identifications :  1465 (1432 at 1% FDR)\n</pre> In\u00a0[74]: Copied! <pre>ptm_mdata = mm.pp.infer_protein(ptm_mdata, propagated_from=global_mdata)\n</pre> ptm_mdata = mm.pp.infer_protein(ptm_mdata, propagated_from=global_mdata) <pre>INFO - Starting protein inference\n</pre> In\u00a0[75]: Copied! <pre>import urllib.request\n\nfasta_url=\"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/fasta/human_fasta.fasta\"\nfasta_file = \"./human_fasta.fasta\"\n\nwith urllib.request.urlopen(fasta_url) as response:\n    with open(fasta_file, \"wb\") as f:\n        fasta_ = response.read()\n        f.write(fasta_)\n\nptm_mdata = mm.utils.attach_fasta(ptm_mdata, fasta_file=fasta_file)\n\nptm_mdata = mm.pp.to_ptm(ptm_mdata, modi_name=\"oxidation\", modification=\"[+15.9949]\")\n\nptm_mdata\n</pre> import urllib.request  fasta_url=\"https://raw.githubusercontent.com/bertis-informatics/msmu/refs/heads/main/data/fasta/human_fasta.fasta\" fasta_file = \"./human_fasta.fasta\"  with urllib.request.urlopen(fasta_url) as response:     with open(fasta_file, \"wb\") as f:         fasta_ = response.read()         f.write(fasta_)  ptm_mdata = mm.utils.attach_fasta(ptm_mdata, fasta_file=fasta_file)  ptm_mdata = mm.pp.to_ptm(ptm_mdata, modi_name=\"oxidation\", modification=\"[+15.9949]\")  ptm_mdata <pre>INFO - Extracted modified peptides: 329 / 2151\nINFO - oxidation site level identifications: 351\nINFO - Building new oxidation_site AnnData.\n</pre> Out[75]: <pre>MuData object with n_obs \u00d7 n_vars = 6 \u00d7 4766\n  obs:\t'set', 'sample_id', 'sample_name', 'condition'\n  uns:\t'_cmd', 'protein_map', 'protein_info'\n  3 modalities\n    psm:\t6 x 2264\n      obs:\t'set', 'sample_id', 'sample_name', 'condition'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t6 x 2151\n      obs:\t'set', 'sample_id', 'sample_name', 'condition'\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value', 'protein_group', 'peptide_type'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'\n    oxidation_site:\t6 x 351\n      obs:\t'set', 'sample_id', 'sample_name', 'condition'\n      var:\t'count_psm', 'peptide', 'count_peptide', 'count_stripped_peptide', 'modified_protein', 'protein_group'\n      uns:\t'level'</pre> In\u00a0[76]: Copied! <pre>ptm_mdata[\"oxidation_site\"].to_df().T\n</pre> ptm_mdata[\"oxidation_site\"].to_df().T Out[76]: 126 127 128 129 130 131 A0A3B3IRV3|M150,Q9ULC4|M150 16.280768 15.531237 15.376702 15.057094 15.299921 15.772261 O00410|M61 14.642673 14.665745 14.845570 14.437368 14.755740 15.703198 O00422|M120 14.847602 15.049636 14.597786 14.460380 14.671438 14.589479 O14497|M1273 13.214325 13.392085 13.262411 13.074445 12.827528 14.306335 O14950|M40,P19105|M39 15.821183 15.779716 15.662250 15.596942 15.563856 15.759404 ... ... ... ... ... ... ... Q9Y490|M289 17.150820 17.170126 16.605962 16.176437 15.987995 16.259189 Q9Y490|M72 14.399083 14.174609 13.842843 13.546905 13.453805 13.618298 Q9Y5B9|M468 14.913293 15.107410 15.251177 14.708296 14.658334 15.900108 Q9Y639|M379 14.101203 13.768589 13.309624 13.224675 13.218592 13.609742 Q9Y6G3|M108 10.560294 12.021548 10.495958 12.244229 10.887468 11.901794 <p>351 rows \u00d7 6 columns</p> In\u00a0[77]: Copied! <pre>ptm_mdata = mm.pp.adjust_ptm_by_protein(\n    ptm_mdata,\n    modality=\"oxidation_site\",\n    global_mdata=global_mdata,\n    method=\"ridge\",\n    rescale=True,\n)\n</pre> ptm_mdata = mm.pp.adjust_ptm_by_protein(     ptm_mdata,     modality=\"oxidation_site\",     global_mdata=global_mdata,     method=\"ridge\",     rescale=True, ) In\u00a0[78]: Copied! <pre>ptm_mdata[\"oxidation_site\"].to_df().T\n</pre> ptm_mdata[\"oxidation_site\"].to_df().T Out[78]: 126 127 128 129 130 131 A0A3B3IRV3|M150,Q9ULC4|M150 14.913651 14.170947 14.017820 13.701122 13.941738 14.409776 O00410|M61 14.003172 14.013189 14.190895 13.791744 14.112336 15.043717 O00422|M120 14.337066 14.538646 14.087810 13.950713 14.161297 14.079522 O14497|M1273 14.062327 14.237820 14.109800 13.924230 13.680461 15.140416 O14950|M40,P19105|M39 14.316405 14.275079 14.157595 14.092328 14.059105 14.254542 ... ... ... ... ... ... ... Q9Y490|M289 14.777373 14.796433 14.239445 13.815383 13.629338 13.897082 Q9Y490|M72 14.746868 14.522217 14.195656 13.903682 13.812320 13.974311 Q9Y5B9|M468 14.015269 14.218388 14.357117 13.823126 13.764951 14.976202 Q9Y639|M379 14.751465 14.420926 13.964825 13.880406 13.874360 14.263071 Q9Y6G3|M108 13.411507 14.857057 13.343002 15.075578 13.730476 14.737434 <p>334 rows \u00d7 6 columns</p>"},{"location":"tutorials/ptm/#post-translational-modification-ptm","title":"Post-Translational Modification (PTM)\u00b6","text":"<p>This tutorial shows hwo to process and analyse PTM data using msmu. We will use a mock oxidation-site dataset for demonstration.</p>"},{"location":"tutorials/ptm/#load-required-libraries","title":"Load Required Libraries\u00b6","text":""},{"location":"tutorials/ptm/#data-preparation","title":"Data Preparation\u00b6","text":"<p>In this tutorial, we will use peptide-level processed data from SAGE TMT workflow for both global protein and PTM data with code below.</p> <p>More details about Sage TMT data processing can be found in DDA - TMT tutorial section.</p>"},{"location":"tutorials/ptm/#global-protein-data-processing","title":"Global Protein Data Processing\u00b6","text":"<p>For real data analysis, global protein data should be processed with other batch experiment for global protein quantification. Here, we will use the same SAGE TMT data for demonstration purpose.</p>"},{"location":"tutorials/ptm/#ptm-data-processing","title":"PTM Data Processing\u00b6","text":""},{"location":"tutorials/ptm/#protein-inference-with-global-protein-data","title":"Protein Inference with global protein data\u00b6","text":"<p>PTM data uses the same peptide-protein mapping as global protein data, therefore we can directly use the peptide to protein mapping from global protein data processing step by using <code>mm.pp.infer_protein</code> function with <code>progagated_from</code> parameter.</p>"},{"location":"tutorials/ptm/#ptm-summarization","title":"PTM Summarization\u00b6","text":"<p>For PTM summarization, we need FASTA file that contains the protein sequences used for ptm site localization.</p> <p>Then, PTM site is summarized by <code>mm.pp.to_ptm</code> with <code>modi_name</code> for specifying modality name (e.g. \"oxidation\" -&gt; \"oxidation_site\") for PTM data and <code>modification</code> for specifying the modification string used for site localization in modified peptides.</p>"},{"location":"tutorials/ptm/#ptm-quantification-adjustment-by-global-protein-levels","title":"PTM quantification adjustment by global protein levels\u00b6","text":"<p>To adjust PTM quantification by global protein levels, we can use <code>mm.pp.adjust_ptm_by_protein</code> function. This function normalizes PTM quantification by corresponding protein levels to remove the confounding effect from protein abundance changes.</p>"},{"location":"tutorials/quick_start/","title":"QUICK START","text":"In\u00a0[\u00a0]: Copied! <pre>import msmu as mm\n</pre> import msmu as mm In\u00a0[\u00a0]: Copied! <pre>mdata = mm.read_sage(\"sage/output/dir/\", label=\"tmt\")\n\nmdata\n</pre> mdata = mm.read_sage(\"sage/output/dir/\", label=\"tmt\")  mdata In\u00a0[\u00a0]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"psm\")\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"psm\") In\u00a0[\u00a0]: Copied! <pre>mdata = mm.pp.log2_transform(mdata, modality=\"psm\")\n\nmdata[\"psm\"].to_df().T\n</pre> mdata = mm.pp.log2_transform(mdata, modality=\"psm\")  mdata[\"psm\"].to_df().T In\u00a0[\u00a0]: Copied! <pre>mdata = mm.pp.normalize(mdata, modality=\"psm\", method=\"median\", rescale=True)\n</pre> mdata = mm.pp.normalize(mdata, modality=\"psm\", method=\"median\", rescale=True) In\u00a0[\u00a0]: Copied! <pre>mdata = mm.pp.to_peptide(mdata, **summarization_args)\n</pre> mdata = mm.pp.to_peptide(mdata, **summarization_args) In\u00a0[\u00a0]: Copied! <pre>mdata = mm.pp.infer_protein(mdata)\n</pre> mdata = mm.pp.infer_protein(mdata) In\u00a0[\u00a0]: Copied! <pre>mdata = mm.pp.to_protein(mdata, **summarization_args)\n\nmm.pl.plot_bar(mdata, modality=\"protein\", )\n</pre> mdata = mm.pp.to_protein(mdata, **summarization_args)  mm.pl.plot_bar(mdata, modality=\"protein\", ) In\u00a0[\u00a0]: Copied! <pre># PCA / UMAP\nmdata = mm.tl.pca(mdata, modality=\"protein\") # mdata = mm.tl.umap(mdata, modality=\"protein\")\nmm.pl.plot_pca(mdata, modality=\"protein\")    # mm.pl.plot_umap(mdata, modality=\"protein\")\n\n# DEA\nde_res = mm.tl.run_de(mdata, modality=\"protein\", ctrl=\"control\", expr=\"expr\")\nde_res.to_df()  # show result in pandas dataframe\nde_res.plot_volcano()   # show result with volcanoplot\n</pre> # PCA / UMAP mdata = mm.tl.pca(mdata, modality=\"protein\") # mdata = mm.tl.umap(mdata, modality=\"protein\") mm.pl.plot_pca(mdata, modality=\"protein\")    # mm.pl.plot_umap(mdata, modality=\"protein\")  # DEA de_res = mm.tl.run_de(mdata, modality=\"protein\", ctrl=\"control\", expr=\"expr\") de_res.to_df()  # show result in pandas dataframe de_res.plot_volcano()   # show result with volcanoplot In\u00a0[\u00a0]: Copied! <pre>mdata.write_h5mu(\"file/name/to/save.h5mu\")\n\nmdata = mm.read_h5mu(\"file/name/mudata.h5mu)\n</pre> mdata.write_h5mu(\"file/name/to/save.h5mu\")  mdata = mm.read_h5mu(\"file/name/mudata.h5mu)"},{"location":"tutorials/quick_start/#quick-start","title":"Quick Start\u00b6","text":""},{"location":"tutorials/quick_start/#workflow","title":"Workflow\u00b6","text":"<p><code>msmu</code> processes LC-MS/MS search outputs and produces an analysis-ready protein matrix. Each processing step is modular, and normalization / filtering / aggregation can be applied optionally at any level depending on your analysis design</p> <pre><code>1. Load DB search result (read functions)\n2. (optional) PSM-level filtering\n3. Log2 Transformation\n4. (optional) PSM normalization\n5. Summarize to peptides\n6. Protein inference\n7. Summarize to protein groups\n8. Analyze\n9. Save</code></pre> <p>Functions can be called from submodules:</p> <ul> <li><code>pp</code>: preprocessing (filter, normalization, summarization, etc,)</li> <li><code>tl</code>: tools (PCA, UMAP, fasta annotation, DE analysis, etc,)</li> <li><code>pl</code>: plotting (bar plot for ID, charges, and histograms, etc,)</li> </ul> <p></p> <p>Basic usages of <code>msmu</code> can be found down below:</p>"},{"location":"tutorials/quick_start/#0-import-msmu","title":"0. Import msmu\u00b6","text":""},{"location":"tutorials/quick_start/#1-load-db-search-result","title":"1. Load DB search result\u00b6","text":"<ul> <li>Ingest outputs from DB search tools in to a unified MuData object.</li> </ul>"},{"location":"tutorials/quick_start/#2-optional-psm-level-filtering","title":"2. (optional) PSM-level filtering\u00b6","text":"<ul> <li>Remove low-confidence PSMs / precursors (q-value, etc.).</li> </ul>"},{"location":"tutorials/quick_start/#3-log2-transformation","title":"3. Log2 Transformation\u00b6","text":"<ul> <li>Apply log2 transformation for quantification matrix</li> <li>Further steps will be proceed with assumption of log2 transformed values.</li> </ul>"},{"location":"tutorials/quick_start/#4-optional-psm-normalization","title":"4. (optional) PSM normalization\u00b6","text":"<ul> <li>Apply observation (sample) wise normalization</li> </ul>"},{"location":"tutorials/quick_start/#5-aggregate-to-peptides","title":"5. Aggregate to peptides\u00b6","text":"<ul> <li>Summarize PSMs (or precursors) to peptide level.</li> <li>(optional) filtering or normalization can be also applied at peptide level.</li> <li>Peptide-level q-values will be calculated based on their PEP.</li> </ul>"},{"location":"tutorials/quick_start/#6-protein-inference","title":"6. Protein inference\u00b6","text":"<ul> <li>Map peptides to protein groups</li> </ul>"},{"location":"tutorials/quick_start/#7-aggregate-to-protein-groups","title":"7. Aggregate to protein groups\u00b6","text":"<ul> <li>Generate protein group level matrix.</li> <li>Only unique peptides will be used for protein summarization.</li> <li>Protein group-level q-values will be calculated based on their PEP.</li> </ul>"},{"location":"tutorials/quick_start/#8-analyse","title":"8. Analyse\u00b6","text":"<ul> <li>Perform differential expression, PCA/UMAP, QC, missingness analysis, and other statistical workflows.</li> </ul>"},{"location":"tutorials/quick_start/#9-save-load-h5mu","title":"9. Save &amp; Load h5mu\u00b6","text":""},{"location":"tutorials/2024_Fulcher/","title":"2024 Fulcher et al. Tutorial","text":"<p>This tutorial demonstrates the integrated analysis of single-cell RNA-seq and proteomics data using the <code>msmu</code> package, based on the original dataset described in Fulcher et al. (2024).</p> <p>Fulcher, J. M., Markillie, L. M., Mitchell, H. D., Williams, S. M., Engbrecht, K. M., Degnan, D. J., ... &amp; Zhu, Y. (2024). Parallel measurement of transcriptomes and proteomes from same single cells using nanodroplet splitting. Nature Communications, 15(1), 10614.</p>"},{"location":"tutorials/2024_Fulcher/#tutorials","title":"Tutorials","text":"<ul> <li>01 Process scRNAseq Data</li> <li>02 Process Proteomics Data</li> <li>03 Handle Multi-omics Data</li> </ul>"},{"location":"tutorials/2024_Fulcher/#environment_setup","title":"Environment Setup","text":"<p><code>.python-version</code>: <code>3.11</code></p>"},{"location":"tutorials/2024_Fulcher/#dependencies_pyprojecttoml","title":"Dependencies (<code>pyproject.toml</code>)","text":"<pre><code>[project]\nname = \"2024-fulcher\"\nrequires-python = \"&gt;=3.11\"\ndependencies = [\n    \"anndata&gt;=0.12.7\",\n    \"fastprogress==1.0.3\",\n    \"ipykernel&gt;=7.1.0\",\n    \"ipywidgets&gt;=8.1.8\",\n    \"mofapy2&gt;=0.7.3\",\n    \"mofax&gt;=0.3.7\",\n    \"msmu&gt;=0.2.6\",\n    \"mudata&gt;=0.3.2\",\n    \"muon&gt;=0.1.7\",\n    \"pimms-learn\",\n    \"requests&gt;=2.32.5\",\n    \"scanpy&gt;=1.11.5\",\n]\n\n[tool.uv.sources]\npimms-learn = { git = \"https://github.com/RasmussenLab/pimms.git\", rev = \"327a431\" }\n</code></pre>"},{"location":"tutorials/2024_Fulcher/#package_versions_pip_list","title":"Package Versions (<code>pip list</code>)","text":"<pre><code>Package                 Version\n----------------------- ---------------------\nanndata                 0.12.7\nannotated-types         0.7.0\nantlr4-python3-runtime  4.9.3\nappnope                 0.1.4\narray-api-compat        1.13.0\nasttokens               3.0.1\nbeartype                0.22.9\nbiopython               1.86\nblis                    1.3.3\ncatalogue               2.0.10\ncategory-encoders       2.9.0\ncertifi                 2026.1.4\ncharset-normalizer      3.4.4\nchoreographer           1.2.1\nclick                   8.3.1\ncloudpathlib            0.23.0\ncloudpickle             3.1.2\ncomm                    0.2.3\nconfection              0.1.5\ncontourpy               1.3.3\ncramjam                 2.11.0\ncycler                  0.12.1\ncymem                   2.0.13\ndebugpy                 1.8.19\ndecorator               5.2.1\ndonfig                  0.8.1.post1\nexecuting               2.2.1\nfastai                  2.8.6\nfastcluster             1.3.0\nfastcore                1.12.4\nfastdownload            0.0.7\nfastparquet             2025.12.0\nfastprogress            1.0.3\nfasttransform           0.0.2\nfilelock                3.20.3\nfonttools               4.61.1\nfsspec                  2026.1.0\ngoogle-crc32c           1.8.0\nh5py                    3.15.1\nidna                    3.11\niniconfig               2.3.0\ninmoose                 0.9.1\nipykernel               7.1.0\nipython                 9.9.0\nipython-pygments-lexers 1.1.1\nipywidgets              8.1.8\njedi                    0.19.2\njinja2                  3.1.6\njoblib                  1.5.3\njupyter-client          8.8.0\njupyter-core            5.9.1\njupyterlab-widgets      3.0.16\nkaleido                 1.2.0\nkiwisolver              1.4.9\nlegacy-api-wrap         1.5\nllvmlite                0.46.0\nlogistro                2.0.1\nmarkdown-it-py          4.0.0\nmarkupsafe              3.0.3\nmatplotlib              3.10.8\nmatplotlib-inline       0.2.1\nmdurl                   0.1.2\nmofapy2                 0.7.3\nmofax                   0.3.7\nmpmath                  1.3.0\nmrmr-selection          0.2.8\nmsmu                    0.2.6\nmudata                  0.3.2\nmuon                    0.1.7\nmurmurhash              1.0.15\nnarwhals                2.15.0\nnatsort                 8.4.0\nnest-asyncio            1.6.0\nnetworkx                3.6.1\nnjab                    0.1.1\nnumba                   0.63.1\nnumcodecs               0.16.5\nnumpy                   2.3.5\nomegaconf               2.3.0\norjson                  3.11.5\npackaging               26.0\npandas                  2.3.3\npandas-flavor           0.8.1\nparso                   0.8.5\npatsy                   1.0.2\npexpect                 4.9.0\npillow                  12.1.0\npimms-learn             0.5.1.dev8+g327a431a0\npingouin                0.5.5\npip                     25.3\nplatformdirs            4.5.1\nplotly                  6.5.2\npluggy                  1.6.0\nplum-dispatch           2.6.1\npolars                  1.37.1\npolars-runtime-32       1.37.1\npreshed                 3.0.12\nprompt-toolkit          3.0.52\nprotobuf                6.33.4\npsutil                  7.2.1\nptyprocess              0.7.0\npure-eval               0.2.3\npydantic                2.12.5\npydantic-core           2.41.5\npygments                2.19.2\npynndescent             0.6.0\npyopenms                3.5.0\npyparsing               3.3.2\npytest                  9.0.2\npytest-timeout          2.4.0\npython-dateutil         2.9.0.post0\npytz                    2025.2\npyyaml                  6.0.3\npyzmq                   27.1.0\nrequests                2.32.5\nrich                    14.2.0\nscanpy                  1.11.5\nscikit-learn            1.8.0\nscipy                   1.17.0\nseaborn                 0.13.2\nsession-info2           0.3\nsetuptools              80.10.1\nsimplejson              3.20.2\nsix                     1.17.0\nsmart-open              7.5.0\nspacy                   3.8.11\nspacy-legacy            3.0.12\nspacy-loggers           1.0.5\nsrsly                   2.5.2\nstack-data              0.6.3\nstatsmodels             0.14.6\nsympy                   1.14.0\ntabulate                0.9.0\nthinc                   8.3.10\nthreadpoolctl           3.6.0\ntorch                   2.9.1\ntorchvision             0.24.1\ntornado                 6.5.4\ntqdm                    4.67.1\ntraitlets               5.14.3\ntyper-slim              0.21.1\ntyping-extensions       4.15.0\ntyping-inspection       0.4.2\ntzdata                  2025.3\numap-learn              0.5.11\nurllib3                 2.6.3\nwasabi                  1.1.3\nwcwidth                 0.3.1\nweasel                  0.4.3\nwidgetsnbextension      4.0.15\nwrapt                   2.0.1\nxarray                  2025.12.0\nzarr                    3.1.5\n</code></pre>"},{"location":"tutorials/2024_Fulcher/01_process_rna_data/","title":"01 Process scRNAseq Data","text":"In\u00a0[1]: Copied! <pre>from pathlib import Path\nimport pandas as pd\nimport requests\nimport scanpy as sc\nimport tarfile\n</pre> from pathlib import Path import pandas as pd import requests import scanpy as sc import tarfile In\u00a0[2]: Copied! <pre>url = \"https://github.com/bertis-informatics/msmu/releases/download/0.2.2/GSE201575.tar.gz\"\nmeta = \"https://github.com/bertis-informatics/msmu/releases/download/0.2.2/meta.csv\"\nbase_dir = Path(url).name.split(\".\")[0]\n\nr = requests.get(url)\nr.raise_for_status()\n\nwith open(Path(url).name, \"wb\") as f:\n    f.write(r.content)\n\nwith tarfile.open(Path(url).name, \"r:gz\") as tar:\n    members = [m for m in tar.getmembers() if not Path(m.name).name.startswith(\"._\")]\n    tar.extractall(members=members)\n</pre> url = \"https://github.com/bertis-informatics/msmu/releases/download/0.2.2/GSE201575.tar.gz\" meta = \"https://github.com/bertis-informatics/msmu/releases/download/0.2.2/meta.csv\" base_dir = Path(url).name.split(\".\")[0]  r = requests.get(url) r.raise_for_status()  with open(Path(url).name, \"wb\") as f:     f.write(r.content)  with tarfile.open(Path(url).name, \"r:gz\") as tar:     members = [m for m in tar.getmembers() if not Path(m.name).name.startswith(\"._\")]     tar.extractall(members=members) <pre>/var/folders/pp/7ts5fh4x5hl81rnn895l34ph0000gn/T/ipykernel_17737/3812210948.py:13: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n  tar.extractall(members=members)\n</pre> In\u00a0[3]: Copied! <pre>path_list = Path(base_dir).glob(\"*.txt.gz\")\npath_list = sorted(path_list)\nadata_list = []\n\nfor p in path_list:\n    a = sc.read_text(p, delimiter=\"\\t\", first_column_names=True).T\n    a.obs.index = [p.stem.split(\".\")[0].split(\"_\")[1]]\n    a.obs[\"filename\"] = [p.stem]\n    adata_list.append(a)\n\nadata = sc.concat(adata_list)\n</pre> path_list = Path(base_dir).glob(\"*.txt.gz\") path_list = sorted(path_list) adata_list = []  for p in path_list:     a = sc.read_text(p, delimiter=\"\\t\", first_column_names=True).T     a.obs.index = [p.stem.split(\".\")[0].split(\"_\")[1]]     a.obs[\"filename\"] = [p.stem]     adata_list.append(a)  adata = sc.concat(adata_list) In\u00a0[4]: Copied! <pre>meta_df = pd.read_csv(meta)\nmeta_df = meta_df.dropna()\nmeta_df.index = meta_df[\"sample_rna\"].values\n\nadata.obs = adata.obs.merge(meta_df, left_index=True, right_index=True, how=\"left\")\n\nadata = adata[adata.obs.dropna().index.to_list()].copy()\nadata.obs.index = adata.obs[\"sample_id\"].values\n\nadata\n</pre> meta_df = pd.read_csv(meta) meta_df = meta_df.dropna() meta_df.index = meta_df[\"sample_rna\"].values  adata.obs = adata.obs.merge(meta_df, left_index=True, right_index=True, how=\"left\")  adata = adata[adata.obs.dropna().index.to_list()].copy() adata.obs.index = adata.obs[\"sample_id\"].values  adata Out[4]: <pre>AnnData object with n_obs \u00d7 n_vars = 70 \u00d7 40207\n    obs: 'filename', 'set', 'sample_id', 'sample', 'cell', 'condition', 'sample_rna'</pre> In\u00a0[5]: Copied! <pre>adata.layers[\"counts\"] = adata.X.copy()\n\nsc.pp.filter_genes(adata, min_cells=3, inplace=True)\nsc.pp.filter_cells(adata, min_genes=200, inplace=True)\n\nsc.pp.normalize_total(adata)\nsc.pp.log1p(adata)\n\nadata\n</pre> adata.layers[\"counts\"] = adata.X.copy()  sc.pp.filter_genes(adata, min_cells=3, inplace=True) sc.pp.filter_cells(adata, min_genes=200, inplace=True)  sc.pp.normalize_total(adata) sc.pp.log1p(adata)  adata Out[5]: <pre>AnnData object with n_obs \u00d7 n_vars = 70 \u00d7 13451\n    obs: 'filename', 'set', 'sample_id', 'sample', 'cell', 'condition', 'sample_rna', 'n_genes'\n    var: 'n_cells'\n    uns: 'log1p'\n    layers: 'counts'</pre> In\u00a0[6]: Copied! <pre>adata.write_h5ad(\"GSE201575.h5ad\")\n</pre> adata.write_h5ad(\"GSE201575.h5ad\")"},{"location":"tutorials/2024_Fulcher/01_process_rna_data/#process-scrna-seq-data-with-msmu","title":"Process scRNA-seq Data with msmu\u00b6","text":""},{"location":"tutorials/2024_Fulcher/01_process_rna_data/#read-count-matrix","title":"Read count matrix\u00b6","text":""},{"location":"tutorials/2024_Fulcher/01_process_rna_data/#add-metadata-and-filter-samples-on-use","title":"Add metadata and filter samples on use\u00b6","text":""},{"location":"tutorials/2024_Fulcher/01_process_rna_data/#filtering-and-normalization","title":"Filtering and normalization\u00b6","text":""},{"location":"tutorials/2024_Fulcher/01_process_rna_data/#save-anndata-object","title":"Save AnnData object\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/","title":"02 Process Proteomics Data","text":"In\u00a0[1]: Copied! <pre>import msmu as mm\nfrom pathlib import Path\nimport pandas as pd\nimport requests\nimport tarfile\n</pre> import msmu as mm from pathlib import Path import pandas as pd import requests import tarfile <pre>Determination of memory status is not supported on this \n platform, measuring for memoryleaks will never fail\n</pre> In\u00a0[2]: Copied! <pre>url = \"https://github.com/bertis-informatics/msmu/releases/download/0.2.2/MSV000089280.tar.gz\"\nmeta = \"https://github.com/bertis-informatics/msmu/releases/download/0.2.2/meta.csv\"\nbase_dir = Path(url).name.split(\".\")[0]\nsage_idents = f\"{base_dir}/results.sage.tsv\"\nsage_quants = f\"{base_dir}/lfq.tsv\"\n\nr = requests.get(url)\nr.raise_for_status()\n\nwith open(Path(url).name, \"wb\") as f:\n    f.write(r.content)\n\nwith tarfile.open(Path(url).name, \"r:gz\") as tar:\n    members = [m for m in tar.getmembers() if not Path(m.name).name.startswith(\"._\")]\n    tar.extractall(members=members)\n</pre> url = \"https://github.com/bertis-informatics/msmu/releases/download/0.2.2/MSV000089280.tar.gz\" meta = \"https://github.com/bertis-informatics/msmu/releases/download/0.2.2/meta.csv\" base_dir = Path(url).name.split(\".\")[0] sage_idents = f\"{base_dir}/results.sage.tsv\" sage_quants = f\"{base_dir}/lfq.tsv\"  r = requests.get(url) r.raise_for_status()  with open(Path(url).name, \"wb\") as f:     f.write(r.content)  with tarfile.open(Path(url).name, \"r:gz\") as tar:     members = [m for m in tar.getmembers() if not Path(m.name).name.startswith(\"._\")]     tar.extractall(members=members) <pre>/var/folders/pp/7ts5fh4x5hl81rnn895l34ph0000gn/T/ipykernel_17793/2858270411.py:15: DeprecationWarning: Python 3.14 will, by default, filter extracted tar archives and reject files or modify their metadata. Use the filter argument to control this behavior.\n  tar.extractall(members=members)\n</pre> In\u00a0[3]: Copied! <pre>mdata = mm.read_sage(identification_file=sage_idents, quantification_file=sage_quants, label=\"label_free\")\n</pre> mdata = mm.read_sage(identification_file=sage_idents, quantification_file=sage_quants, label=\"label_free\") <pre>INFO - Identification file loaded: (722655, 40)\nINFO - Quantification file loaded: (19530, 112)\nINFO - Decoy entries separated: (217399, 15)\n</pre> In\u00a0[4]: Copied! <pre>meta_df = pd.read_csv(meta)\nmeta_df = meta_df.set_index(\"sample_id\")  # set the index to match sample id in mdata.obs\n\nmdata.obs = mdata.obs.join(meta_df)\nmdata.push_obs()  # update all modalities with the new obs data\n</pre> meta_df = pd.read_csv(meta) meta_df = meta_df.set_index(\"sample_id\")  # set the index to match sample id in mdata.obs  mdata.obs = mdata.obs.join(meta_df) mdata.push_obs()  # update all modalities with the new obs data In\u00a0[5]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\")\nmdata = mm.pp.apply_filter(mdata, modality=\"psm\")\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"proteins\", keep=\"not_contains\", value=\"contam_\") mdata = mm.pp.apply_filter(mdata, modality=\"psm\")  mdata Out[5]: <pre>MuData object with n_obs \u00d7 n_vars = 106 \u00d7 267797\n  obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n  uns:\t'_cmd'\n  2 modalities\n    psm:\t106 x 248267\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value', 'rt', 'calcmass'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t106 x 19530\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      uns:\t'level'</pre> In\u00a0[6]: Copied! <pre>mdata = mm.pp.to_peptide(mdata)\nmdata\n</pre> mdata = mm.pp.to_peptide(mdata) mdata <pre>INFO - Peptide-level identifications: 25260 (19769 at 1% FDR)\n</pre> <pre>Using existing peptide quantification data.\n</pre> Out[6]: <pre>MuData object with n_obs \u00d7 n_vars = 106 \u00d7 248267\n  obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n  uns:\t'_cmd'\n  2 modalities\n    psm:\t106 x 248267\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value', 'rt', 'calcmass'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t106 x 25260\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value'\n      uns:\t'level', 'decoy'</pre> In\u00a0[7]: Copied! <pre>mdata[\"psm\"].var[\"cell\"] = mdata[\"psm\"].var[\"filename\"].map(mdata.obs[\"cell\"])\nmdata[\"psm\"].uns[\"decoy\"][\"cell\"] = mdata[\"psm\"].uns[\"decoy\"][\"filename\"].map(mdata.obs[\"cell\"])\n\nmdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"cell\", keep=\"contains\", value=\"C10|SVEC\")\nmdata = mm.pp.apply_filter(mdata, modality=\"psm\")\n\nmdata = mdata[mdata.obs[\"cell\"].isin([\"C10\", \"SVEC\"])].copy()\nmdata\n</pre> mdata[\"psm\"].var[\"cell\"] = mdata[\"psm\"].var[\"filename\"].map(mdata.obs[\"cell\"]) mdata[\"psm\"].uns[\"decoy\"][\"cell\"] = mdata[\"psm\"].uns[\"decoy\"][\"filename\"].map(mdata.obs[\"cell\"])  mdata = mm.pp.add_filter(mdata, modality=\"psm\", column=\"cell\", keep=\"contains\", value=\"C10|SVEC\") mdata = mm.pp.apply_filter(mdata, modality=\"psm\")  mdata = mdata[mdata.obs[\"cell\"].isin([\"C10\", \"SVEC\"])].copy() mdata Out[7]: <pre>MuData object with n_obs \u00d7 n_vars = 70 \u00d7 99285\n  obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n  uns:\t'_cmd'\n  2 modalities\n    psm:\t70 x 74025\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value', 'rt', 'calcmass', 'cell'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t70 x 25260\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value'\n      uns:\t'level', 'decoy'</pre> In\u00a0[8]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"peptide\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"peptide\")\nmdata.mod[\"peptide\"] = mdata[\"peptide\"][:, mdata[\"peptide\"].to_df().dropna(axis=1, how=\"all\").columns]\nmdata.update()\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"peptide\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"peptide\") mdata.mod[\"peptide\"] = mdata[\"peptide\"][:, mdata[\"peptide\"].to_df().dropna(axis=1, how=\"all\").columns] mdata.update()  mdata Out[8]: <pre>MuData object with n_obs \u00d7 n_vars = 70 \u00d7 92871\n  obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n  uns:\t'_cmd'\n  2 modalities\n    psm:\t70 x 74025\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value', 'rt', 'calcmass', 'cell'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n    peptide:\t70 x 18846\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'</pre> In\u00a0[\u00a0]: Copied! <pre>mdata[\"psm\"].layers[\"raw\"] = mdata[\"psm\"].X.copy()\n\nmdata = mm.pp.log2_transform(mdata, modality=\"peptide\")\nmdata = mm.pp.normalize(mdata, modality=\"peptide\", method=\"median\")\n</pre> mdata[\"psm\"].layers[\"raw\"] = mdata[\"psm\"].X.copy()  mdata = mm.pp.log2_transform(mdata, modality=\"peptide\") mdata = mm.pp.normalize(mdata, modality=\"peptide\", method=\"median\") <pre>/Users/jl/Scripts/msmu/msmu/_preprocessing/_normalise.py:29: ImplicitModificationWarning: Modifying `X` on a view results in data being overridden\n  mdata[modality].X = log2_arr\n/Users/jl/Scripts/msmu/msmu/_preprocessing/_normalise.py:123: ImplicitModificationWarning: Modifying `X` on a view results in data being overridden\n  mdata.mod[modality].X = normalised_arr\n</pre> In\u00a0[10]: Copied! <pre>mdata = mm.pp.infer_protein(mdata)\n</pre> mdata = mm.pp.infer_protein(mdata) <pre>INFO - Starting protein inference\nINFO - Initial proteins: 4268\nINFO - Removed indistinguishable: 197\nINFO - Removed subsettable: 263\nINFO - Removed subsumable: 19\nINFO - Total protein groups: 3789\n</pre> In\u00a0[11]: Copied! <pre>mdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"total_intensity\")\n</pre> mdata = mm.pp.to_protein(mdata, top_n=3, rank_method=\"total_intensity\") <pre>INFO - Ranking features by 'total_intensity' to select top 3 features.\nINFO - Protein-level identifications :  3595 (3054 at 1% FDR)\n</pre> In\u00a0[12]: Copied! <pre>mdata = mm.pp.add_filter(mdata, modality=\"protein\", column=\"q_value\", keep=\"lt\", value=0.01)\nmdata = mm.pp.apply_filter(mdata, modality=\"protein\")\nmdata.mod[\"protein\"] = mdata[\"protein\"][:, mdata[\"protein\"].to_df().dropna(axis=1, how=\"all\").columns]\nmdata.update()\n\nmdata\n</pre> mdata = mm.pp.add_filter(mdata, modality=\"protein\", column=\"q_value\", keep=\"lt\", value=0.01) mdata = mm.pp.apply_filter(mdata, modality=\"protein\") mdata.mod[\"protein\"] = mdata[\"protein\"][:, mdata[\"protein\"].to_df().dropna(axis=1, how=\"all\").columns] mdata.update()  mdata Out[12]: <pre>MuData object with n_obs \u00d7 n_vars = 70 \u00d7 95925\n  obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n  uns:\t'_cmd'\n  3 modalities\n    psm:\t70 x 74025\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value', 'rt', 'calcmass', 'cell'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n      layers:\t'raw'\n    peptide:\t70 x 18846\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value', 'protein_group', 'peptide_type'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'\n    protein:\t70 x 3054\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'count_psm', 'count_stripped_peptide', 'PEP', 'q_value'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'</pre> In\u00a0[13]: Copied! <pre>import matplotlib.pyplot as plt\nimport pandas as pd\nimport pimmslearn.plotting as pmp\nimport pimmslearn.sampling as pms\nimport pimmslearn.models as pmm\n\nfrom pimmslearn.plotting.defaults import color_model_mapping\nfrom pimmslearn.sklearn.ae_transformer import AETransformer\nfrom pimmslearn.sklearn.cf_transformer import CollaborativeFilteringTransformer\n\n\npmp.make_large_descriptors(\"8\")\n\nindex_name: str = \"Sample ID\"\ncolumn_name: str = \"protein group\"\nfrac_non_train: float = 0.1\nfrac_mnar: float = 0.05\nrandom_state: int = 42\n</pre> import matplotlib.pyplot as plt import pandas as pd import pimmslearn.plotting as pmp import pimmslearn.sampling as pms import pimmslearn.models as pmm  from pimmslearn.plotting.defaults import color_model_mapping from pimmslearn.sklearn.ae_transformer import AETransformer from pimmslearn.sklearn.cf_transformer import CollaborativeFilteringTransformer   pmp.make_large_descriptors(\"8\")  index_name: str = \"Sample ID\" column_name: str = \"protein group\" frac_non_train: float = 0.1 frac_mnar: float = 0.05 random_state: int = 42 In\u00a0[14]: Copied! <pre>df = mdata[\"protein\"].to_df()\ndf.index.name = \"Sample ID\"\ndf.columns.name = \"protein group\"\n</pre> df = mdata[\"protein\"].to_df() df.index.name = \"Sample ID\" df.columns.name = \"protein group\" In\u00a0[15]: Copied! <pre>ax = pmp.data.plot_feat_median_over_prop_missing(data=df, type=\"boxplot\")\n</pre> ax = pmp.data.plot_feat_median_over_prop_missing(data=df, type=\"boxplot\") <pre>/Users/jl/.local/share/virtualenvs/msmu-c3VCzU_G/lib/python3.13/site-packages/pimmslearn/plotting/data.py:327: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n  ax = ax[0]  # returned series due to by argument?\n</pre> In\u00a0[16]: Copied! <pre>df = df.stack().to_frame(\"intensity\")\n\nsplits, thresholds, fake_na_mcar, fake_na_mnar = pms.sample_mnar_mcar(\n    df_long=df,\n    frac_non_train=frac_non_train,\n    frac_mnar=frac_mnar,\n    random_state=random_state,\n)\nsplits = pms.check_split_integrity(splits)\n</pre> df = df.stack().to_frame(\"intensity\")  splits, thresholds, fake_na_mcar, fake_na_mnar = pms.sample_mnar_mcar(     df_long=df,     frac_non_train=frac_non_train,     frac_mnar=frac_mnar,     random_state=random_state, ) splits = pms.check_split_integrity(splits) <pre>/Users/jl/.local/share/virtualenvs/msmu-c3VCzU_G/lib/python3.13/site-packages/pimmslearn/sampling.py:209: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n  loc=float(quantile_frac),\n/Users/jl/.local/share/virtualenvs/msmu-c3VCzU_G/lib/python3.13/site-packages/pimmslearn/sampling.py:210: FutureWarning: Calling float on a single element Series is deprecated and will raise a TypeError in the future. Use float(ser.iloc[0]) instead\n  scale=float(0.3 * df_long.std()),\n</pre> In\u00a0[17]: Copied! <pre>cf_model = CollaborativeFilteringTransformer(\n    target_column=\"intensity\",\n    sample_column=\"Sample ID\",\n    item_column=\"protein group\",\n    out_folder=\"runs/scikit_interface\",\n)\n\ncf_model.fit(splits.train_X, splits.val_y, cuda=False, epochs_max=20)\n</pre> cf_model = CollaborativeFilteringTransformer(     target_column=\"intensity\",     sample_column=\"Sample ID\",     item_column=\"protein group\",     out_folder=\"runs/scikit_interface\", )  cf_model.fit(splits.train_X, splits.val_y, cuda=False, epochs_max=20) <pre>suggested_lr.valley = 0.00525\n</pre> epoch train_loss valid_loss time 0 6.320165 6.174103 00:00 1 5.522466 4.395256 00:00 2 3.587925 2.049297 00:00 3 2.431448 1.833395 00:00 4 1.831739 1.518024 00:00 5 1.435816 1.355048 00:00 6 1.189103 1.294942 00:00 7 1.034226 1.249249 00:00 8 0.919461 1.232482 00:00 9 0.839021 1.222002 00:00 10 0.773871 1.213310 00:00 11 0.722318 1.214855 00:00 <pre>No improvement since epoch 10: early stopping\n</pre> Out[17]: <pre>CollaborativeFilteringTransformer(item_column='protein group',\n                                  out_folder=Path('runs/scikit_interface'),\n                                  sample_column='Sample ID',\n                                  target_column='intensity')</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.CollaborativeFilteringTransformeriFitted<pre>CollaborativeFilteringTransformer(item_column='protein group',\n                                  out_folder=Path('runs/scikit_interface'),\n                                  sample_column='Sample ID',\n                                  target_column='intensity')</pre> In\u00a0[18]: Copied! <pre>df_imputed = cf_model.transform(df).unstack()\nassert df_imputed.isna().sum().sum() == 0\n</pre> df_imputed = cf_model.transform(df).unstack() assert df_imputed.isna().sum().sum() == 0 In\u00a0[19]: Copied! <pre>df_imputed = df_imputed.stack()  # long-format\nobserved = df_imputed.loc[df.index]\nimputed = df_imputed.loc[df_imputed.index.difference(df.index)]\ndf_imputed = df_imputed.unstack()  # back to wide-format\n# some checks\nassert len(df) == len(observed)\nassert df_imputed.shape[0] * df_imputed.shape[1] == len(imputed) + len(observed)\n\nfig, axes = plt.subplots(2, figsize=(8, 4))\n\nmin_max = pmp.data.get_min_max_iterable([observed, imputed])\nlabel_template = \"{method} (N={n:,d})\"\nax, _ = pmp.data.plot_histogram_intensities(\n    observed,\n    ax=axes[0],\n    min_max=min_max,\n    label=label_template.format(\n        method=\"measured\",\n        n=len(observed),\n    ),\n    color=\"grey\",\n    alpha=1,\n)\n_ = ax.legend()\nax, _ = pmp.data.plot_histogram_intensities(\n    imputed,\n    ax=axes[1],\n    min_max=min_max,\n    label=label_template.format(\n        method=\"CF imputed\",\n        n=len(imputed),\n    ),\n    color=color_model_mapping[\"CF\"],\n    alpha=1,\n)\n_ = ax.legend()\n</pre> df_imputed = df_imputed.stack()  # long-format observed = df_imputed.loc[df.index] imputed = df_imputed.loc[df_imputed.index.difference(df.index)] df_imputed = df_imputed.unstack()  # back to wide-format # some checks assert len(df) == len(observed) assert df_imputed.shape[0] * df_imputed.shape[1] == len(imputed) + len(observed)  fig, axes = plt.subplots(2, figsize=(8, 4))  min_max = pmp.data.get_min_max_iterable([observed, imputed]) label_template = \"{method} (N={n:,d})\" ax, _ = pmp.data.plot_histogram_intensities(     observed,     ax=axes[0],     min_max=min_max,     label=label_template.format(         method=\"measured\",         n=len(observed),     ),     color=\"grey\",     alpha=1, ) _ = ax.legend() ax, _ = pmp.data.plot_histogram_intensities(     imputed,     ax=axes[1],     min_max=min_max,     label=label_template.format(         method=\"CF imputed\",         n=len(imputed),     ),     color=color_model_mapping[\"CF\"],     alpha=1, ) _ = ax.legend() In\u00a0[20]: Copied! <pre>splits.to_wide_format()\nsplits.val_y = pd.DataFrame(pd.NA, index=splits.train_X.index, columns=splits.train_X.columns).fillna(splits.val_y)\n</pre> splits.to_wide_format() splits.val_y = pd.DataFrame(pd.NA, index=splits.train_X.index, columns=splits.train_X.columns).fillna(splits.val_y) In\u00a0[21]: Copied! <pre>model_selected = \"DAE\"\n\nmodel = AETransformer(\n    model=model_selected,\n    hidden_layers=[512],\n    latent_dim=50,\n    out_folder=\"runs/scikit_interface\",\n    batch_size=10,\n)\n</pre> model_selected = \"DAE\"  model = AETransformer(     model=model_selected,     hidden_layers=[512],     latent_dim=50,     out_folder=\"runs/scikit_interface\",     batch_size=10, ) In\u00a0[22]: Copied! <pre>model.fit(splits.train_X, splits.val_y, epochs_max=50, cuda=False)\n</pre> model.fit(splits.train_X, splits.val_y, epochs_max=50, cuda=False) epoch train_loss valid_loss time 0 31082.289062 1663.821411 00:00 1 29537.611328 1580.292236 00:00 2 27614.193359 1379.376953 00:00 3 25691.705078 1447.400391 00:00 4 24164.673828 1423.883423 00:00 5 22979.968750 1181.390015 00:00 6 21837.660156 1150.241577 00:00 7 20585.669922 1149.429443 00:00 8 19582.843750 1130.486206 00:00 9 18656.513672 1136.786377 00:00 10 18028.900391 1183.855469 00:00 11 17458.158203 1220.037476 00:00 12 16862.056641 1204.772095 00:00 13 16387.130859 1181.086670 00:00 14 15914.469727 1175.465820 00:00 15 15412.682617 1172.427368 00:00 16 14872.686523 1138.039551 00:00 17 14321.765625 1118.993286 00:00 18 13806.336914 1138.566040 00:00 19 13332.366211 1119.463257 00:00 20 12888.664062 1118.378662 00:00 21 12363.695312 1109.387085 00:00 22 11877.583008 1104.461548 00:00 23 11523.218750 1100.300537 00:00 24 11178.151367 1109.922119 00:00 25 10833.538086 1103.574463 00:00 26 10543.821289 1106.167847 00:00 27 10258.711914 1107.717651 00:00 28 9946.045898 1100.307251 00:00 29 9641.920898 1093.588257 00:00 30 9378.814453 1095.416016 00:00 31 9125.350586 1090.117310 00:00 32 8903.874023 1085.963135 00:00 33 8626.411133 1087.794922 00:00 34 8382.924805 1089.914551 00:00 35 8222.190430 1089.441284 00:00 36 7962.709961 1080.896240 00:00 37 7748.377930 1073.487915 00:00 38 7572.700195 1073.060303 00:00 39 7424.407715 1074.218140 00:00 40 7307.616211 1078.132324 00:00 41 7132.653809 1077.919922 00:00 42 7049.728516 1077.697388 00:00 43 6878.440918 1074.800903 00:00 44 6760.032715 1074.024658 00:00 45 6639.622559 1071.721191 00:00 46 6609.085938 1075.444824 00:00 47 6488.123047 1074.282593 00:00 48 6376.672363 1073.937500 00:00 49 6316.729492 1074.901123 00:00 Out[22]: <pre>AETransformer(batch_size=10, hidden_layers=[512], latent_dim=50,\n              model=&lt;class 'pimmslearn.models.ae.Autoencoder'&gt;,\n              out_folder=Path('runs/scikit_interface'))</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.AETransformeriFitted<pre>AETransformer(batch_size=10, hidden_layers=[512], latent_dim=50,\n              model=&lt;class 'pimmslearn.models.ae.Autoencoder'&gt;,\n              out_folder=Path('runs/scikit_interface'))</pre> In\u00a0[23]: Copied! <pre>df_imputed = model.transform(splits.train_X).stack()\n</pre> df_imputed = model.transform(splits.train_X).stack() In\u00a0[24]: Copied! <pre>pred_val = splits.val_y.stack().to_frame(\"observed\")\npred_val[model_selected] = df_imputed\nval_metrics = pmm.calculte_metrics(pred_val, \"observed\")\n\nfig, ax = plt.subplots(figsize=(8, 2))\n\nax, errors_binned = pmp.errors.plot_errors_by_median(\n    pred=pred_val,\n    target_col=\"observed\",\n    feat_medians=splits.train_X.median(),\n    ax=ax,\n    metric_name=\"MAE\",\n    palette=color_model_mapping,\n)\n</pre> pred_val = splits.val_y.stack().to_frame(\"observed\") pred_val[model_selected] = df_imputed val_metrics = pmm.calculte_metrics(pred_val, \"observed\")  fig, ax = plt.subplots(figsize=(8, 2))  ax, errors_binned = pmp.errors.plot_errors_by_median(     pred=pred_val,     target_col=\"observed\",     feat_medians=splits.train_X.median(),     ax=ax,     metric_name=\"MAE\",     palette=color_model_mapping, ) <pre>/Users/jl/.local/share/virtualenvs/msmu-c3VCzU_G/lib/python3.13/site-packages/seaborn/categorical.py:641: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grouped_vals = vals.groupby(grouper)\n/Users/jl/.local/share/virtualenvs/msmu-c3VCzU_G/lib/python3.13/site-packages/seaborn/categorical.py:641: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n  grouped_vals = vals.groupby(grouper)\n</pre> In\u00a0[25]: Copied! <pre>splits.to_long_format()\ndf_imputed = df_imputed.replace(splits.val_y).replace(splits.test_y)\n</pre> splits.to_long_format() df_imputed = df_imputed.replace(splits.val_y).replace(splits.test_y) In\u00a0[26]: Copied! <pre>observed = df_imputed.loc[df.index].squeeze()\nimputed = df_imputed.loc[df_imputed.index.difference(df.index)].squeeze()\n\nfig, axes = plt.subplots(2, figsize=(8, 4))\n\nmin_max = pmp.data.get_min_max_iterable([observed, imputed])\n\nlabel_template = \"{method} (N={n:,d})\"\nax, _ = pmp.data.plot_histogram_intensities(\n    observed,\n    ax=axes[0],\n    min_max=min_max,\n    label=label_template.format(\n        method=\"measured\",\n        n=len(observed),\n    ),\n    color=\"grey\",\n    alpha=1,\n)\n_ = ax.legend()\nax, _ = pmp.data.plot_histogram_intensities(\n    imputed,\n    ax=axes[1],\n    min_max=min_max,\n    label=label_template.format(\n        method=f\"{model_selected} imputed\",\n        n=len(imputed),\n    ),\n    color=color_model_mapping[model_selected],\n    alpha=1,\n)\n_ = ax.legend()\n</pre> observed = df_imputed.loc[df.index].squeeze() imputed = df_imputed.loc[df_imputed.index.difference(df.index)].squeeze()  fig, axes = plt.subplots(2, figsize=(8, 4))  min_max = pmp.data.get_min_max_iterable([observed, imputed])  label_template = \"{method} (N={n:,d})\" ax, _ = pmp.data.plot_histogram_intensities(     observed,     ax=axes[0],     min_max=min_max,     label=label_template.format(         method=\"measured\",         n=len(observed),     ),     color=\"grey\",     alpha=1, ) _ = ax.legend() ax, _ = pmp.data.plot_histogram_intensities(     imputed,     ax=axes[1],     min_max=min_max,     label=label_template.format(         method=f\"{model_selected} imputed\",         n=len(imputed),     ),     color=color_model_mapping[model_selected],     alpha=1, ) _ = ax.legend() In\u00a0[27]: Copied! <pre>mdata.mod[\"protein\"].layers[\"imputed\"] = df_imputed.unstack()\nmdata.update()\n\nmdata\n</pre> mdata.mod[\"protein\"].layers[\"imputed\"] = df_imputed.unstack() mdata.update()  mdata <pre>/var/folders/pp/7ts5fh4x5hl81rnn895l34ph0000gn/T/ipykernel_17793/3088553350.py:1: ImplicitModificationWarning: Setting element `.layers['imputed']` of view, initializing view as actual.\n  mdata.mod[\"protein\"].layers[\"imputed\"] = df_imputed.unstack()\n</pre> Out[27]: <pre>MuData object with n_obs \u00d7 n_vars = 70 \u00d7 95925\n  obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n  uns:\t'_cmd'\n  3 modalities\n    psm:\t70 x 74025\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value', 'rt', 'calcmass', 'cell'\n      uns:\t'level', 'search_engine', 'quantification', 'label', 'acquisition', 'identification_file', 'quantification_file', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'search_result', 'filter'\n      layers:\t'raw'\n    peptide:\t70 x 18846\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value', 'protein_group', 'peptide_type'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'\n    protein:\t70 x 3054\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'count_psm', 'count_stripped_peptide', 'PEP', 'q_value'\n      uns:\t'level', 'decoy', 'filter', 'decoy_filter'\n      varm:\t'filter'\n      layers:\t'imputed'</pre> In\u00a0[28]: Copied! <pre>mdata.write_h5mu(\"MSV000089280.h5mu\")\n</pre> mdata.write_h5mu(\"MSV000089280.h5mu\")"},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#process-proteomics-data-from-sage-with-msmu","title":"Process Proteomics Data from Sage with msmu\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#psm","title":"PSM\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#peptide","title":"Peptide\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#filtering-peptide","title":"Filtering - peptide\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#normalization","title":"Normalization\u00b6","text":"<p>Here, we log2 transform and normalize the data at the peptide level.</p> <p>Median centering normalization is applied using <code>mm.pp.normalize()</code> function.</p>"},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#protein-inference","title":"Protein inference\u00b6","text":"<p>You can infer protein-level data from peptide-level data using the <code>mm.pp.infer_protein()</code> function.</p>"},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#protein","title":"Protein\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#filtering-protein","title":"Filtering - protein\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#imputation","title":"Imputation\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#check-missing-value-pattern","title":"Check missing value pattern\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#robust-missing-value-imputation","title":"Robust missing value imputation\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#check-imputation-results","title":"Check imputation results\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#imputation-with-denoising-autoencoder","title":"Imputation with denoising autoencoder\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#check-imputation-results","title":"Check imputation results\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#push-imputed-data-to-mudata-object","title":"Push imputed data to mudata object\u00b6","text":""},{"location":"tutorials/2024_Fulcher/02_process_protein_data/#save-mudata-object","title":"Save MuData object\u00b6","text":""},{"location":"tutorials/2024_Fulcher/03_handle_multi-omics_data/","title":"03 Handle Multi-omics Data","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport msmu as mm\nimport mofax as mofa\nimport muon as mu\nimport pandas as pd\nimport requests\nimport scanpy as sc\nimport seaborn as sns\n\nplt.rcParams[\"font.family\"] = \"Arial\"\n\nrandom_state = 42\n</pre> import matplotlib.pyplot as plt import msmu as mm import mofax as mofa import muon as mu import pandas as pd import requests import scanpy as sc import seaborn as sns  plt.rcParams[\"font.family\"] = \"Arial\"  random_state = 42 <pre>Determination of memory status is not supported on this \n platform, measuring for memoryleaks will never fail\n/Users/jl/.local/share/virtualenvs/msmu-c3VCzU_G/lib/python3.13/site-packages/muon/_core/preproc.py:31: FutureWarning: `__version__` is deprecated, use `importlib.metadata.version('scanpy')` instead\n  if Version(scanpy.__version__) &lt; Version(\"1.10\"):\n</pre> In\u00a0[2]: Copied! <pre>adata = sc.read_h5ad(\"GSE201575.h5ad\")\nmdata = mm.read_h5mu(\"MSV000089280.h5mu\")\nmdata.mod[\"rna\"] = adata\nmdata.update()\nmdata\n</pre> adata = sc.read_h5ad(\"GSE201575.h5ad\") mdata = mm.read_h5mu(\"MSV000089280.h5mu\") mdata.mod[\"rna\"] = adata mdata.update() mdata Out[2]: <pre>MuData object with n_obs \u00d7 n_vars = 70 \u00d7 109376\n  obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n  uns:\t'_cmd'\n  4 modalities\n    psm:\t70 x 74025\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'proteins', 'peptide', 'stripped_peptide', 'filename', 'scan_num', 'charge', 'peptide_length', 'missed_cleavages', 'semi_enzymatic', 'contaminant', 'PEP', 'q_value', 'cell'\n      uns:\t'acquisition', 'decoy', 'decoy_filter', 'filter', 'identification_file', 'label', 'level', 'quantification', 'quantification_file', 'search_engine'\n      varm:\t'filter', 'search_result'\n      layers:\t'raw'\n    peptide:\t70 x 18846\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'peptide', 'proteins', 'stripped_peptide', 'count_psm', 'PEP', 'q_value', 'protein_group', 'peptide_type'\n      uns:\t'decoy', 'decoy_filter', 'filter', 'level'\n      varm:\t'filter'\n    protein:\t70 x 3054\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'count_psm', 'count_stripped_peptide', 'PEP', 'q_value'\n      uns:\t'decoy', 'decoy_filter', 'filter', 'level'\n      varm:\t'filter'\n      layers:\t'imputed'\n    rna:\t70 x 13451\n      obs:\t'filename', 'set', 'sample_id', 'sample', 'cell', 'condition', 'sample_rna', 'n_genes'\n      var:\t'n_cells'\n      uns:\t'log1p'\n      layers:\t'counts'</pre> In\u00a0[3]: Copied! <pre>mdata.write_h5mu(\"multimodal.h5mu\")\n</pre> mdata.write_h5mu(\"multimodal.h5mu\") In\u00a0[4]: Copied! <pre>mdata = mm.read_h5mu(\"multimodal.h5mu\")\nmdata_subset = mu.MuData({\"protein\": mdata.mod[\"protein\"].copy(), \"rna\": mdata.mod[\"rna\"].copy()})\nmdata_subset.mod[\"protein\"].X = mdata_subset.mod[\"protein\"].layers[\"imputed\"]\n\nsc.pp.pca(mdata_subset.mod[\"rna\"])\nsc.pp.pca(mdata_subset.mod[\"protein\"])\nsc.pp.neighbors(mdata_subset.mod[\"rna\"], n_pcs=4)\nsc.pp.neighbors(mdata_subset.mod[\"protein\"], n_pcs=4)\n\n# Calculate weighted nearest neighbors (WNN)\nmu.pp.neighbors(mdata_subset, key_added=\"wnn\")\nmu.tl.umap(mdata_subset, neighbors_key=\"wnn\", random_state=random_state)\n\nmdata.obsm[\"WNN_UMAP\"] = mdata_subset.obsm[\"X_umap\"]\n</pre> mdata = mm.read_h5mu(\"multimodal.h5mu\") mdata_subset = mu.MuData({\"protein\": mdata.mod[\"protein\"].copy(), \"rna\": mdata.mod[\"rna\"].copy()}) mdata_subset.mod[\"protein\"].X = mdata_subset.mod[\"protein\"].layers[\"imputed\"]  sc.pp.pca(mdata_subset.mod[\"rna\"]) sc.pp.pca(mdata_subset.mod[\"protein\"]) sc.pp.neighbors(mdata_subset.mod[\"rna\"], n_pcs=4) sc.pp.neighbors(mdata_subset.mod[\"protein\"], n_pcs=4)  # Calculate weighted nearest neighbors (WNN) mu.pp.neighbors(mdata_subset, key_added=\"wnn\") mu.tl.umap(mdata_subset, neighbors_key=\"wnn\", random_state=random_state)  mdata.obsm[\"WNN_UMAP\"] = mdata_subset.obsm[\"X_umap\"] <pre>OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n/Users/jl/.local/share/virtualenvs/msmu-c3VCzU_G/lib/python3.13/site-packages/pynndescent/pynndescent_.py:939: UserWarning: Failed to correctly find n_neighbors for some samples. Results may be less than ideal. Try re-running with different parameters.\n  warn(\n/Users/jl/.local/share/virtualenvs/msmu-c3VCzU_G/lib/python3.13/site-packages/pynndescent/pynndescent_.py:939: UserWarning: Failed to correctly find n_neighbors for some samples. Results may be less than ideal. Try re-running with different parameters.\n  warn(\n</pre> In\u00a0[5]: Copied! <pre>fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(14, 4))\nmu.pl.embedding(\n    mdata,\n    basis=\"WNN_UMAP\",\n    color=\"cell\",\n    size=100,\n    title=\"WNN UMAP\",\n    ax=ax0,\n    legend_loc=\"on data\",\n    legend_fontoutline=2,\n    show=False,\n)\nmu.pl.embedding(\n    mdata,\n    basis=\"WNN_UMAP\",\n    color=\"P04223\",\n    size=100,\n    ax=ax1,\n    title=\"HA1K (Protein)\",\n    colorbar_loc=None,\n    show=False,\n    cmap=\"Blues\",\n)\nmu.pl.embedding(\n    mdata,\n    basis=\"WNN_UMAP\",\n    color=\"H2-K1\",\n    size=100,\n    ax=ax2,\n    title=\"\",\n    colorbar_loc=None,\n    show=False,\n    cmap=\"Reds\",\n)\n\n\nfig.colorbar(mappable=ax1.collections[0], ax=ax1, fraction=0.05, aspect=20, pad=0.02, shrink=0.875, anchor=(1, 0))\nfig.colorbar(mappable=ax2.collections[0], ax=ax2, fraction=0.05, aspect=20, pad=0.02, shrink=0.875, anchor=(1, 0))\n\nax1.collections[0].colorbar.set_label(\n    \"Intensity\\n(log$_2$)\",\n    rotation=0,\n    ha=\"left\",\n    va=\"bottom\",\n    x=0,\n    y=1.025,\n    labelpad=-30,\n)\nax2.collections[0].colorbar.set_label(\n    \"Read Count\\n(log$_{10}$)\",\n    rotation=0,\n    ha=\"left\",\n    va=\"bottom\",\n    x=0,\n    y=1.025,\n    labelpad=-24,\n)\nax2.text(0.5, 1.0175, \"H2-K1\", ha=\"right\", va=\"bottom\", transform=ax2.transAxes, fontstyle=\"italic\", size=12)\nax2.text(0.51, 1.0175, \"(RNA)\", ha=\"left\", va=\"bottom\", transform=ax2.transAxes, size=12)\n\nfig.savefig(\"Fig2B_WNN_UMAP.svg\", dpi=300, bbox_inches=\"tight\")\n</pre> fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(14, 4)) mu.pl.embedding(     mdata,     basis=\"WNN_UMAP\",     color=\"cell\",     size=100,     title=\"WNN UMAP\",     ax=ax0,     legend_loc=\"on data\",     legend_fontoutline=2,     show=False, ) mu.pl.embedding(     mdata,     basis=\"WNN_UMAP\",     color=\"P04223\",     size=100,     ax=ax1,     title=\"HA1K (Protein)\",     colorbar_loc=None,     show=False,     cmap=\"Blues\", ) mu.pl.embedding(     mdata,     basis=\"WNN_UMAP\",     color=\"H2-K1\",     size=100,     ax=ax2,     title=\"\",     colorbar_loc=None,     show=False,     cmap=\"Reds\", )   fig.colorbar(mappable=ax1.collections[0], ax=ax1, fraction=0.05, aspect=20, pad=0.02, shrink=0.875, anchor=(1, 0)) fig.colorbar(mappable=ax2.collections[0], ax=ax2, fraction=0.05, aspect=20, pad=0.02, shrink=0.875, anchor=(1, 0))  ax1.collections[0].colorbar.set_label(     \"Intensity\\n(log$_2$)\",     rotation=0,     ha=\"left\",     va=\"bottom\",     x=0,     y=1.025,     labelpad=-30, ) ax2.collections[0].colorbar.set_label(     \"Read Count\\n(log$_{10}$)\",     rotation=0,     ha=\"left\",     va=\"bottom\",     x=0,     y=1.025,     labelpad=-24, ) ax2.text(0.5, 1.0175, \"H2-K1\", ha=\"right\", va=\"bottom\", transform=ax2.transAxes, fontstyle=\"italic\", size=12) ax2.text(0.51, 1.0175, \"(RNA)\", ha=\"left\", va=\"bottom\", transform=ax2.transAxes, size=12)  fig.savefig(\"Fig2B_WNN_UMAP.svg\", dpi=300, bbox_inches=\"tight\") In\u00a0[6]: Copied! <pre>mdata = mm.read_h5mu(\"multimodal.h5mu\")\nmdata_subset = mu.MuData({\"protein\": mdata.mod[\"protein\"].copy(), \"rna\": mdata.mod[\"rna\"].copy()})\n\nmdata_subset\n</pre> mdata = mm.read_h5mu(\"multimodal.h5mu\") mdata_subset = mu.MuData({\"protein\": mdata.mod[\"protein\"].copy(), \"rna\": mdata.mod[\"rna\"].copy()})  mdata_subset Out[6]: <pre>MuData object with n_obs \u00d7 n_vars = 70 \u00d7 16505\n  2 modalities\n    protein:\t70 x 3054\n      obs:\t'set', 'sample', 'cell', 'condition', 'sample_rna'\n      var:\t'count_psm', 'count_stripped_peptide', 'PEP', 'q_value'\n      uns:\t'decoy', 'decoy_filter', 'filter', 'level'\n      varm:\t'filter'\n      layers:\t'imputed'\n    rna:\t70 x 13451\n      obs:\t'filename', 'set', 'sample_id', 'sample', 'cell', 'condition', 'sample_rna', 'n_genes'\n      var:\t'n_cells'\n      uns:\t'log1p'\n      layers:\t'counts'</pre> In\u00a0[7]: Copied! <pre>mu.tl.mofa(mdata_subset, outfile=\"multimodal_model.hdf5\", seed=random_state)\n</pre> mu.tl.mofa(mdata_subset, outfile=\"multimodal_model.hdf5\", seed=random_state) <pre>\n        #########################################################\n        ###           __  __  ____  ______                    ### \n        ###          |  \\/  |/ __ \\|  ____/\\    _             ### \n        ###          | \\  / | |  | | |__ /  \\ _| |_           ### \n        ###          | |\\/| | |  | |  __/ /\\ \\_   _|          ###\n        ###          | |  | | |__| | | / ____ \\|_|            ###\n        ###          |_|  |_|\\____/|_|/_/    \\_\\              ###\n        ###                                                   ### \n        ######################################################### \n       \n \n        \n</pre> <pre>Loaded view='protein' group='group1' with N=70 samples and D=3054 features...\nLoaded view='rna' group='group1' with N=70 samples and D=13451 features...\n\n\nModel options:\n- Automatic Relevance Determination prior on the factors: True\n- Automatic Relevance Determination prior on the weights: True\n- Spike-and-slab prior on the factors: False\n- Spike-and-slab prior on the weights: True\nLikelihoods:\n- View 0 (protein): gaussian\n- View 1 (rna): gaussian\n\n\n\n\n######################################\n## Training the model with seed 42 ##\n######################################\n\n\n\nConverged!\n\n\n\n#######################\n## Training finished ##\n#######################\n\n\nWarning: Output file multimodal_model.hdf5 already exists, it will be replaced\nSaving model in multimodal_model.hdf5...\nSaved MOFA embeddings in .obsm['X_mofa'] slot and their loadings in .varm['LFs'].\n</pre> In\u00a0[8]: Copied! <pre>model = mofa.mofa_model(\"multimodal_model.hdf5\")\nmodel\n</pre> model = mofa.mofa_model(\"multimodal_model.hdf5\") model Out[8]: <pre>MOFA+ model: multimodal model\nSamples (cells): 70\nFeatures: 16505\nGroups: group1 (70)\nViews: protein (3054), rna (13451)\nFactors: 10\nExpectations: W, Z</pre> In\u00a0[9]: Copied! <pre>r2 = model.get_variance_explained(views=[\"protein\", \"rna\"])\n\nr2[\"View\"] = r2[\"View\"].map({\"protein\": \"Protein\", \"rna\": \"RNA\"})\nr2[\"Factor\"] = pd.Categorical(\n    r2[\"Factor\"],\n    categories=[f\"Factor{i+1}\" for i in range(r2[\"Factor\"].nunique())],\n    ordered=True,\n)\nr2_mat = r2.pivot_table(index=\"Factor\", columns=\"View\", values=\"R2\")\n\n# Plot\nfig = plt.figure(figsize=(3, 5))\nax = sns.heatmap(\n    r2_mat,\n    cmap=\"Greens\",\n    linecolor=\"black\",\n    linewidth=0.5,\n    fmt=\".2f\",\n    cbar_kws=dict(shrink=0.9, anchor=(1, 0), aspect=25, pad=0.05, fraction=0.15),\n)\n\nax.collections[0].colorbar.set_label(\n    \"Explained\\nVariance (%)\",\n    rotation=0,\n    ha=\"left\",\n    va=\"bottom\",\n    x=0,\n    y=1.025,\n    labelpad=-30,\n)\nax.invert_yaxis()\n\nfor spine in ax.spines.values():\n    spine.set_edgecolor(\"black\")\n    spine.set_linewidth(0.75)\n    spine.set_visible(True)\n\ncbar = ax.collections[0].colorbar\ncbar.set_ticks([0, 5, 10, 15])\n\nfor spine in cbar.ax.spines.values():\n    spine.set_edgecolor(\"black\")\n    spine.set_linewidth(0.75)\n\nfig.tight_layout()\nfig.show()\n\nfig.savefig(\"Fig2C_MOFA_R2.svg\", bbox_inches=\"tight\")\n</pre> r2 = model.get_variance_explained(views=[\"protein\", \"rna\"])  r2[\"View\"] = r2[\"View\"].map({\"protein\": \"Protein\", \"rna\": \"RNA\"}) r2[\"Factor\"] = pd.Categorical(     r2[\"Factor\"],     categories=[f\"Factor{i+1}\" for i in range(r2[\"Factor\"].nunique())],     ordered=True, ) r2_mat = r2.pivot_table(index=\"Factor\", columns=\"View\", values=\"R2\")  # Plot fig = plt.figure(figsize=(3, 5)) ax = sns.heatmap(     r2_mat,     cmap=\"Greens\",     linecolor=\"black\",     linewidth=0.5,     fmt=\".2f\",     cbar_kws=dict(shrink=0.9, anchor=(1, 0), aspect=25, pad=0.05, fraction=0.15), )  ax.collections[0].colorbar.set_label(     \"Explained\\nVariance (%)\",     rotation=0,     ha=\"left\",     va=\"bottom\",     x=0,     y=1.025,     labelpad=-30, ) ax.invert_yaxis()  for spine in ax.spines.values():     spine.set_edgecolor(\"black\")     spine.set_linewidth(0.75)     spine.set_visible(True)  cbar = ax.collections[0].colorbar cbar.set_ticks([0, 5, 10, 15])  for spine in cbar.ax.spines.values():     spine.set_edgecolor(\"black\")     spine.set_linewidth(0.75)  fig.tight_layout() fig.show()  fig.savefig(\"Fig2C_MOFA_R2.svg\", bbox_inches=\"tight\") In\u00a0[10]: Copied! <pre>def fetch_protein_name(accession):\n    url = f\"https://rest.uniprot.org/uniprotkb/{accession}\"\n    r = requests.get(url)\n    r.raise_for_status()\n    data = r.json()\n\n    name = data.get(\"uniProtkbId\", None)\n\n    return name.split(\"_\")[0]\n</pre> def fetch_protein_name(accession):     url = f\"https://rest.uniprot.org/uniprotkb/{accession}\"     r = requests.get(url)     r.raise_for_status()     data = r.json()      name = data.get(\"uniProtkbId\", None)      return name.split(\"_\")[0] In\u00a0[11]: Copied! <pre>df_f2 = model.get_weights(\n    views=\"protein\",\n    factors=1,\n    df=True,\n)\ndf_f2 = pd.melt(\n    df_f2.reset_index().rename(columns={\"index\": \"feature\"}),\n    id_vars=\"feature\",\n    var_name=\"factor\",\n    value_name=\"value\",\n)\ndf_f2[\"abs_value\"] = abs(df_f2.value)\ndf_f2[\"sign\"] = df_f2[\"value\"].apply(lambda x: \"Positive\" if x &gt;= 0 else \"Negative\")\ndf_f2[\"sign\"] = pd.Categorical(df_f2[\"sign\"], categories=[\"Positive\", \"Negative\"], ordered=True)\n\n# Assign ranks to features, per factor\ndf_f2[\"abs_rank\"] = df_f2.groupby(\"factor\")[\"abs_value\"].rank(ascending=False)\ndf_f2 = df_f2.sort_values([\"factor\", \"abs_rank\"], ascending=True)\ndf_f2 = df_f2[df_f2[\"abs_rank\"] &lt;= 15]\ndf_f2[\"gene\"] = df_f2[\"feature\"].apply(lambda x: fetch_protein_name(x))\n\nfig = plt.figure(figsize=(4, 5))\nax = sns.barplot(\n    data=df_f2,\n    x=\"abs_value\",\n    y=\"gene\",\n    hue=\"sign\",\n    dodge=False,\n    palette={\"Positive\": \"#5DA5D1\", \"Negative\": \"#D6E6F4\"},\n    width=0.75,\n    edgecolor=\"black\",\n)\n\nfor container, hatch in zip(ax.containers, [\"\", \"//\"]):\n    for bar in container:\n        bar.set_hatch(hatch)\n\nax.set_title(\"Protein\")\nax.xaxis.set_ticks([0, 0.5, 1.0, 1.5])\nax.set_xlabel(\"Absolute Weight\")\nax.set_ylabel(\"Top Factor2 Features\")\nax.legend(title=\"Direction\")\n\nfig.tight_layout()\nfig.savefig(\"Fig2D_f2_prot.svg\", bbox_inches=\"tight\")\n</pre> df_f2 = model.get_weights(     views=\"protein\",     factors=1,     df=True, ) df_f2 = pd.melt(     df_f2.reset_index().rename(columns={\"index\": \"feature\"}),     id_vars=\"feature\",     var_name=\"factor\",     value_name=\"value\", ) df_f2[\"abs_value\"] = abs(df_f2.value) df_f2[\"sign\"] = df_f2[\"value\"].apply(lambda x: \"Positive\" if x &gt;= 0 else \"Negative\") df_f2[\"sign\"] = pd.Categorical(df_f2[\"sign\"], categories=[\"Positive\", \"Negative\"], ordered=True)  # Assign ranks to features, per factor df_f2[\"abs_rank\"] = df_f2.groupby(\"factor\")[\"abs_value\"].rank(ascending=False) df_f2 = df_f2.sort_values([\"factor\", \"abs_rank\"], ascending=True) df_f2 = df_f2[df_f2[\"abs_rank\"] &lt;= 15] df_f2[\"gene\"] = df_f2[\"feature\"].apply(lambda x: fetch_protein_name(x))  fig = plt.figure(figsize=(4, 5)) ax = sns.barplot(     data=df_f2,     x=\"abs_value\",     y=\"gene\",     hue=\"sign\",     dodge=False,     palette={\"Positive\": \"#5DA5D1\", \"Negative\": \"#D6E6F4\"},     width=0.75,     edgecolor=\"black\", )  for container, hatch in zip(ax.containers, [\"\", \"//\"]):     for bar in container:         bar.set_hatch(hatch)  ax.set_title(\"Protein\") ax.xaxis.set_ticks([0, 0.5, 1.0, 1.5]) ax.set_xlabel(\"Absolute Weight\") ax.set_ylabel(\"Top Factor2 Features\") ax.legend(title=\"Direction\")  fig.tight_layout() fig.savefig(\"Fig2D_f2_prot.svg\", bbox_inches=\"tight\") In\u00a0[12]: Copied! <pre>df_f2 = model.get_weights(\n    views=\"rna\",\n    factors=1,\n    df=True,\n)\ndf_f2 = pd.melt(\n    df_f2.reset_index().rename(columns={\"index\": \"feature\"}),\n    id_vars=\"feature\",\n    var_name=\"factor\",\n    value_name=\"value\",\n)\ndf_f2[\"abs_value\"] = abs(df_f2.value)\ndf_f2[\"sign\"] = df_f2[\"value\"].apply(lambda x: \"Positive\" if x &gt;= 0 else \"Negative\")\ndf_f2[\"sign\"] = pd.Categorical(df_f2[\"sign\"], categories=[\"Positive\", \"Negative\"], ordered=True)\n\n# Assign ranks to features, per factor\ndf_f2[\"abs_rank\"] = df_f2.groupby(\"factor\")[\"abs_value\"].rank(ascending=False)\ndf_f2 = df_f2.sort_values([\"factor\", \"abs_rank\"], ascending=True)\ndf_f2 = df_f2[df_f2[\"abs_rank\"] &lt;= 15]\n\nfig = plt.figure(figsize=(4, 5))\nax = sns.barplot(\n    data=df_f2,\n    x=\"abs_value\",\n    y=\"feature\",\n    hue=\"sign\",\n    dodge=False,\n    palette={\"Positive\": \"#FF6262\", \"Negative\": \"#FCBEA5\"},\n    width=0.75,\n    edgecolor=\"black\",\n)\n\nfor container, hatch in zip(ax.containers, [\"\", \"//\"]):\n    for bar in container:\n        bar.set_hatch(hatch)\n\nax.set_title(\"RNA\")\nax.xaxis.set_ticks([0.0, 0.5, 1.0, 1.5, 2.0, 2.5])\nax.set_xlabel(\"Absolute Weight\")\nax.set_ylabel(\"Top Factor2 Features\")\nfor tick in ax.get_yticklabels():\n    tick.set_fontstyle(\"italic\")\nax.legend(title=\"Direction\")\n\nfig.tight_layout()\nfig.savefig(\"Fig2D_f2_rna.svg\", bbox_inches=\"tight\")\n</pre> df_f2 = model.get_weights(     views=\"rna\",     factors=1,     df=True, ) df_f2 = pd.melt(     df_f2.reset_index().rename(columns={\"index\": \"feature\"}),     id_vars=\"feature\",     var_name=\"factor\",     value_name=\"value\", ) df_f2[\"abs_value\"] = abs(df_f2.value) df_f2[\"sign\"] = df_f2[\"value\"].apply(lambda x: \"Positive\" if x &gt;= 0 else \"Negative\") df_f2[\"sign\"] = pd.Categorical(df_f2[\"sign\"], categories=[\"Positive\", \"Negative\"], ordered=True)  # Assign ranks to features, per factor df_f2[\"abs_rank\"] = df_f2.groupby(\"factor\")[\"abs_value\"].rank(ascending=False) df_f2 = df_f2.sort_values([\"factor\", \"abs_rank\"], ascending=True) df_f2 = df_f2[df_f2[\"abs_rank\"] &lt;= 15]  fig = plt.figure(figsize=(4, 5)) ax = sns.barplot(     data=df_f2,     x=\"abs_value\",     y=\"feature\",     hue=\"sign\",     dodge=False,     palette={\"Positive\": \"#FF6262\", \"Negative\": \"#FCBEA5\"},     width=0.75,     edgecolor=\"black\", )  for container, hatch in zip(ax.containers, [\"\", \"//\"]):     for bar in container:         bar.set_hatch(hatch)  ax.set_title(\"RNA\") ax.xaxis.set_ticks([0.0, 0.5, 1.0, 1.5, 2.0, 2.5]) ax.set_xlabel(\"Absolute Weight\") ax.set_ylabel(\"Top Factor2 Features\") for tick in ax.get_yticklabels():     tick.set_fontstyle(\"italic\") ax.legend(title=\"Direction\")  fig.tight_layout() fig.savefig(\"Fig2D_f2_rna.svg\", bbox_inches=\"tight\")"},{"location":"tutorials/2024_Fulcher/03_handle_multi-omics_data/#handle-multi-omics-data-with-msmu","title":"Handle multi-omics Data with msmu\u00b6","text":""},{"location":"tutorials/2024_Fulcher/03_handle_multi-omics_data/#merge-modalities","title":"Merge modalities\u00b6","text":""},{"location":"tutorials/2024_Fulcher/03_handle_multi-omics_data/#wnn-umap","title":"WNN UMAP\u00b6","text":""},{"location":"tutorials/2024_Fulcher/03_handle_multi-omics_data/#fig-2b","title":"Fig 2B\u00b6","text":""},{"location":"tutorials/2024_Fulcher/03_handle_multi-omics_data/#mofa","title":"MOFA\u00b6","text":""},{"location":"tutorials/2024_Fulcher/03_handle_multi-omics_data/#creating-model","title":"Creating Model\u00b6","text":""},{"location":"tutorials/2024_Fulcher/03_handle_multi-omics_data/#model-inspection","title":"Model Inspection\u00b6","text":""},{"location":"tutorials/2024_Fulcher/03_handle_multi-omics_data/#fig-2c","title":"Fig 2C\u00b6","text":""},{"location":"tutorials/2024_Fulcher/03_handle_multi-omics_data/#fig-2d","title":"Fig 2D\u00b6","text":""}]}